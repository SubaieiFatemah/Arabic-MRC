{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "import shutil\r\n",
        "from collections import Counter\r\n",
        "import numpy as np\r\n",
        "import json\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from transformers import AutoTokenizer, ElectraForQuestionAnswering, DataCollatorWithPadding, ElectraModel\r\n",
        "from Preprocess.arabertpreprocess import ArabertPreprocessor\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import csv\r\n",
        "torch.manual_seed(3407)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "<torch._C.Generator at 0x7f647ce5dd68>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1646505308161
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_end_index(answer, context):\r\n",
        "  ## 1 if span match the context 0 otherwise\r\n",
        "  text = answer['text']\r\n",
        "  start_idx = answer['answer_start']\r\n",
        "  end_idx = start_idx + len(text)\r\n",
        "  answer['answer_end'] = end_idx\r\n",
        "  if text == context[start_idx:end_idx]:\r\n",
        "    answer['answer_end'] = end_idx\r\n",
        "    return False\r\n",
        "  for i in range(1,3):\r\n",
        "    if text == context[start_idx-i:end_idx-i]:\r\n",
        "      answer['answer_end']= end_idx-1\r\n",
        "      answer['answer_start'] = start_idx-1\r\n",
        "      return False\r\n",
        "  return True"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505308335
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def arabert_preprocess(context,question, answer, arabert_prep):\r\n",
        "    answer['text'] = arabert_prep.preprocess(answer['text'])\r\n",
        "    context = arabert_prep.preprocess(context)\r\n",
        "    question = arabert_prep.preprocess(question)\r\n",
        "    res = context.find(answer['text'])\r\n",
        "    if res !=-1:\r\n",
        "        answer['answer_start'] = res\r\n",
        "    return context, question, answer, res"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505308494
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Read_AAQAD(path,arabert_prep):\r\n",
        "  contexts =[]\r\n",
        "  answers =[]\r\n",
        "  questions =[]\r\n",
        "  IDs= []\r\n",
        "  plausible = []\r\n",
        "  cnt = 0\r\n",
        "  with open(path) as f:\r\n",
        "    aaqad_dict = json.load(f)\r\n",
        "    for article in aaqad_dict['data']:\r\n",
        "      for passage in article['paragraphs']:\r\n",
        "        context = passage['context']\r\n",
        "        for qa in passage['qas']:\r\n",
        "          question = qa['question']\r\n",
        "          if 'plausible_answers' in qa.keys():# there is two cases if the question have no answer then use plausible answer\r\n",
        "            access = 'plausible_answers'\r\n",
        "            plausible.append(True)\r\n",
        "          else:\r\n",
        "            access = 'answers'\r\n",
        "            plausible.append(False)\r\n",
        "          for answer in qa[access]:\r\n",
        "            context,question, answer, res =  arabert_preprocess(context,question, answer, arabert_prep)\r\n",
        "            #if res==-1:\r\n",
        "            #  cnt+=1\r\n",
        "            #  continue\r\n",
        "            flag = add_end_index(answer, context) #if false dont add the \r\n",
        "            cnt =cnt + flag\r\n",
        "            flag = False\r\n",
        "            if not flag:\r\n",
        "              contexts.append(context)\r\n",
        "              answers.append(answer)\r\n",
        "              questions.append(question)\r\n",
        "              IDs.append(int(qa['id']))\r\n",
        "  return contexts,questions,answers,plausible,IDs\r\n",
        "            "
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505308660
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_ids(path):\r\n",
        "  #IDs need to be fixed for evaluating purposes\r\n",
        "    a_file = open(path, \"r\")\r\n",
        "    json_object = json.load(a_file)\r\n",
        "    a_file.close()\r\n",
        "    for article in json_object['data']:\r\n",
        "      for passage in article['paragraphs']:\r\n",
        "        context = passage['context']\r\n",
        "        for qa in passage['qas']:\r\n",
        "            qa['id'] = str(qa['id'])\r\n",
        "    a_file = open(path, \"w\")\r\n",
        "    json.dump(json_object, a_file)\r\n",
        "    a_file.close()"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505308805
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"araelectra-base-discriminator\"\r\n",
        "arabert_prep = ArabertPreprocessor(model_name=model_name)\r\n",
        "fix_ids('Data/AAQAD-train.json')\r\n",
        "fix_ids('Data/AAQAD-dev.json')\r\n",
        "fix_ids('Data/AAQAD-test.json')\r\n",
        "aqad_train_contexts, aqad_train_questions, aqad_train_answers,aqad_train_plausible, aqad_train_ids = Read_AAQAD('Data/AAQAD-train.json', arabert_prep)\r\n",
        "aqad_val_contexts, aqad_val_questions, aqad_val_answers,aqad_val_plausible, aqad_val_ids = Read_AAQAD('Data/AAQAD-dev.json', arabert_prep)\r\n",
        "aqad_test_contexts, aqad_test_questions, aqad_test_answers,aqad_test_plausible, aqad_test_ids = Read_AAQAD('Data/AAQAD-test.json', arabert_prep)\r\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505326976
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(aqad_train_ids[0]))\r\n",
        "print(type(aqad_val_ids[0]))\r\n",
        "print(type(aqad_test_ids[0]))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'int'>\n<class 'int'>\n<class 'int'>\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505327108
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the tokenizer\r\n",
        "model_name = model_name = \"aubmindlab/araelectra-base-discriminator\"\r\n",
        "\r\n",
        "araelectra_tokenizer = AutoTokenizer.from_pretrained(model_name,do_lower_case=False)\r\n",
        "aqad_train_encodings = araelectra_tokenizer(aqad_train_questions, aqad_train_contexts, truncation=True, return_tensors=\"pt\", padding=\"max_length\", max_length=512)\r\n",
        "aqad_val_encodings = araelectra_tokenizer(aqad_val_questions, aqad_val_contexts, truncation=True, return_tensors=\"pt\", padding=\"max_length\", max_length=512 )\r\n",
        "aqad_test_encodings = araelectra_tokenizer(aqad_test_questions, aqad_test_contexts,truncation= True, return_tensors=\"pt\", padding=\"max_length\", max_length=512)\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505332107
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def index_to_token_position(encodings , answers):\r\n",
        "  start_positions = list()\r\n",
        "  end_positions = list()\r\n",
        "  for i in range(len(answers)):\r\n",
        "    start_positions.append(encodings.char_to_token(i, answers[i]['answer_start'], 1))\r\n",
        "    end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'], 1))\r\n",
        "    #if context truncated\r\n",
        "    if start_positions[-1] is None: \r\n",
        "      start_positions[-1] = araelectra_tokenizer.model_max_length\r\n",
        "    #if end index is space\r\n",
        "    itt = 1\r\n",
        "    while end_positions[-1] is None: \r\n",
        "      end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end']-itt, 1)\r\n",
        "      itt = itt + 1 \r\n",
        "  encodings.update({'start_positions': torch.tensor(start_positions), 'end_positions': torch.tensor(end_positions)})\r\n",
        "  encodings['start_positions'] = encodings['start_positions'].view(len(answers), 1)\r\n",
        "  encodings['end_positions'] = encodings['end_positions'].view(len(answers), 1)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505332287
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_token_position(aqad_train_encodings, aqad_train_answers)\r\n",
        "index_to_token_position(aqad_val_encodings, aqad_val_answers)\r\n",
        "index_to_token_position(aqad_test_encodings, aqad_test_answers)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505332440
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_weights_labels_tensors(encodings, plausible):\r\n",
        "  plausible = torch.tensor(plausible)\r\n",
        "  weights = torch.zeros(plausible.shape)\r\n",
        "  no_ans = torch.ones(plausible.shape)\r\n",
        "  weights[plausible==False]=1.0\r\n",
        "  no_ans[plausible==False]=0.0\r\n",
        "  weights = weights.view(-1,1)\r\n",
        "  no_ans = no_ans.view(-1,1)\r\n",
        "  encodings.update({'weights':weights, 'no_ans':no_ans})"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505332561
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "add_weights_labels_tensors(aqad_train_encodings, aqad_train_plausible)\r\n",
        "add_weights_labels_tensors(aqad_val_encodings, aqad_val_plausible)\r\n",
        "add_weights_labels_tensors(aqad_test_encodings, aqad_test_plausible)"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505332739
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aqad_train_encodings['IDs'] = aqad_train_ids\r\n",
        "aqad_val_encodings['IDs'] = aqad_val_ids\r\n",
        "aqad_test_encodings['IDs'] = aqad_test_ids"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505332874
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aqad_train_encodings.keys()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions', 'weights', 'no_ans', 'IDs'])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505333019
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset and DataLoader"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from tqdm import tqdm"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505333135
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AqadDataset(torch.utils.data.Dataset):\r\n",
        "    def __init__(self, encodings):\r\n",
        "        self.encodings = encodings\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        return {key: val[idx] for key, val in self.encodings.items()}\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.encodings.input_ids)\r\n",
        "\r\n",
        "train_dataset = AqadDataset(aqad_train_encodings)\r\n",
        "val_dataset = AqadDataset(aqad_val_encodings)\r\n",
        "test_dataset = AqadDataset(aqad_test_encodings)"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505333222
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(araelectra_tokenizer)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505333335
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle= True)\r\n",
        "val_loader = DataLoader(val_dataset, batch_size = 8, shuffle = True)\r\n",
        "test_loader = DataLoader(test_dataset, batch_size = 8, shuffle = True)"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505333456
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checkpoint Saving and Loading"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\r\n",
        "    \"\"\"\r\n",
        "    state: checkpoint to save\r\n",
        "    is_best: is this the best checkpoint; min validation loss\r\n",
        "    checkpoint_path: path to save checkpoint\r\n",
        "    best_model_path: path to save best checkpoint\r\n",
        "    \"\"\"\r\n",
        "    f_path = checkpoint_path\r\n",
        "    # save checkpoint data to the path given, checkpoint_path\r\n",
        "    torch.save(state, f_path)\r\n",
        "    # if it is a best model, min validation loss\r\n",
        "    if is_best:\r\n",
        "        best_fpath = best_model_path\r\n",
        "        # copy that checkpoint file to best path given, best_model_path\r\n",
        "        shutil.copyfile(f_path, best_fpath)"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505333577
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer):\r\n",
        "    \"\"\"\r\n",
        "    checkpoint_path: path to saved checkpoint\r\n",
        "    model: model to load checkpoint parameters into       \r\n",
        "    optimizer: optimizer defined in previous training\r\n",
        "    \"\"\"\r\n",
        "    # load check point\r\n",
        "    checkpoint = torch.load(checkpoint_fpath)\r\n",
        "    # initialize state_dict from checkpoint to model\r\n",
        "    model.load_state_dict(checkpoint['state_dict'])\r\n",
        "    # initialize optimizer from checkpoint to optimizer\r\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\r\n",
        "    # initialize valid_loss_min from checkpoint to valid_loss_min\r\n",
        "    results = checkpoint['result_dict']\r\n",
        "    # return model, optimizer, epoch value, min validation loss \r\n",
        "    return model, optimizer, checkpoint['epoch'], results"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505333699
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def order_exp(base_path, exp_name):\r\n",
        "  exp_path = os.path.join(base_path, exp_name)\r\n",
        "  if not os.path.exists(exp_path):\r\n",
        "    os.mkdir(exp_path)\r\n",
        "  curr_ckp_path = os.path.join(exp_path,'curr.pt')\r\n",
        "  best_ckp_path = os.path.join(exp_path, 'best.pt')\r\n",
        "  return curr_ckp_path, best_ckp_path, exp_path"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505333824
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Script (SQuAD v2)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AraElectraAbstain(nn.Module):\r\n",
        "  def __init__(self, Electra):\r\n",
        "    super().__init__()\r\n",
        "    self.base = Electra\r\n",
        "    #self.Weights = Weights\r\n",
        "    self.fcn = nn.Linear(768, 2)\r\n",
        "    self.abstainProjection = nn.Linear(768,1)\r\n",
        "    self.fcn2 = nn.Linear(512,1)\r\n",
        "    self.relu = nn.ReLU()\r\n",
        "    self.sigmoid = nn.Sigmoid()\r\n",
        "  def forward(self, tokens, token_type, mask):\r\n",
        "    output = self.base(input_ids = tokens, attention_mask = mask, token_type_ids = token_type)\r\n",
        "    electra_encoding = output.last_hidden_state\r\n",
        "    span = self.fcn(electra_encoding)\r\n",
        "    na_probs_logits = self.relu(self.abstainProjection(electra_encoding).view(-1,512))\r\n",
        "    na_probs_logits = self.fcn2(na_probs_logits)\r\n",
        "    na_probs = self.sigmoid(na_probs_logits) \r\n",
        "    return span,na_probs"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505333946
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze(Electra, count=None):\r\n",
        "    if count is not None:\r\n",
        "\t      # We freeze here the embeddings of the model\r\n",
        "        #for param in Electra.embeddings.parameters():\r\n",
        "        #    param.requires_grad = False\r\n",
        "\r\n",
        "        if count != -1:\r\n",
        "\t          # if freeze_layer_count == -1, we only freeze the embedding layer\r\n",
        "\t          # otherwise we freeze the first `freeze_layer_count` encoder layers\r\n",
        "            for layer in Electra.encoder.layer[:count]:\r\n",
        "                for param in layer.parameters():\r\n",
        "                    param.requires_grad = False\r\n",
        "    print(sum(p.numel() for p in Electra.parameters()), sum(p.numel() for p in Electra.parameters() if p.requires_grad))"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505334069
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Electra = ElectraModel.from_pretrained(model_name)\r\n",
        "QA_AraElectra = AraElectraAbstain(Electra)\r\n"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505336138
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freeze(QA_AraElectra.base, 4)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "134602752 106251264\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505336260
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\r\n",
        "learning_rate = 5e-5\r\n",
        "optimizer = torch.optim.AdamW(QA_AraElectra.parameters(), lr=learning_rate)\r\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "criterion_span = nn.CrossEntropyLoss(reduction='none')\r\n",
        "criterion_abstain = nn.BCELoss()\r\n",
        "QA_AraElectra.to(device)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "AraElectraAbstain(\n  (base): ElectraModel(\n    (embeddings): ElectraEmbeddings(\n      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): ElectraEncoder(\n      (layer): ModuleList(\n        (0): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (fcn): Linear(in_features=768, out_features=2, bias=True)\n  (abstainProjection): Linear(in_features=768, out_features=1, bias=True)\n  (fcn2): Linear(in_features=512, out_features=1, bias=True)\n  (relu): ReLU()\n  (sigmoid): Sigmoid()\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505338492
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_raw_preds(data_loader, model): \r\n",
        "  model.eval()\r\n",
        "  with torch.no_grad():\r\n",
        "    #F1 = EM = Total = 0\r\n",
        "    total_loss = 0.0\r\n",
        "    total_predictions = dict()\r\n",
        "    no_probs_pred = dict()\r\n",
        "    #loop = tqdm(data_loader)\r\n",
        "    #loop = tqdm(data_loader, leave=True)\r\n",
        "    for batch_idx, batch in enumerate(data_loader):\r\n",
        "      #moving tensors to gpu    \r\n",
        "      tokens = batch['input_ids'].to(device)\r\n",
        "      masks = batch['attention_mask'].to(device)\r\n",
        "      tokens_type = batch['token_type_ids'].to(device)\r\n",
        "      gt_start = batch['start_positions'].to(device)\r\n",
        "      gt_end = batch['end_positions'].to(device)\r\n",
        "      weights = batch['weights'].view(-1,1).to(device)\r\n",
        "      gt_no_ans = batch['no_ans'].to(device)\r\n",
        "      IDs = batch['IDs'].to(device)\r\n",
        "      span, no_probs = model(tokens, masks, tokens_type)\r\n",
        "      #calculating loss\r\n",
        "      span_loss = criterion_span(span, torch.concat([gt_start,gt_end], dim=1))\r\n",
        "      span_loss = torch.sum(torch.mean(span_loss*weights, dim=0))\r\n",
        "      no_ans_loss = criterion_abstain(no_probs, gt_no_ans)\r\n",
        "      loss = no_ans_loss + span_loss\r\n",
        "      #update average total loss \r\n",
        "      total_loss = total_loss + ((1 / (batch_idx + 1)) * (loss.item() - total_loss)) \r\n",
        "      #calculating f1 score and EM\r\n",
        "      curr_batch_size = tokens.shape[0]\r\n",
        "      #print(curr_batch_size)\r\n",
        "      for i in range(curr_batch_size):\r\n",
        "        #print(f\"this is tensor index {i}\")\r\n",
        "        span_pred= torch.argmax(span[i], dim=0)\r\n",
        "        start_pred, end_pred = span_pred[0], span_pred[1]\r\n",
        "        #print(start_pred.shape, end_pred.shape)\r\n",
        "        #print(start_pred, end_pred)\r\n",
        "        total_predictions[str(IDs[i].item())] = araelectra_tokenizer.decode(tokens[i][start_pred.item():end_pred.item()], skip_special_tokens=True, clean_up_tokenization_spaces=True)\r\n",
        "        no_probs_pred[str(IDs[i].item())] = no_probs[i].item()\r\n",
        "    #saving evaluation results\r\n",
        "    #evaluation\r\n",
        "\r\n",
        "    model.train()\r\n",
        "    return total_predictions, no_probs_pred"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505338613
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_preds(total_preds, no_probs_preds,data_path, log_path):\r\n",
        "    preds_path = os.path.join(log_path, 'preds')\r\n",
        "    if not os.path.exists(preds_path):\r\n",
        "        os.mkdir(preds_path)\r\n",
        "    no_probs_path = os.path.join(preds_path, 'na_probs.json')\r\n",
        "    text_preds_path = os.path.join(preds_path, 'preds.json')\r\n",
        "    jsonString = json.dumps(total_preds)\r\n",
        "    jsonFile = open(text_preds_path, \"w\")\r\n",
        "    jsonFile.write(jsonString)\r\n",
        "    jsonFile.close()\r\n",
        "    jsonString = json.dumps(no_probs_preds)\r\n",
        "    jsonFile = open(no_probs_path, \"w\")\r\n",
        "    jsonFile.write(jsonString)\r\n",
        "    jsonFile.close()\r\n",
        "    #!python evaluatev2.py data_path text_preds_path electra --na-prob-file no_probs_path --na-prob-thresh 0.4 --out-file log_path\r\n",
        "    os.system(f\"python evaluatev2.py {data_path} {text_preds_path} electra --na-prob-file {no_probs_path} --na-prob-thresh 0.5 --out-file {log_path}\")\r\n",
        "    with open(os.path.join(log_path, 'res.csv')) as f:\r\n",
        "        DictReader_obj = csv.DictReader(f)\r\n",
        "        lastrow = None\r\n",
        "        for item in DictReader_obj:\r\n",
        "            lastrow = dict(item)\r\n",
        "    print(lastrow)\r\n",
        "    return lastrow\r\n"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505338757
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,start_epoch, num_epochs, optimizer,max_compined_metric, train_loader, val_loader, log, exp_name):\r\n",
        "  curr_ckp_path, best_ckp_path, exp_path = order_exp('Runs/AraElectra_abstain/train', exp_name)\r\n",
        "  model.train()\r\n",
        "  for epoch in range(start_epoch,num_epochs):\r\n",
        "    total_loss = 0.0\r\n",
        "    loop = tqdm(train_loader, leave=True)\r\n",
        "    for batch_idx, batch in enumerate(loop):\r\n",
        "      tokens = batch['input_ids'].to(device)\r\n",
        "      masks = batch['attention_mask'].to(device)\r\n",
        "      tokens_type = batch['token_type_ids'].to(device)\r\n",
        "      gt_start = batch['start_positions'].to(device)\r\n",
        "      gt_end = batch['end_positions'].to(device)\r\n",
        "      weights = batch['weights'].view(-1,1).to(device)\r\n",
        "      gt_no_ans = batch['no_ans'].to(device)\r\n",
        "      span,no_probs = model(tokens, masks, tokens_type)\r\n",
        "      #print(gt_start.shape)\r\n",
        "      #print(span.shape)\r\n",
        "      #print(weights.shape)\r\n",
        "      span_loss = criterion_span(span, torch.concat([gt_start.view(-1,1),gt_end.view(-1,1)], dim=1))\r\n",
        "      #print(span_loss.shape)\r\n",
        "      span_loss = torch.sum(torch.mean(span_loss*weights, dim=0))\r\n",
        "      #print(no_probs.shape)\r\n",
        "      #print(gt_no_ans.shape)\r\n",
        "    \r\n",
        "      no_ans_loss = criterion_abstain(no_probs, gt_no_ans)\r\n",
        "      loss = no_ans_loss + span_loss\r\n",
        "      loss.backward()\r\n",
        "      optimizer.step()\r\n",
        "      optimizer.zero_grad()\r\n",
        "      total_loss = total_loss + ((1 / (batch_idx + 1)) * (loss.item() - total_loss)) \r\n",
        "      loop.set_description(f'Epoch {epoch}')\r\n",
        "      loop.set_postfix(loss=loss.item())\r\n",
        "\r\n",
        "    total_preds, no_probs_preds = get_raw_preds(val_loader, model)\r\n",
        "    result_dict = get_preds(total_preds, no_probs_preds,'Data/AAQAD-dev.json',exp_path )\r\n",
        "    checkpoint = {\r\n",
        "            'epoch': epoch + 1,\r\n",
        "            'result_dict':result_dict,\r\n",
        "            'state_dict': model.state_dict(),\r\n",
        "            'optimizer': optimizer.state_dict(),\r\n",
        "        }\r\n",
        "    curr_compined_metric = float(result_dict['exact'])+1.5*float(result_dict['f1'])\r\n",
        "    if curr_compined_metric>=max_compined_metric:\r\n",
        "      max_compined_metric = curr_compined_metric\r\n",
        "      save_ckp(checkpoint, True, curr_ckp_path, best_ckp_path)\r\n",
        "    else:\r\n",
        "      save_ckp(checkpoint, False, curr_ckp_path, best_ckp_path)\r\n",
        "    print(result_dict)\r\n",
        "  return model\r\n"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646505338883
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = train(QA_AraElectra,0, num_epochs, optimizer,0.0, train_loader, val_loader, True, 'first')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Epoch 0: 100%|██████████| 1579/1579 [36:26<00:00,  1.39s/it, loss=6.34] \n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Runs/AraElectra_abstain/train/first/res.csv') as f:\r\n",
        "    DictReader_obj = csv.DictReader(f)\r\n",
        "    lastrow = None\r\n",
        "    for item in DictReader_obj:\r\n",
        "        lastrow = dict(item)\r\n",
        "    print(json.dumps(lastrow, indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"exact\": \"15.680166147455868\",\n  \"f1\": \"19.742277127887526\",\n  \"total\": \"1926\",\n  \"HasAns_exact\": \"1.0058675607711651\",\n  \"HasAns_f1\": \"7.563810350638166\",\n  \"HasAns_total\": \"1193\",\n  \"NoAns_exact\": \"39.56343792633015\",\n  \"NoAns_f1\": \"39.56343792633015\",\n  \"NoAns_total\": \"733\",\n  \"best_exact\": \"38.05815160955348\",\n  \"best_exact_thresh\": \"0.0\",\n  \"best_f1\": \"38.09578704438517\",\n  \"best_f1_thresh\": \"0.0007945864927023649\"\n}\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646520370266
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}