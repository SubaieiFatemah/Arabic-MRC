{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "import shutil\r\n",
        "from collections import Counter\r\n",
        "import numpy as np\r\n",
        "import json\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from transformers import AutoTokenizer, ElectraForQuestionAnswering, DataCollatorWithPadding,BertModel, ElectraForSequenceClassification, ElectraModel\r\n",
        "from Preprocess.arabertpreprocess import ArabertPreprocessor\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import csv\r\n",
        "torch.manual_seed(3407)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "<torch._C.Generator at 0x7f7529785d68>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1646746685000
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_end_index(answer, context):\r\n",
        "  ## 1 if span match the context 0 otherwise\r\n",
        "  text = answer['text']\r\n",
        "  start_idx = answer['answer_start']\r\n",
        "  end_idx = start_idx + len(text)\r\n",
        "  answer['answer_end'] = end_idx\r\n",
        "  if text == context[start_idx:end_idx]:\r\n",
        "    answer['answer_end'] = end_idx\r\n",
        "    return False\r\n",
        "  for i in range(1,3):\r\n",
        "    if text == context[start_idx-i:end_idx-i]:\r\n",
        "      answer['answer_end']= end_idx-1\r\n",
        "      answer['answer_start'] = start_idx-1\r\n",
        "      return False\r\n",
        "  return True"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746715405
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def arabert_preprocess(context,question, answer, arabert_prep):\r\n",
        "    answer['text'] = arabert_prep.preprocess(answer['text'])\r\n",
        "    context = arabert_prep.preprocess(context)\r\n",
        "    question = arabert_prep.preprocess(question)\r\n",
        "    res = context.find(answer['text'])\r\n",
        "    if res !=-1:\r\n",
        "        answer['answer_start'] = res\r\n",
        "    return context, question, answer, res"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746716501
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Read_AAQAD(path,arabert_prep):\r\n",
        "  contexts =[]\r\n",
        "  answers =[]\r\n",
        "  questions =[]\r\n",
        "  IDs= []\r\n",
        "  plausible = []\r\n",
        "  cnt = 0\r\n",
        "  with open(path) as f:\r\n",
        "    aaqad_dict = json.load(f)\r\n",
        "    for article in aaqad_dict['data']:\r\n",
        "      for passage in article['paragraphs']:\r\n",
        "        context = passage['context']\r\n",
        "        for qa in passage['qas']:\r\n",
        "          question = qa['question']\r\n",
        "          if 'plausible_answers' in qa.keys():# there is two cases if the question have no answer then use plausible answer\r\n",
        "            access = 'plausible_answers'\r\n",
        "            plausible.append(True)\r\n",
        "          else:\r\n",
        "            access = 'answers'\r\n",
        "            plausible.append(False)\r\n",
        "          for answer in qa[access]:\r\n",
        "            context,question, answer, res =  arabert_preprocess(context,question, answer, arabert_prep)\r\n",
        "            #if res==-1:\r\n",
        "            #  cnt+=1\r\n",
        "            #  continue\r\n",
        "            flag = add_end_index(answer, context) #if false dont add the \r\n",
        "            cnt =cnt + flag\r\n",
        "            flag = False\r\n",
        "            if not flag:\r\n",
        "              contexts.append(context)\r\n",
        "              answers.append(answer)\r\n",
        "              questions.append(question)\r\n",
        "              IDs.append(int(qa['id']))\r\n",
        "  return contexts,questions,answers,plausible,IDs"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746716829
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_ids(path):\r\n",
        "  #IDs need to be fixed for evaluating purposes\r\n",
        "    a_file = open(path, \"r\")\r\n",
        "    json_object = json.load(a_file)\r\n",
        "    a_file.close()\r\n",
        "    for article in json_object['data']:\r\n",
        "      for passage in article['paragraphs']:\r\n",
        "        context = passage['context']\r\n",
        "        for qa in passage['qas']:\r\n",
        "            qa['id'] = str(qa['id'])\r\n",
        "    a_file = open(path, \"w\")\r\n",
        "    json.dump(json_object, a_file)\r\n",
        "    a_file.close()"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746717345
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"araelectra-base-discriminator\"\r\n",
        "arabert_prep = ArabertPreprocessor(model_name=model_name)\r\n",
        "fix_ids('Data/AAQAD-train.json')\r\n",
        "fix_ids('Data/AAQAD-dev.json')\r\n",
        "fix_ids('Data/AAQAD-test.json')\r\n",
        "aqad_train_contexts, aqad_train_questions, aqad_train_answers,aqad_train_plausible, aqad_train_ids = Read_AAQAD('Data/AAQAD-train.json', arabert_prep)\r\n",
        "aqad_val_contexts, aqad_val_questions, aqad_val_answers,aqad_val_plausible, aqad_val_ids = Read_AAQAD('Data/AAQAD-dev.json', arabert_prep)\r\n",
        "aqad_test_contexts, aqad_test_questions, aqad_test_answers,aqad_test_plausible, aqad_test_ids = Read_AAQAD('Data/AAQAD-test.json', arabert_prep)\r\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746736418
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answered_feat(contexts, questions, answers, plausible):\r\n",
        "    new_contexts, new_questions, new_answers = [], [], []\r\n",
        "    for i in range(len(answers)):\r\n",
        "        if plausible[i] == False:\r\n",
        "            new_contexts.append(contexts[i])\r\n",
        "            new_questions.append(questions[i])\r\n",
        "            new_answers.append(answers[i])\r\n",
        "    return new_contexts, new_questions, new_answers\r\n",
        "span_train_contexts, span_train_questions, span_train_answers = get_answered_feat(aqad_train_contexts, aqad_train_questions, aqad_train_answers, aqad_train_plausible)   "
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746736812
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(span_train_contexts), len(span_train_questions))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "8045 8045\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746737145
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the tokenizer\r\n",
        "model_name = model_name = \"aubmindlab/araelectra-base-discriminator\"\r\n",
        "araelectra_tokenizer = AutoTokenizer.from_pretrained(model_name,do_lower_case=False)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746737613
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = araelectra_tokenizer(aqad_train_questions, aqad_train_contexts, truncation=True)\r\n",
        "span_train_encodings = araelectra_tokenizer(span_train_questions, span_train_contexts, truncation=True)\r\n",
        "val_encodings = araelectra_tokenizer(aqad_val_questions, aqad_val_contexts, truncation=True)\r\n",
        "test_encodings = araelectra_tokenizer(aqad_test_questions, aqad_test_contexts,truncation= True)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746740531
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def index_to_token_position(encodings , answers):\r\n",
        "  start_positions = list()\r\n",
        "  end_positions = list()\r\n",
        "  for i in range(len(answers)):\r\n",
        "    start_positions.append(encodings.char_to_token(i, answers[i]['answer_start'], 1))\r\n",
        "    end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'], 1))\r\n",
        "    #if context truncated\r\n",
        "    if start_positions[-1] is None: \r\n",
        "      start_positions[-1] = araelectra_tokenizer.model_max_length\r\n",
        "    #if end index is space\r\n",
        "    itt = 1\r\n",
        "    while end_positions[-1] is None: \r\n",
        "      end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end']-itt, 1)\r\n",
        "      itt = itt + 1 \r\n",
        "  encodings.update({'start_positions': torch.tensor(start_positions), 'end_positions': torch.tensor(end_positions)})\r\n",
        "  encodings['start_positions'] = encodings['start_positions'].view(len(answers), 1)\r\n",
        "  encodings['end_positions'] = encodings['end_positions'].view(len(answers), 1)"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746740819
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_token_position(span_train_encodings, span_train_answers)\r\n",
        "index_to_token_position(val_encodings, aqad_val_answers)\r\n",
        "index_to_token_position(test_encodings, aqad_test_answers)"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746741115
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_weights_labels_tensors(encodings, plausible):\r\n",
        "  plausible = torch.tensor(plausible)\r\n",
        "  weights = torch.zeros(plausible.shape)\r\n",
        "  no_ans = torch.ones(plausible.shape)\r\n",
        "  weights[plausible==False]=1.0\r\n",
        "  no_ans[plausible==False]=0.0\r\n",
        "  weights = weights.view(-1,1)\r\n",
        "  no_ans = no_ans.view(-1,1)\r\n",
        "  encodings.update({'weights':weights, 'no_ans':no_ans})"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746741571
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "add_weights_labels_tensors(train_encodings, aqad_train_plausible)\r\n",
        "add_weights_labels_tensors(val_encodings, aqad_val_plausible)\r\n",
        "add_weights_labels_tensors(test_encodings, aqad_test_plausible)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746741860
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_encodings['IDs'] = aqad_val_ids\r\n",
        "test_encodings['IDs'] = aqad_test_ids"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746742209
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_encodings.keys())\r\n",
        "print(val_encodings.keys())\r\n",
        "print(test_encodings.keys())\r\n",
        "print(span_train_encodings.keys())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'weights', 'no_ans'])\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions', 'weights', 'no_ans', 'IDs'])\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions', 'weights', 'no_ans', 'IDs'])\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746742552
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset and DataLoader"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from tqdm import tqdm"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746830743
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AqadDataset(torch.utils.data.Dataset):\r\n",
        "    def __init__(self, encodings):\r\n",
        "        self.encodings = encodings\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        return {key: val[idx] for key, val in self.encodings.items()}\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.encodings.input_ids)\r\n",
        "\r\n",
        "cls_train_dataset = AqadDataset(train_encodings)\r\n",
        "span_train_dataset = AqadDataset(span_train_encodings)\r\n",
        "val_dataset = AqadDataset(val_encodings)\r\n",
        "test_dataset = AqadDataset(test_encodings)"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746831122
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(araelectra_tokenizer)"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746831881
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls_train_loader = DataLoader(cls_train_dataset, batch_size=8, shuffle= True, collate_fn= data_collator)\r\n",
        "span_train_loader = DataLoader(span_train_dataset, batch_size=8, shuffle= True, collate_fn = data_collator)\r\n",
        "val_loader = DataLoader(val_dataset, batch_size = 8, shuffle = True, collate_fn = data_collator)\r\n",
        "test_loader = DataLoader(test_dataset, batch_size = 8, shuffle = True, collate_fn = data_collator)\r\n"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746832407
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checkpoints"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\r\n",
        "    \"\"\"\r\n",
        "    state: checkpoint to save\r\n",
        "    is_best: is this the best checkpoint; min validation loss\r\n",
        "    checkpoint_path: path to save checkpoint\r\n",
        "    best_model_path: path to save best checkpoint\r\n",
        "    \"\"\"\r\n",
        "    f_path = checkpoint_path\r\n",
        "    # save checkpoint data to the path given, checkpoint_path\r\n",
        "    torch.save(state, f_path)\r\n",
        "    # if it is a best model, min validation loss\r\n",
        "    if is_best:\r\n",
        "        best_fpath = best_model_path\r\n",
        "        # copy that checkpoint file to best path given, best_model_path\r\n",
        "        shutil.copyfile(f_path, best_fpath)"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746833664
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer):\r\n",
        "    \"\"\"\r\n",
        "    checkpoint_path: path to saved checkpoint\r\n",
        "    model: model to load checkpoint parameters into       \r\n",
        "    optimizer: optimizer defined in previous training\r\n",
        "    \"\"\"\r\n",
        "    # load check point\r\n",
        "    checkpoint = torch.load(checkpoint_fpath)\r\n",
        "    # initialize state_dict from checkpoint to model\r\n",
        "    model.load_state_dict(checkpoint['state_dict'])\r\n",
        "    # initialize optimizer from checkpoint to optimizer\r\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\r\n",
        "    # initialize valid_loss_min from checkpoint to valid_loss_min\r\n",
        "    results = checkpoint['result_dict']\r\n",
        "    # return model, optimizer, epoch value, min validation loss \r\n",
        "    return model, optimizer, checkpoint['epoch'], results"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746834053
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def order_exp(base_path, exp_name):\r\n",
        "  exp_path = os.path.join(base_path, exp_name)\r\n",
        "  if not os.path.exists(exp_path):\r\n",
        "    os.mkdir(exp_path)\r\n",
        "  curr_ckp_path = os.path.join(exp_path,'curr.pt')\r\n",
        "  best_ckp_path = os.path.join(exp_path, 'best.pt')\r\n",
        "  return curr_ckp_path, best_ckp_path, exp_path"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746834609
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification train and evaluation "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cls_eval(model, data_loader, exp_path, train_loss):\r\n",
        "    model.eval()\r\n",
        "    total_acc = 0\r\n",
        "    for batch in data_loader:\r\n",
        "      tokens = batch['input_ids'].to(device)\r\n",
        "      masks = batch['attention_mask'].to(device)\r\n",
        "      tokens_type = batch['token_type_ids'].to(device)\r\n",
        "      gt_no_ans = batch['no_ans'].to(device)\r\n",
        "      output = model(tokens, masks, tokens_type)\r\n",
        "      pred = output.logits.view(masks.shape[0],2,)\r\n",
        "      pred = torch.argmax(pred, dim=1)\r\n",
        "      target = batch['no_ans'].to(device).view(masks.shape[0],)\r\n",
        "      total_acc += torch.sum(target==pred)\r\n",
        "    total_acc = total_acc/ val_dataset.__len__()\r\n",
        "    res_dict = {'acc':total_acc.item()*100, 'train_loss':train_loss}\r\n",
        "    if exp_path:\r\n",
        "        log_path = os.path.join(exp_path,'res.csv')\r\n",
        "        if not os.path.exists(log_path):\r\n",
        "            with open(log_path,'w') as f:\r\n",
        "                writer = csv.DictWriter(f, fieldnames=res_dict.keys())\r\n",
        "                writer.writeheader()\r\n",
        "        with open(log_path, 'a') as f:\r\n",
        "            writer = csv.DictWriter(f, fieldnames=res_dict.keys())\r\n",
        "            #writer.writeheader()\r\n",
        "            writer.writerow(res_dict)\r\n",
        "    return res_dict\r\n"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746836783
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cls_train(model,start_epoch, num_epochs, optimizer,max_acc, train_loader, val_loader, log, exp_name):\r\n",
        "  curr_ckp_path, best_ckp_path, exp_path = order_exp('Runs/AraElectra_abstain/train', exp_name)\r\n",
        "  model.train()\r\n",
        "  for epoch in range(start_epoch,num_epochs):\r\n",
        "    total_loss = 0.0\r\n",
        "    loop = tqdm(train_loader, leave=True)\r\n",
        "    for batch_idx, batch in enumerate(loop):\r\n",
        "      tokens = batch['input_ids'].to(device)\r\n",
        "      masks = batch['attention_mask'].to(device)\r\n",
        "      tokens_type = batch['token_type_ids'].to(device)\r\n",
        "      output = model(tokens, masks, tokens_type)\r\n",
        "      pred = output.logits.view(masks.shape[0],2,)\r\n",
        "      target = batch['no_ans'].type(torch.LongTensor)\r\n",
        "      target = target.to(device)\r\n",
        "      loss = cls_criterion(pred, target.view(masks.shape[0],))\r\n",
        "      loss.backward()\r\n",
        "      optimizer.step()\r\n",
        "      optimizer.zero_grad()\r\n",
        "      total_loss = total_loss + ((1 / (batch_idx + 1)) * (loss.item() - total_loss)) \r\n",
        "      loop.set_description(f'Epoch {epoch}')\r\n",
        "      loop.set_postfix(loss=loss.item())\r\n",
        "\r\n",
        "    result_dict = cls_eval(model, val_loader,exp_path,total_loss )\r\n",
        "    checkpoint = {\r\n",
        "            'epoch': epoch + 1,\r\n",
        "            'result_dict':result_dict,\r\n",
        "            'state_dict': model.state_dict(),\r\n",
        "            'optimizer': optimizer.state_dict(),\r\n",
        "        }\r\n",
        "    curr_acc = result_dict['acc']\r\n",
        "    if curr_acc>=max_acc:\r\n",
        "      max_acc = curr_acc\r\n",
        "      save_ckp(checkpoint, True, curr_ckp_path, best_ckp_path)\r\n",
        "    else:\r\n",
        "      save_ckp(checkpoint, False, curr_ckp_path, best_ckp_path)\r\n",
        "    print(result_dict)\r\n",
        "  return model\r\n"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746844269
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Cls_AraElectra = ElectraForSequenceClassification.from_pretrained(model_name, num_labels=2)\r\n",
        "QA_AraElectra = ElectraForQuestionAnswering.from_pretrained(model_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of the model checkpoint at aubmindlab/araelectra-base-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of ElectraForSequenceClassification were not initialized from the model checkpoint at aubmindlab/araelectra-base-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of the model checkpoint at aubmindlab/araelectra-base-discriminator were not used when initializing ElectraForQuestionAnswering: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n- This IS expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at aubmindlab/araelectra-base-discriminator and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746889352
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze(Electra, count=None):\r\n",
        "    if count is not None:\r\n",
        "\t      # We freeze here the embeddings of the model\r\n",
        "        #for param in Electra.embeddings.parameters():\r\n",
        "        #    param.requires_grad = False\r\n",
        "\r\n",
        "        if count != -1:\r\n",
        "\t          # if freeze_layer_count == -1, we only freeze the embedding layer\r\n",
        "\t          # otherwise we freeze the first `freeze_layer_count` encoder layers\r\n",
        "            for layer in Electra.encoder.layer[:count]:\r\n",
        "                for param in layer.parameters():\r\n",
        "                    param.requires_grad = False\r\n",
        "    print(sum(p.numel() for p in Electra.parameters()), sum(p.numel() for p in Electra.parameters() if p.requires_grad))"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746898657
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freeze(Cls_AraElectra.electra,4)\r\n",
        "freeze(QA_AraElectra.electra, 4)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "134602752 106251264\n134602752 106251264\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746899782
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Training"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\r\n",
        "learning_rate = 3e-5\r\n",
        "optimizer = torch.optim.Adam(Cls_AraElectra.parameters(), lr=learning_rate)\r\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "#criterion_span = nn.CrossEntropyLoss(reduction='none')\r\n",
        "cls_criterion = nn.CrossEntropyLoss()\r\n",
        "Cls_AraElectra.to(device)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "ElectraForSequenceClassification(\n  (electra): ElectraModel(\n    (embeddings): ElectraEmbeddings(\n      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): ElectraEncoder(\n      (layer): ModuleList(\n        (0): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): ElectraClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646746956324
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls_trained_model = cls_train(Cls_AraElectra, 0, 2, optimizer, 0, cls_train_loader, val_loader , True, 'first')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Epoch 0:  25%|██▍       | 393/1579 [05:39<13:41,  1.44it/s, loss=0.727]"
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646672196774
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Cls Model if needed"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls_model = ElectraForSequenceClassification.from_pretrained(model_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 3e-5\r\n",
        "optimizer = torch.optim.AdamW(cls_model.parameters(), lr=learning_rate)\r\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "#criterion_span = nn.CrossEntropyLoss(reduction='none')\r\n",
        "#cls_criterion = nn.CrossEntropyLoss()\r\n",
        "cls_model.to(device)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls_model, optimizer, start_epoch, result_dict = load_ckp('Runs/AraElectraCls/train/first/best.pt', cls_model, optimizer)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Span Training"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_raw_preds(data_loader, model, cls_model): \r\n",
        "  model.eval()\r\n",
        "  with torch.no_grad():\r\n",
        "    #F1 = EM = Total = 0\r\n",
        "    total_loss = 0.0\r\n",
        "    total_predictions = dict()\r\n",
        "    no_probs_pred = dict()\r\n",
        "    soft = torch.nn.Softmax(dim=1)\r\n",
        "    #loop = tqdm(data_loader)\r\n",
        "    #loop = tqdm(data_loader, leave=True)\r\n",
        "    for batch_idx, batch in enumerate(data_loader):\r\n",
        "      #moving tensors to gpu    \r\n",
        "      tokens = batch['input_ids'].to(device)\r\n",
        "      masks = batch['attention_mask'].to(device)\r\n",
        "      tokens_type = batch['token_type_ids'].to(device)\r\n",
        "      gt_start = batch['start_positions'].to(device)\r\n",
        "      gt_end = batch['end_positions'].to(device)\r\n",
        "      weights = batch['weights'].view(-1,1).to(device)\r\n",
        "      gt_no_ans = batch['no_ans'].to(device)\r\n",
        "      IDs = batch['IDs'].to(device)\r\n",
        "      outputs = model(tokens, masks, tokens_type, start_positions=gt_start, end_positions=gt_end)\r\n",
        "      no_probs = cls_model(tokens, masks, tokens_type)\r\n",
        "      no_probs = soft(no_probs.logits)\r\n",
        "      #calculating loss\r\n",
        "      loss = outputs.loss\r\n",
        "      #update average total loss \r\n",
        "      total_loss = total_loss + ((1 / (batch_idx + 1)) * (loss.item() - total_loss)) \r\n",
        "      #calculating f1 score and EM\r\n",
        "      curr_batch_size = tokens.shape[0]\r\n",
        "      #print(curr_batch_size)\r\n",
        "      #print(outputs.start_logits.shape)\r\n",
        "      #print(no_probs.logits.shape)\r\n",
        "      for i in range(curr_batch_size):\r\n",
        "        #print(f\"this is tensor index {i}\")\r\n",
        "        start_pred, end_pred= torch.argmax(outputs.start_logits[i], dim=0), torch.argmax(outputs.end_logits[i], dim = 0)\r\n",
        "        #print(start_pred.shape, end_pred.shape)\r\n",
        "        #print(start_pred)\r\n",
        "        #print(start_pred, end_pred)\r\n",
        "        total_predictions[str(IDs[i].item())] = araelectra_tokenizer.decode(tokens[i][start_pred.item():end_pred.item()], skip_special_tokens=True, clean_up_tokenization_spaces=True)\r\n",
        "        no_probs_pred[str(IDs[i].item())] = no_probs.logits[i][1].item()\r\n",
        "    #saving evaluation results\r\n",
        "    #evaluation\r\n",
        "\r\n",
        "    model.train()\r\n",
        "    return total_predictions, no_probs_pred"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646675634794
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_preds(total_preds, no_probs_preds,data_path, log_path):\r\n",
        "    preds_path = os.path.join(log_path, 'preds')\r\n",
        "    if not os.path.exists(preds_path):\r\n",
        "        os.mkdir(preds_path)\r\n",
        "    no_probs_path = os.path.join(preds_path, 'na_probs.json')\r\n",
        "    text_preds_path = os.path.join(preds_path, 'preds.json')\r\n",
        "    jsonString = json.dumps(total_preds)\r\n",
        "    jsonFile = open(text_preds_path, \"w\")\r\n",
        "    jsonFile.write(jsonString)\r\n",
        "    jsonFile.close()\r\n",
        "    jsonString = json.dumps(no_probs_preds)\r\n",
        "    jsonFile = open(no_probs_path, \"w\")\r\n",
        "    jsonFile.write(jsonString)\r\n",
        "    jsonFile.close()\r\n",
        "    #!python evaluatev2.py data_path text_preds_path electra --na-prob-file no_probs_path --na-prob-thresh 0.4 --out-file log_path\r\n",
        "    os.system(f\"python evaluatev2.py {data_path} {text_preds_path} electra --na-prob-file {no_probs_path} --na-prob-thresh 0.5 --out-file {log_path}\")\r\n",
        "    with open(os.path.join(log_path, 'res.csv')) as f:\r\n",
        "        DictReader_obj = csv.DictReader(f)\r\n",
        "        lastrow = None\r\n",
        "        for item in DictReader_obj:\r\n",
        "            lastrow = dict(item)\r\n",
        "    #print(lastrow)\r\n",
        "    return lastrow\r\n"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646675385922
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def span_train(model,start_epoch, num_epochs, optimizer,max_compined_metric, train_loader, val_loader, log, exp_name):\r\n",
        "  curr_ckp_path, best_ckp_path, exp_path = order_exp('Runs/AraElectra_abstain/train', exp_name)\r\n",
        "  model.train()\r\n",
        "  for epoch in range(start_epoch,num_epochs):\r\n",
        "    total_loss = 0.0\r\n",
        "    loop = tqdm(train_loader, leave=True)\r\n",
        "    for batch_idx, batch in enumerate(loop):\r\n",
        "      tokens = batch['input_ids'].to(device)\r\n",
        "      masks = batch['attention_mask'].to(device)\r\n",
        "      tokens_type = batch['token_type_ids'].to(device)\r\n",
        "      gt_start = batch['start_positions'].to(device)\r\n",
        "      gt_end = batch['end_positions'].to(device)\r\n",
        "      outputs = model(tokens, masks, tokens_type, start_positions=gt_start, end_positions=gt_end)\r\n",
        "      loss = outputs.loss\r\n",
        "      loss.backward()\r\n",
        "      optimizer.step()\r\n",
        "      optimizer.zero_grad()\r\n",
        "      total_loss = total_loss + ((1 / (batch_idx + 1)) * (loss.item() - total_loss)) \r\n",
        "      loop.set_description(f'Epoch {epoch}')\r\n",
        "      loop.set_postfix(loss=loss.item())\r\n",
        "\r\n",
        "    total_preds, no_probs_preds = get_raw_preds(val_loader, model)\r\n",
        "    result_dict = get_preds(total_preds, no_probs_preds,'Data/AAQAD-dev.json',exp_path )\r\n",
        "    checkpoint = {\r\n",
        "            'epoch': epoch + 1,\r\n",
        "            'result_dict':result_dict,\r\n",
        "            'state_dict': model.state_dict(),\r\n",
        "            'optimizer': optimizer.state_dict(),\r\n",
        "        }\r\n",
        "    curr_compined_metric = float(result_dict['exact'])+1.5*float(result_dict['f1'])\r\n",
        "    if curr_compined_metric>=max_compined_metric:\r\n",
        "      max_compined_metric = curr_compined_metric\r\n",
        "      save_ckp(checkpoint, True, curr_ckp_path, best_ckp_path)\r\n",
        "    else:\r\n",
        "      save_ckp(checkpoint, False, curr_ckp_path, best_ckp_path)\r\n",
        "    print(result_dict)\r\n",
        "  return model\r\n"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646675386917
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "span_num_epochs = 2\r\n",
        "span_learning_rate = 3e-5\r\n",
        "span_optimizer = torch.optim.AdamW(QA_AraElectra.parameters(), lr=span_learning_rate)\r\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "#criterion_span = nn.CrossEntropyLoss(reduction='none')\r\n",
        "#cls_criterion = nn.CrossEntropyLoss()\r\n",
        "QA_AraElectra.to(device)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": "ElectraForQuestionAnswering(\n  (electra): ElectraModel(\n    (embeddings): ElectraEmbeddings(\n      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): ElectraEncoder(\n      (layer): ModuleList(\n        (0): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646675397693
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = get_raw_preds(val_loader, QA_AraElectra, Cls_AraElectra)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "torch.Size([8, 232])\ntorch.Size([8, 2])\ntensor(74, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(113, device='cuda:0')\ntensor(206, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(46, device='cuda:0')\ntorch.Size([8, 301])\ntorch.Size([8, 2])\ntensor(19, device='cuda:0')\ntensor(39, device='cuda:0')\ntensor(60, device='cuda:0')\ntensor(5, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(272, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(18, device='cuda:0')\ntorch.Size([8, 221])\ntorch.Size([8, 2])\ntensor(45, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(28, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(5, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(45, device='cuda:0')\ntorch.Size([8, 191])\ntorch.Size([8, 2])\ntensor(20, device='cuda:0')\ntensor(45, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(166, device='cuda:0')\ntensor(5, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(19, device='cuda:0')\ntorch.Size([8, 146])\ntorch.Size([8, 2])\ntensor(47, device='cuda:0')\ntensor(74, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(9, device='cuda:0')\ntorch.Size([8, 204])\ntorch.Size([8, 2])\ntensor(20, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(74, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(21, device='cuda:0')\ntorch.Size([8, 314])\ntorch.Size([8, 2])\ntensor(20, device='cuda:0')\ntensor(53, device='cuda:0')\ntensor(44, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(59, device='cuda:0')\ntensor(22, device='cuda:0')\ntorch.Size([8, 247])\ntorch.Size([8, 2])\ntensor(49, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(50, device='cuda:0')\ntensor(103, device='cuda:0')\ntorch.Size([8, 169])\ntorch.Size([8, 2])\ntensor(12, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(45, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(57, device='cuda:0')\ntorch.Size([8, 276])\ntorch.Size([8, 2])\ntensor(24, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(6, device='cuda:0')\ntensor(49, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(53, device='cuda:0')\ntensor(15, device='cuda:0')\ntorch.Size([8, 297])\ntorch.Size([8, 2])\ntensor(20, device='cuda:0')\ntensor(3, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(17, device='cuda:0')\ntorch.Size([8, 131])\ntorch.Size([8, 2])\ntensor(46, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(5, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(32, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(41, device='cuda:0')\ntorch.Size([8, 441])\ntorch.Size([8, 2])\ntensor(26, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(87, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(49, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(37, device='cuda:0')\ntensor(27, device='cuda:0')\ntorch.Size([8, 512])\ntorch.Size([8, 2])\ntensor(20, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(54, device='cuda:0')\ntensor(3, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(47, device='cuda:0')\ntorch.Size([8, 273])\ntorch.Size([8, 2])\ntensor(22, device='cuda:0')\ntensor(10, device='cuda:0')\ntensor(61, device='cuda:0')\ntensor(53, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(198, device='cuda:0')\ntensor(17, device='cuda:0')\ntorch.Size([8, 252])\ntorch.Size([8, 2])\ntensor(102, device='cuda:0')\ntensor(45, device='cuda:0')\ntensor(55, device='cuda:0')\ntensor(32, device='cuda:0')\ntensor(61, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(21, device='cuda:0')\ntorch.Size([8, 246])\ntorch.Size([8, 2])\ntensor(50, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(8, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(16, device='cuda:0')\ntorch.Size([8, 291])\ntorch.Size([8, 2])\ntensor(46, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(62, device='cuda:0')\ntensor(59, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(8, device='cuda:0')\ntorch.Size([8, 274])\ntorch.Size([8, 2])\ntensor(47, device='cuda:0')\ntensor(69, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(27, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(115, device='cuda:0')\ntorch.Size([8, 165])\ntorch.Size([8, 2])\ntensor(20, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(107, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(7, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(15, device='cuda:0')\ntorch.Size([8, 169])\ntorch.Size([8, 2])\ntensor(45, device='cuda:0')\ntensor(28, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(55, device='cuda:0')\ntensor(55, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(110, device='cuda:0')\ntorch.Size([8, 297])\ntorch.Size([8, 2])\ntensor(19, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(5, device='cuda:0')\ntensor(42, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(53, device='cuda:0')\ntensor(18, device='cuda:0')\ntorch.Size([8, 300])\ntorch.Size([8, 2])\ntensor(105, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(54, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(56, device='cuda:0')\ntensor(10, device='cuda:0')\ntensor(21, device='cuda:0')\ntorch.Size([8, 439])\ntorch.Size([8, 2])\ntensor(18, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(8, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(32, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(1, device='cuda:0')\ntorch.Size([8, 306])\ntorch.Size([8, 2])\ntensor(15, device='cuda:0')\ntensor(27, device='cuda:0')\ntensor(202, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(62, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(15, device='cuda:0')\ntorch.Size([8, 153])\ntorch.Size([8, 2])\ntensor(47, device='cuda:0')\ntensor(53, device='cuda:0')\ntensor(65, device='cuda:0')\ntensor(62, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(4, device='cuda:0')\ntensor(19, device='cuda:0')\ntorch.Size([8, 147])\ntorch.Size([8, 2])\ntensor(17, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(64, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(16, device='cuda:0')\ntorch.Size([8, 142])\ntorch.Size([8, 2])\ntensor(64, device='cuda:0')\ntensor(62, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(4, device='cuda:0')\ntorch.Size([8, 200])\ntorch.Size([8, 2])\ntensor(27, device='cuda:0')\ntensor(55, device='cuda:0')\ntensor(56, device='cuda:0')\ntensor(60, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(8, device='cuda:0')\ntensor(20, device='cuda:0')\ntorch.Size([8, 181])\ntorch.Size([8, 2])\ntensor(22, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(67, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(35, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(28, device='cuda:0')\ntorch.Size([8, 404])\ntorch.Size([8, 2])\ntensor(19, device='cuda:0')\ntensor(77, device='cuda:0')\ntensor(55, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(6, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(39, device='cuda:0')\ntorch.Size([8, 247])\ntorch.Size([8, 2])\ntensor(18, device='cuda:0')\ntensor(64, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(54, device='cuda:0')\ntensor(50, device='cuda:0')\ntorch.Size([8, 238])\ntorch.Size([8, 2])\ntensor(2, device='cuda:0')\ntensor(77, device='cuda:0')\ntensor(139, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(11, device='cuda:0')\ntorch.Size([8, 231])\ntorch.Size([8, 2])\ntensor(78, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(29, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(21, device='cuda:0')\ntorch.Size([8, 510])\ntorch.Size([8, 2])\ntensor(36, device='cuda:0')\ntensor(40, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(65, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(29, device='cuda:0')\ntensor(1, device='cuda:0')\ntorch.Size([8, 194])\ntorch.Size([8, 2])\ntensor(23, device='cuda:0')\ntensor(75, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(60, device='cuda:0')\ntensor(50, device='cuda:0')\ntensor(70, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(49, device='cuda:0')\ntorch.Size([8, 441])\ntorch.Size([8, 2])\ntensor(14, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(30, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(4, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(265, device='cuda:0')\ntorch.Size([8, 338])\ntorch.Size([8, 2])\ntensor(241, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(35, device='cuda:0')\ntensor(5, device='cuda:0')\ntensor(43, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(73, device='cuda:0')\ntorch.Size([8, 163])\ntorch.Size([8, 2])\ntensor(37, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(16, device='cuda:0')\ntorch.Size([8, 190])\ntorch.Size([8, 2])\ntensor(24, device='cuda:0')\ntensor(75, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(73, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(27, device='cuda:0')\ntorch.Size([8, 448])\ntorch.Size([8, 2])\ntensor(19, device='cuda:0')\ntensor(188, device='cuda:0')\ntensor(202, device='cuda:0')\ntensor(136, device='cuda:0')\ntensor(72, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(60, device='cuda:0')\ntensor(22, device='cuda:0')\ntorch.Size([8, 220])\ntorch.Size([8, 2])\ntensor(38, device='cuda:0')\ntensor(174, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(30, device='cuda:0')\ntensor(80, device='cuda:0')\ntensor(72, device='cuda:0')\ntensor(27, device='cuda:0')\ntorch.Size([8, 248])\ntorch.Size([8, 2])\ntensor(22, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(48, device='cuda:0')\ntensor(64, device='cuda:0')\ntensor(67, device='cuda:0')\ntensor(11, device='cuda:0')\ntorch.Size([8, 255])\ntorch.Size([8, 2])\ntensor(40, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(5, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(18, device='cuda:0')\ntorch.Size([8, 199])\ntorch.Size([8, 2])\ntensor(112, device='cuda:0')\ntensor(3, device='cuda:0')\ntensor(27, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(49, device='cuda:0')\ntensor(56, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(57, device='cuda:0')\ntorch.Size([8, 434])\ntorch.Size([8, 2])\ntensor(23, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(173, device='cuda:0')\ntensor(63, device='cuda:0')\ntensor(29, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(30, device='cuda:0')\ntorch.Size([8, 338])\ntorch.Size([8, 2])\ntensor(22, device='cuda:0')\ntensor(241, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(90, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(24, device='cuda:0')\ntorch.Size([8, 172])\ntorch.Size([8, 2])\ntensor(38, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(86, device='cuda:0')\ntensor(5, device='cuda:0')\ntensor(11, device='cuda:0')\ntorch.Size([8, 292])\ntorch.Size([8, 2])\ntensor(2, device='cuda:0')\ntensor(57, device='cuda:0')\ntensor(63, device='cuda:0')\ntensor(60, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(1, device='cuda:0')\ntorch.Size([8, 175])\ntorch.Size([8, 2])\ntensor(21, device='cuda:0')\ntensor(66, device='cuda:0')\ntensor(53, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(51, device='cuda:0')\ntensor(86, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(41, device='cuda:0')\ntorch.Size([8, 365])\ntorch.Size([8, 2])\ntensor(20, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(204, device='cuda:0')\ntensor(36, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(22, device='cuda:0')\ntorch.Size([8, 236])\ntorch.Size([8, 2])\ntensor(11, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(44, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(77, device='cuda:0')\ntorch.Size([8, 171])\ntorch.Size([8, 2])\ntensor(24, device='cuda:0')\ntensor(48, device='cuda:0')\ntensor(29, device='cuda:0')\ntensor(44, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(60, device='cuda:0')\ntorch.Size([8, 448])\ntorch.Size([8, 2])\ntensor(188, device='cuda:0')\ntensor(78, device='cuda:0')\ntensor(80, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(4, device='cuda:0')\ntorch.Size([8, 251])\ntorch.Size([8, 2])\ntensor(1, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(31, device='cuda:0')\ntensor(28, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(18, device='cuda:0')\ntorch.Size([8, 345])\ntorch.Size([8, 2])\ntensor(26, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(1, device='cuda:0')\ntorch.Size([8, 314])\ntorch.Size([8, 2])\ntensor(22, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(56, device='cuda:0')\ntensor(199, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(17, device='cuda:0')\ntorch.Size([8, 241])\ntorch.Size([8, 2])\ntensor(29, device='cuda:0')\ntensor(57, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(235, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(27, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(38, device='cuda:0')\ntorch.Size([8, 290])\ntorch.Size([8, 2])\ntensor(1, device='cuda:0')\ntensor(53, device='cuda:0')\ntensor(49, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(5, device='cuda:0')\ntensor(38, device='cuda:0')\ntorch.Size([8, 161])\ntorch.Size([8, 2])\ntensor(61, device='cuda:0')\ntensor(73, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(22, device='cuda:0')\ntorch.Size([8, 375])\ntorch.Size([8, 2])\ntensor(1, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(40, device='cuda:0')\ntorch.Size([8, 199])\ntorch.Size([8, 2])\ntensor(21, device='cuda:0')\ntensor(29, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(18, device='cuda:0')\ntorch.Size([8, 290])\ntorch.Size([8, 2])\ntensor(41, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(70, device='cuda:0')\ntensor(60, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(20, device='cuda:0')\ntorch.Size([8, 247])\ntorch.Size([8, 2])\ntensor(22, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(32, device='cuda:0')\ntensor(28, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(54, device='cuda:0')\ntorch.Size([8, 295])\ntorch.Size([8, 2])\ntensor(17, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(164, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(40, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(19, device='cuda:0')\ntorch.Size([8, 139])\ntorch.Size([8, 2])\ntensor(27, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(31, device='cuda:0')\ntensor(28, device='cuda:0')\ntorch.Size([8, 241])\ntorch.Size([8, 2])\ntensor(18, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(48, device='cuda:0')\ntensor(65, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(77, device='cuda:0')\ntensor(24, device='cuda:0')\ntorch.Size([8, 219])\ntorch.Size([8, 2])\ntensor(42, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(42, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(176, device='cuda:0')\ntorch.Size([8, 245])\ntorch.Size([8, 2])\ntensor(28, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(80, device='cuda:0')\ntensor(51, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(69, device='cuda:0')\ntorch.Size([8, 374])\ntorch.Size([8, 2])\ntensor(11, device='cuda:0')\ntensor(51, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(5, device='cuda:0')\ntensor(4, device='cuda:0')\ntensor(28, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(31, device='cuda:0')\ntorch.Size([8, 170])\ntorch.Size([8, 2])\ntensor(61, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(79, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(12, device='cuda:0')\ntorch.Size([8, 248])\ntorch.Size([8, 2])\ntensor(28, device='cuda:0')\ntensor(30, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(18, device='cuda:0')\ntorch.Size([8, 223])\ntorch.Size([8, 2])\ntensor(1, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(32, device='cuda:0')\ntensor(5, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(29, device='cuda:0')\ntensor(32, device='cuda:0')\ntorch.Size([8, 342])\ntorch.Size([8, 2])\ntensor(27, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(79, device='cuda:0')\ntensor(77, device='cuda:0')\ntorch.Size([8, 208])\ntorch.Size([8, 2])\ntensor(28, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(27, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(80, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(23, device='cuda:0')\ntorch.Size([8, 163])\ntorch.Size([8, 2])\ntensor(21, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(31, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(54, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(46, device='cuda:0')\ntorch.Size([8, 213])\ntorch.Size([8, 2])\ntensor(25, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(49, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(13, device='cuda:0')\ntorch.Size([8, 359])\ntorch.Size([8, 2])\ntensor(69, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(20, device='cuda:0')\ntorch.Size([8, 395])\ntorch.Size([8, 2])\ntensor(24, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(7, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(54, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(30, device='cuda:0')\ntorch.Size([8, 189])\ntorch.Size([8, 2])\ntensor(29, device='cuda:0')\ntensor(63, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(8, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(51, device='cuda:0')\ntensor(17, device='cuda:0')\ntorch.Size([8, 297])\ntorch.Size([8, 2])\ntensor(21, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(80, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(50, device='cuda:0')\ntensor(77, device='cuda:0')\ntensor(20, device='cuda:0')\ntorch.Size([8, 306])\ntorch.Size([8, 2])\ntensor(44, device='cuda:0')\ntensor(239, device='cuda:0')\ntensor(49, device='cuda:0')\ntensor(107, device='cuda:0')\ntensor(176, device='cuda:0')\ntensor(48, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(223, device='cuda:0')\ntorch.Size([8, 255])\ntorch.Size([8, 2])\ntensor(27, device='cuda:0')\ntensor(28, device='cuda:0')\ntensor(8, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(28, device='cuda:0')\ntensor(74, device='cuda:0')\ntensor(18, device='cuda:0')\ntorch.Size([8, 256])\ntorch.Size([8, 2])\ntensor(39, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(49, device='cuda:0')\ntensor(37, device='cuda:0')\ntensor(35, device='cuda:0')\ntensor(42, device='cuda:0')\ntensor(25, device='cuda:0')\ntorch.Size([8, 293])\ntorch.Size([8, 2])\ntensor(1, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(54, device='cuda:0')\ntensor(112, device='cuda:0')\ntensor(15, device='cuda:0')\ntorch.Size([8, 141])\ntorch.Size([8, 2])\ntensor(26, device='cuda:0')\ntensor(75, device='cuda:0')\ntensor(58, device='cuda:0')\ntensor(71, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(61, device='cuda:0')\ntensor(53, device='cuda:0')\ntorch.Size([8, 512])\ntorch.Size([8, 2])\ntensor(47, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(48, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(16, device='cuda:0')\ntorch.Size([8, 408])\ntorch.Size([8, 2])\ntensor(1, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(59, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(18, device='cuda:0')\ntorch.Size([8, 304])\ntorch.Size([8, 2])\ntensor(13, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(268, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(29, device='cuda:0')\ntorch.Size([8, 248])\ntorch.Size([8, 2])\ntensor(47, device='cuda:0')\ntensor(28, device='cuda:0')\ntensor(55, device='cuda:0')\ntensor(44, device='cuda:0')\ntensor(74, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(49, device='cuda:0')\ntensor(19, device='cuda:0')\ntorch.Size([8, 306])\ntorch.Size([8, 2])\ntensor(17, device='cuda:0')\ntensor(7, device='cuda:0')\ntensor(28, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(48, device='cuda:0')\ntensor(270, device='cuda:0')\ntensor(198, device='cuda:0')\ntorch.Size([8, 250])\ntorch.Size([8, 2])\ntensor(12, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(32, device='cuda:0')\ntensor(6, device='cuda:0')\ntensor(72, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(18, device='cuda:0')\ntorch.Size([8, 214])\ntorch.Size([8, 2])\ntensor(49, device='cuda:0')\ntensor(5, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(35, device='cuda:0')\ntorch.Size([8, 172])\ntorch.Size([8, 2])\ntensor(3, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(70, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(27, device='cuda:0')\ntensor(13, device='cuda:0')\ntorch.Size([8, 126])\ntorch.Size([8, 2])\ntensor(40, device='cuda:0')\ntensor(45, device='cuda:0')\ntensor(67, device='cuda:0')\ntensor(9, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(4, device='cuda:0')\ntensor(55, device='cuda:0')\ntensor(15, device='cuda:0')\ntorch.Size([8, 199])\ntorch.Size([8, 2])\ntensor(15, device='cuda:0')\ntensor(181, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(43, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(59, device='cuda:0')\ntorch.Size([8, 127])\ntorch.Size([8, 2])\ntensor(47, device='cuda:0')\ntensor(56, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(8, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(1, device='cuda:0')\ntorch.Size([8, 199])\ntorch.Size([8, 2])\ntensor(24, device='cuda:0')\ntensor(63, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(103, device='cuda:0')\ntensor(143, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(37, device='cuda:0')\ntorch.Size([8, 270])\ntorch.Size([8, 2])\ntensor(22, device='cuda:0')\ntensor(79, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(61, device='cuda:0')\ntensor(14, device='cuda:0')\ntorch.Size([8, 445])\ntorch.Size([8, 2])\ntensor(23, device='cuda:0')\ntensor(111, device='cuda:0')\ntensor(239, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(236, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(14, device='cuda:0')\ntorch.Size([8, 148])\ntorch.Size([8, 2])\ntensor(14, device='cuda:0')\ntensor(60, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(10, device='cuda:0')\ntensor(6, device='cuda:0')\ntensor(16, device='cuda:0')\ntorch.Size([8, 316])\ntorch.Size([8, 2])\ntensor(32, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(35, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(16, device='cuda:0')\ntorch.Size([8, 301])\ntorch.Size([8, 2])\ntensor(272, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(55, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(14, device='cuda:0')\ntorch.Size([8, 235])\ntorch.Size([8, 2])\ntensor(20, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(54, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(43, device='cuda:0')\ntorch.Size([8, 312])\ntorch.Size([8, 2])\ntensor(55, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(4, device='cuda:0')\ntensor(9, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(49, device='cuda:0')\ntensor(43, device='cuda:0')\ntensor(20, device='cuda:0')\ntorch.Size([8, 309])\ntorch.Size([8, 2])\ntensor(9, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(44, device='cuda:0')\ntorch.Size([8, 363])\ntorch.Size([8, 2])\ntensor(1, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(56, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(30, device='cuda:0')\ntensor(30, device='cuda:0')\ntensor(7, device='cuda:0')\ntorch.Size([8, 223])\ntorch.Size([8, 2])\ntensor(45, device='cuda:0')\ntensor(78, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(40, device='cuda:0')\ntensor(47, device='cuda:0')\ntorch.Size([8, 147])\ntorch.Size([8, 2])\ntensor(21, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(11, device='cuda:0')\ntorch.Size([8, 212])\ntorch.Size([8, 2])\ntensor(16, device='cuda:0')\ntensor(7, device='cuda:0')\ntensor(48, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(54, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(19, device='cuda:0')\ntorch.Size([8, 160])\ntorch.Size([8, 2])\ntensor(11, device='cuda:0')\ntensor(49, device='cuda:0')\ntensor(32, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(1, device='cuda:0')\ntorch.Size([8, 296])\ntorch.Size([8, 2])\ntensor(20, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(10, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(24, device='cuda:0')\ntorch.Size([8, 187])\ntorch.Size([8, 2])\ntensor(15, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(21, device='cuda:0')\ntorch.Size([8, 307])\ntorch.Size([8, 2])\ntensor(20, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(48, device='cuda:0')\ntensor(53, device='cuda:0')\ntensor(7, device='cuda:0')\ntensor(45, device='cuda:0')\ntensor(203, device='cuda:0')\ntorch.Size([8, 195])\ntorch.Size([8, 2])\ntensor(51, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(90, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(139, device='cuda:0')\ntensor(57, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(19, device='cuda:0')\ntorch.Size([8, 129])\ntorch.Size([8, 2])\ntensor(17, device='cuda:0')\ntensor(43, device='cuda:0')\ntensor(10, device='cuda:0')\ntensor(44, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(36, device='cuda:0')\ntensor(37, device='cuda:0')\ntorch.Size([8, 137])\ntorch.Size([8, 2])\ntensor(21, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(44, device='cuda:0')\ntensor(3, device='cuda:0')\ntensor(74, device='cuda:0')\ntensor(57, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(21, device='cuda:0')\ntorch.Size([8, 186])\ntorch.Size([8, 2])\ntensor(14, device='cuda:0')\ntensor(50, device='cuda:0')\ntensor(29, device='cuda:0')\ntensor(56, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(34, device='cuda:0')\ntensor(19, device='cuda:0')\ntorch.Size([8, 305])\ntorch.Size([8, 2])\ntensor(269, device='cuda:0')\ntensor(45, device='cuda:0')\ntensor(56, device='cuda:0')\ntensor(201, device='cuda:0')\ntensor(48, device='cuda:0')\ntensor(4, device='cuda:0')\ntensor(5, device='cuda:0')\ntensor(7, device='cuda:0')\ntorch.Size([8, 245])\ntorch.Size([8, 2])\ntensor(18, device='cuda:0')\ntensor(107, device='cuda:0')\ntensor(43, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(49, device='cuda:0')\ntensor(16, device='cuda:0')\ntorch.Size([8, 512])\ntorch.Size([8, 2])\ntensor(8, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(40, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(4, device='cuda:0')\ntensor(7, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(22, device='cuda:0')\ntorch.Size([8, 246])\ntorch.Size([8, 2])\ntensor(18, device='cuda:0')\ntensor(30, device='cuda:0')\ntensor(45, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(28, device='cuda:0')\ntorch.Size([8, 249])\ntorch.Size([8, 2])\ntensor(17, device='cuda:0')\ntensor(27, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(7, device='cuda:0')\ntensor(62, device='cuda:0')\ntensor(72, device='cuda:0')\ntensor(20, device='cuda:0')\ntorch.Size([8, 290])\ntorch.Size([8, 2])\ntensor(17, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(243, device='cuda:0')\ntensor(131, device='cuda:0')\ntensor(29, device='cuda:0')\ntorch.Size([8, 152])\ntorch.Size([8, 2])\ntensor(15, device='cuda:0')\ntensor(63, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(42, device='cuda:0')\ntorch.Size([8, 304])\ntorch.Size([8, 2])\ntensor(12, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(78, device='cuda:0')\ntensor(39, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(43, device='cuda:0')\ntensor(25, device='cuda:0')\ntorch.Size([8, 236])\ntorch.Size([8, 2])\ntensor(32, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(47, device='cuda:0')\ntorch.Size([8, 444])\ntorch.Size([8, 2])\ntensor(18, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(31, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(238, device='cuda:0')\ntensor(66, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(3, device='cuda:0')\ntorch.Size([8, 136])\ntorch.Size([8, 2])\ntensor(46, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(45, device='cuda:0')\ntensor(57, device='cuda:0')\ntorch.Size([8, 184])\ntorch.Size([8, 2])\ntensor(49, device='cuda:0')\ntensor(72, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(10, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(70, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(108, device='cuda:0')\ntorch.Size([8, 295])\ntorch.Size([8, 2])\ntensor(20, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(44, device='cuda:0')\ntensor(28, device='cuda:0')\ntensor(248, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(23, device='cuda:0')\ntorch.Size([8, 512])\ntorch.Size([8, 2])\ntensor(22, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(43, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(48, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(32, device='cuda:0')\ntorch.Size([8, 341])\ntorch.Size([8, 2])\ntensor(23, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(6, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(140, device='cuda:0')\ntensor(48, device='cuda:0')\ntensor(50, device='cuda:0')\ntorch.Size([8, 215])\ntorch.Size([8, 2])\ntensor(19, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(63, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(42, device='cuda:0')\ntensor(60, device='cuda:0')\ntensor(65, device='cuda:0')\ntensor(24, device='cuda:0')\ntorch.Size([8, 210])\ntorch.Size([8, 2])\ntensor(59, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(5, device='cuda:0')\ntensor(28, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(56, device='cuda:0')\ntensor(79, device='cuda:0')\ntensor(17, device='cuda:0')\ntorch.Size([8, 208])\ntorch.Size([8, 2])\ntensor(47, device='cuda:0')\ntensor(48, device='cuda:0')\ntensor(50, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(81, device='cuda:0')\ntensor(2, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(20, device='cuda:0')\ntorch.Size([8, 250])\ntorch.Size([8, 2])\ntensor(12, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(14, device='cuda:0')\ntorch.Size([8, 311])\ntorch.Size([8, 2])\ntensor(200, device='cuda:0')\ntensor(42, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(62, device='cuda:0')\ntensor(9, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(68, device='cuda:0')\ntorch.Size([8, 181])\ntorch.Size([8, 2])\ntensor(1, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(40, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(27, device='cuda:0')\ntensor(19, device='cuda:0')\ntorch.Size([8, 171])\ntorch.Size([8, 2])\ntensor(22, device='cuda:0')\ntensor(88, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(3, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(3, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(13, device='cuda:0')\ntorch.Size([8, 197])\ntorch.Size([8, 2])\ntensor(77, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(54, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(23, device='cuda:0')\ntorch.Size([8, 245])\ntorch.Size([8, 2])\ntensor(28, device='cuda:0')\ntensor(31, device='cuda:0')\ntensor(63, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(43, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(20, device='cuda:0')\ntorch.Size([8, 186])\ntorch.Size([8, 2])\ntensor(23, device='cuda:0')\ntensor(165, device='cuda:0')\ntensor(59, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(6, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(12, device='cuda:0')\ntorch.Size([8, 172])\ntorch.Size([8, 2])\ntensor(21, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(10, device='cuda:0')\ntorch.Size([8, 187])\ntorch.Size([8, 2])\ntensor(63, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(36, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(49, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(13, device='cuda:0')\ntorch.Size([8, 192])\ntorch.Size([8, 2])\ntensor(22, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(54, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(33, device='cuda:0')\ntensor(53, device='cuda:0')\ntorch.Size([8, 436])\ntorch.Size([8, 2])\ntensor(21, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(32, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(211, device='cuda:0')\ntensor(80, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(13, device='cuda:0')\ntorch.Size([8, 216])\ntorch.Size([8, 2])\ntensor(75, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(10, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(12, device='cuda:0')\ntorch.Size([8, 445])\ntorch.Size([8, 2])\ntensor(239, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(40, device='cuda:0')\ntensor(55, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(1, device='cuda:0')\ntorch.Size([8, 191])\ntorch.Size([8, 2])\ntensor(23, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(70, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(36, device='cuda:0')\ntensor(13, device='cuda:0')\ntorch.Size([8, 166])\ntorch.Size([8, 2])\ntensor(12, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(65, device='cuda:0')\ntorch.Size([8, 185])\ntorch.Size([8, 2])\ntensor(19, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(70, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(9, device='cuda:0')\ntorch.Size([8, 292])\ntorch.Size([8, 2])\ntensor(13, device='cuda:0')\ntensor(42, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(23, device='cuda:0')\ntorch.Size([8, 198])\ntorch.Size([8, 2])\ntensor(20, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(71, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(49, device='cuda:0')\ntorch.Size([8, 182])\ntorch.Size([8, 2])\ntensor(22, device='cuda:0')\ntensor(48, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(49, device='cuda:0')\ntensor(29, device='cuda:0')\ntensor(32, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(14, device='cuda:0')\ntorch.Size([8, 512])\ntorch.Size([8, 2])\ntensor(1, device='cuda:0')\ntensor(76, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(29, device='cuda:0')\ntensor(40, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(49, device='cuda:0')\ntorch.Size([8, 248])\ntorch.Size([8, 2])\ntensor(13, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(37, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(36, device='cuda:0')\ntorch.Size([8, 184])\ntorch.Size([8, 2])\ntensor(13, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(44, device='cuda:0')\ntensor(78, device='cuda:0')\ntensor(49, device='cuda:0')\ntensor(20, device='cuda:0')\ntorch.Size([8, 251])\ntorch.Size([8, 2])\ntensor(37, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(28, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(20, device='cuda:0')\ntorch.Size([8, 188])\ntorch.Size([8, 2])\ntensor(19, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(2, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(29, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(20, device='cuda:0')\ntorch.Size([8, 189])\ntorch.Size([8, 2])\ntensor(45, device='cuda:0')\ntensor(40, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(9, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(64, device='cuda:0')\ntorch.Size([8, 296])\ntorch.Size([8, 2])\ntensor(1, device='cuda:0')\ntensor(8, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(27, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(31, device='cuda:0')\ntensor(63, device='cuda:0')\ntorch.Size([8, 289])\ntorch.Size([8, 2])\ntensor(6, device='cuda:0')\ntensor(242, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(23, device='cuda:0')\ntorch.Size([8, 143])\ntorch.Size([8, 2])\ntensor(16, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(29, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(73, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(61, device='cuda:0')\ntorch.Size([8, 361])\ntorch.Size([8, 2])\ntensor(54, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(79, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(16, device='cuda:0')\ntorch.Size([8, 160])\ntorch.Size([8, 2])\ntensor(14, device='cuda:0')\ntensor(42, device='cuda:0')\ntensor(8, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(42, device='cuda:0')\ntensor(8, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(19, device='cuda:0')\ntorch.Size([8, 233])\ntorch.Size([8, 2])\ntensor(50, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(201, device='cuda:0')\ntensor(42, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(24, device='cuda:0')\ntorch.Size([8, 181])\ntorch.Size([8, 2])\ntensor(65, device='cuda:0')\ntensor(51, device='cuda:0')\ntensor(9, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(67, device='cuda:0')\ntensor(42, device='cuda:0')\ntensor(20, device='cuda:0')\ntorch.Size([8, 377])\ntorch.Size([8, 2])\ntensor(16, device='cuda:0')\ntensor(272, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(48, device='cuda:0')\ntensor(71, device='cuda:0')\ntensor(27, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(41, device='cuda:0')\ntorch.Size([8, 512])\ntorch.Size([8, 2])\ntensor(74, device='cuda:0')\ntensor(49, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(6, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(23, device='cuda:0')\ntorch.Size([8, 512])\ntorch.Size([8, 2])\ntensor(20, device='cuda:0')\ntensor(72, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(43, device='cuda:0')\ntensor(71, device='cuda:0')\ntensor(42, device='cuda:0')\ntorch.Size([8, 250])\ntorch.Size([8, 2])\ntensor(24, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(49, device='cuda:0')\ntensor(43, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(17, device='cuda:0')\ntorch.Size([8, 306])\ntorch.Size([8, 2])\ntensor(27, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(58, device='cuda:0')\ntensor(53, device='cuda:0')\ntensor(84, device='cuda:0')\ntensor(12, device='cuda:0')\ntorch.Size([8, 146])\ntorch.Size([8, 2])\ntensor(18, device='cuda:0')\ntensor(44, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(77, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(144, device='cuda:0')\ntensor(36, device='cuda:0')\ntorch.Size([8, 270])\ntorch.Size([8, 2])\ntensor(1, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(31, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(30, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(10, device='cuda:0')\ntorch.Size([8, 512])\ntorch.Size([8, 2])\ntensor(17, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(36, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(6, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(82, device='cuda:0')\ntorch.Size([8, 213])\ntorch.Size([8, 2])\ntensor(211, device='cuda:0')\ntensor(8, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(33, device='cuda:0')\ntensor(30, device='cuda:0')\ntensor(17, device='cuda:0')\ntorch.Size([8, 172])\ntorch.Size([8, 2])\ntensor(1, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(57, device='cuda:0')\ntensor(28, device='cuda:0')\ntorch.Size([8, 203])\ntorch.Size([8, 2])\ntensor(27, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(33, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(6, device='cuda:0')\ntorch.Size([8, 450])\ntorch.Size([8, 2])\ntensor(27, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(48, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(21, device='cuda:0')\ntorch.Size([8, 190])\ntorch.Size([8, 2])\ntensor(21, device='cuda:0')\ntensor(29, device='cuda:0')\ntensor(64, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(50, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(4, device='cuda:0')\ntorch.Size([8, 193])\ntorch.Size([8, 2])\ntensor(18, device='cuda:0')\ntensor(175, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(30, device='cuda:0')\ntensor(39, device='cuda:0')\ntensor(50, device='cuda:0')\ntorch.Size([8, 163])\ntorch.Size([8, 2])\ntensor(63, device='cuda:0')\ntensor(61, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(55, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(59, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(1, device='cuda:0')\ntorch.Size([8, 448])\ntorch.Size([8, 2])\ntensor(74, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(28, device='cuda:0')\ntensor(188, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(57, device='cuda:0')\ntorch.Size([8, 136])\ntorch.Size([8, 2])\ntensor(23, device='cuda:0')\ntensor(72, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(78, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(20, device='cuda:0')\ntorch.Size([8, 311])\ntorch.Size([8, 2])\ntensor(109, device='cuda:0')\ntensor(207, device='cuda:0')\ntensor(42, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(28, device='cuda:0')\ntensor(19, device='cuda:0')\ntorch.Size([8, 366])\ntorch.Size([8, 2])\ntensor(30, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(76, device='cuda:0')\ntensor(205, device='cuda:0')\ntensor(66, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(22, device='cuda:0')\ntorch.Size([8, 291])\ntorch.Size([8, 2])\ntensor(64, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(38, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(65, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(5, device='cuda:0')\ntensor(32, device='cuda:0')\ntorch.Size([8, 150])\ntorch.Size([8, 2])\ntensor(55, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(77, device='cuda:0')\ntensor(27, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(62, device='cuda:0')\ntensor(74, device='cuda:0')\ntensor(19, device='cuda:0')\ntorch.Size([8, 141])\ntorch.Size([8, 2])\ntensor(12, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(33, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(108, device='cuda:0')\ntorch.Size([8, 218])\ntorch.Size([8, 2])\ntensor(15, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(102, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(37, device='cuda:0')\ntorch.Size([8, 243])\ntorch.Size([8, 2])\ntensor(28, device='cuda:0')\ntensor(80, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(50, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(44, device='cuda:0')\ntorch.Size([8, 283])\ntorch.Size([8, 2])\ntensor(20, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(56, device='cuda:0')\ntensor(30, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(68, device='cuda:0')\ntensor(236, device='cuda:0')\ntensor(108, device='cuda:0')\ntorch.Size([8, 220])\ntorch.Size([8, 2])\ntensor(25, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(49, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(42, device='cuda:0')\ntensor(174, device='cuda:0')\ntensor(23, device='cuda:0')\ntorch.Size([8, 443])\ntorch.Size([8, 2])\ntensor(15, device='cuda:0')\ntensor(35, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(238, device='cuda:0')\ntensor(51, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(10, device='cuda:0')\ntensor(211, device='cuda:0')\ntorch.Size([8, 184])\ntorch.Size([8, 2])\ntensor(23, device='cuda:0')\ntensor(45, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(54, device='cuda:0')\ntorch.Size([8, 170])\ntorch.Size([8, 2])\ntensor(51, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(7, device='cuda:0')\ntensor(35, device='cuda:0')\ntensor(50, device='cuda:0')\ntensor(40, device='cuda:0')\ntensor(1, device='cuda:0')\ntorch.Size([8, 274])\ntorch.Size([8, 2])\ntensor(19, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(54, device='cuda:0')\ntorch.Size([8, 406])\ntorch.Size([8, 2])\ntensor(22, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(27, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(35, device='cuda:0')\ntorch.Size([8, 195])\ntorch.Size([8, 2])\ntensor(47, device='cuda:0')\ntensor(31, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(75, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(19, device='cuda:0')\ntorch.Size([8, 239])\ntorch.Size([8, 2])\ntensor(1, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(27, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(32, device='cuda:0')\ntensor(67, device='cuda:0')\ntorch.Size([8, 269])\ntorch.Size([8, 2])\ntensor(13, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(39, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(20, device='cuda:0')\ntorch.Size([8, 142])\ntorch.Size([8, 2])\ntensor(20, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(39, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(33, device='cuda:0')\ntensor(20, device='cuda:0')\ntorch.Size([8, 236])\ntorch.Size([8, 2])\ntensor(32, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(50, device='cuda:0')\ntensor(19, device='cuda:0')\ntorch.Size([8, 167])\ntorch.Size([8, 2])\ntensor(4, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(85, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(109, device='cuda:0')\ntensor(24, device='cuda:0')\ntorch.Size([8, 150])\ntorch.Size([8, 2])\ntensor(44, device='cuda:0')\ntensor(106, device='cuda:0')\ntensor(62, device='cuda:0')\ntensor(32, device='cuda:0')\ntensor(37, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(25, device='cuda:0')\ntorch.Size([8, 165])\ntorch.Size([8, 2])\ntensor(112, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(5, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(30, device='cuda:0')\ntorch.Size([8, 151])\ntorch.Size([8, 2])\ntensor(13, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(43, device='cuda:0')\ntensor(28, device='cuda:0')\ntensor(43, device='cuda:0')\ntensor(53, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(15, device='cuda:0')\ntorch.Size([8, 249])\ntorch.Size([8, 2])\ntensor(20, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(37, device='cuda:0')\ntensor(35, device='cuda:0')\ntorch.Size([8, 150])\ntorch.Size([8, 2])\ntensor(22, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(3, device='cuda:0')\ntensor(18, device='cuda:0')\ntorch.Size([8, 161])\ntorch.Size([8, 2])\ntensor(10, device='cuda:0')\ntensor(29, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(4, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(28, device='cuda:0')\ntorch.Size([8, 170])\ntorch.Size([8, 2])\ntensor(5, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(35, device='cuda:0')\ntensor(66, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(49, device='cuda:0')\ntorch.Size([8, 319])\ntorch.Size([8, 2])\ntensor(20, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(33, device='cuda:0')\ntorch.Size([8, 235])\ntorch.Size([8, 2])\ntensor(15, device='cuda:0')\ntensor(87, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(29, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(15, device='cuda:0')\ntorch.Size([8, 304])\ntorch.Size([8, 2])\ntensor(23, device='cuda:0')\ntensor(44, device='cuda:0')\ntensor(55, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(74, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(202, device='cuda:0')\ntensor(12, device='cuda:0')\ntorch.Size([8, 270])\ntorch.Size([8, 2])\ntensor(26, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(47, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(45, device='cuda:0')\ntensor(20, device='cuda:0')\ntorch.Size([8, 445])\ntorch.Size([8, 2])\ntensor(24, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(50, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(69, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(239, device='cuda:0')\ntorch.Size([8, 371])\ntorch.Size([8, 2])\ntensor(269, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(45, device='cuda:0')\ntensor(268, device='cuda:0')\ntensor(85, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(39, device='cuda:0')\ntensor(22, device='cuda:0')\ntorch.Size([8, 160])\ntorch.Size([8, 2])\ntensor(1, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(45, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(4, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(19, device='cuda:0')\ntorch.Size([8, 147])\ntorch.Size([8, 2])\ntensor(20, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(64, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(40, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(78, device='cuda:0')\ntensor(16, device='cuda:0')\ntorch.Size([8, 164])\ntorch.Size([8, 2])\ntensor(24, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(6, device='cuda:0')\ntensor(54, device='cuda:0')\ntensor(87, device='cuda:0')\ntensor(22, device='cuda:0')\ntorch.Size([8, 185])\ntorch.Size([8, 2])\ntensor(25, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(70, device='cuda:0')\ntensor(53, device='cuda:0')\ntensor(4, device='cuda:0')\ntensor(45, device='cuda:0')\ntensor(25, device='cuda:0')\ntorch.Size([8, 248])\ntorch.Size([8, 2])\ntensor(28, device='cuda:0')\ntensor(55, device='cuda:0')\ntensor(8, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(37, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(11, device='cuda:0')\ntorch.Size([8, 169])\ntorch.Size([8, 2])\ntensor(43, device='cuda:0')\ntensor(28, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(10, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(26, device='cuda:0')\ntensor(20, device='cuda:0')\ntorch.Size([8, 453])\ntorch.Size([8, 2])\ntensor(12, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(193, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(63, device='cuda:0')\ntensor(4, device='cuda:0')\ntensor(78, device='cuda:0')\ntorch.Size([8, 175])\ntorch.Size([8, 2])\ntensor(23, device='cuda:0')\ntensor(49, device='cuda:0')\ntensor(58, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(75, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(5, device='cuda:0')\ntorch.Size([8, 159])\ntorch.Size([8, 2])\ntensor(22, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(45, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(1, device='cuda:0')\ntorch.Size([8, 157])\ntorch.Size([8, 2])\ntensor(69, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(75, device='cuda:0')\ntensor(9, device='cuda:0')\ntensor(86, device='cuda:0')\ntensor(37, device='cuda:0')\ntensor(25, device='cuda:0')\ntensor(14, device='cuda:0')\ntorch.Size([8, 270])\ntorch.Size([8, 2])\ntensor(38, device='cuda:0')\ntensor(51, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(43, device='cuda:0')\ntensor(34, device='cuda:0')\ntensor(24, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(47, device='cuda:0')\ntorch.Size([8, 447])\ntorch.Size([8, 2])\ntensor(133, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(198, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(18, device='cuda:0')\ntensor(23, device='cuda:0')\ntensor(33, device='cuda:0')\ntensor(23, device='cuda:0')\ntorch.Size([8, 188])\ntorch.Size([8, 2])\ntensor(21, device='cuda:0')\ntensor(45, device='cuda:0')\ntensor(3, device='cuda:0')\ntensor(15, device='cuda:0')\ntensor(13, device='cuda:0')\ntensor(10, device='cuda:0')\ntensor(22, device='cuda:0')\ntensor(26, device='cuda:0')\ntorch.Size([8, 189])\ntorch.Size([8, 2])\ntensor(14, device='cuda:0')\ntensor(5, device='cuda:0')\ntensor(29, device='cuda:0')\ntensor(74, device='cuda:0')\ntensor(27, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(28, device='cuda:0')\ntensor(40, device='cuda:0')\ntorch.Size([8, 185])\ntorch.Size([8, 2])\ntensor(87, device='cuda:0')\ntensor(20, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(85, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(15, device='cuda:0')\ntorch.Size([8, 184])\ntorch.Size([8, 2])\ntensor(40, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(108, device='cuda:0')\ntensor(69, device='cuda:0')\ntensor(3, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(28, device='cuda:0')\ntorch.Size([8, 212])\ntorch.Size([8, 2])\ntensor(80, device='cuda:0')\ntensor(52, device='cuda:0')\ntensor(43, device='cuda:0')\ntensor(55, device='cuda:0')\ntensor(31, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(19, device='cuda:0')\ntensor(11, device='cuda:0')\ntorch.Size([8, 372])\ntorch.Size([8, 2])\ntensor(21, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(9, device='cuda:0')\ntensor(22, device='cuda:0')\ntorch.Size([8, 181])\ntorch.Size([8, 2])\ntensor(17, device='cuda:0')\ntensor(59, device='cuda:0')\ntensor(8, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(7, device='cuda:0')\ntensor(23, device='cuda:0')\ntorch.Size([8, 379])\ntorch.Size([8, 2])\ntensor(11, device='cuda:0')\ntensor(17, device='cuda:0')\ntensor(16, device='cuda:0')\ntensor(1, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(49, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(46, device='cuda:0')\ntorch.Size([8, 373])\ntorch.Size([8, 2])\ntensor(18, device='cuda:0')\ntensor(44, device='cuda:0')\ntensor(63, device='cuda:0')\ntensor(41, device='cuda:0')\ntensor(50, device='cuda:0')\ntensor(21, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(37, device='cuda:0')\ntorch.Size([8, 255])\ntorch.Size([8, 2])\ntensor(49, device='cuda:0')\ntensor(46, device='cuda:0')\ntensor(14, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(11, device='cuda:0')\ntensor(32, device='cuda:0')\ntensor(8, device='cuda:0')\ntensor(46, device='cuda:0')\ntorch.Size([6, 310])\ntorch.Size([6, 2])\ntensor(14, device='cuda:0')\ntensor(51, device='cuda:0')\ntensor(12, device='cuda:0')\ntensor(10, device='cuda:0')\ntensor(10, device='cuda:0')\ntensor(38, device='cuda:0')\n"
        }
      ],
      "execution_count": 39,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646675779510
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}