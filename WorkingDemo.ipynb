{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import Required Packages"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "import shutil\r\n",
        "from collections import Counter\r\n",
        "import numpy as np\r\n",
        "import json\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from transformers import AutoTokenizer, ElectraForQuestionAnswering, DataCollatorWithPadding,BertModel, ElectraForSequenceClassification, ElectraModel\r\n",
        "from Preprocess.arabertpreprocess import ArabertPreprocessor\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import csv\r\n",
        "import random\r\n",
        "random.seed(1)\r\n",
        "torch.manual_seed(3407)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "<torch._C.Generator at 0x7f70099c0f90>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1650316825969
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load models"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_models():\r\n",
        "    def load_ckp(checkpoint_fpath, model, optimizer):\r\n",
        "        \"\"\"\r\n",
        "        checkpoint_path: path to saved checkpoint\r\n",
        "        model: model to load checkpoint parameters into       \r\n",
        "        optimizer: optimizer defined in previous training\r\n",
        "        \"\"\"\r\n",
        "        # load check point\r\n",
        "        checkpoint = torch.load(checkpoint_fpath)\r\n",
        "        # initialize state_dict from checkpoint to model\r\n",
        "        model.load_state_dict(checkpoint['state_dict'])\r\n",
        "        # initialize optimizer from checkpoint to optimizer\r\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\r\n",
        "        # initialize valid_loss_min from checkpoint to valid_loss_min\r\n",
        "        results = checkpoint['result_dict']\r\n",
        "        # return model, optimizer, epoch value, min validation loss \r\n",
        "        return model, optimizer, checkpoint['epoch'], results\r\n",
        "    model_name = model_name = \"aubmindlab/araelectra-base-discriminator\"\r\n",
        "    araelectra_tokenizer = AutoTokenizer.from_pretrained(model_name,do_lower_case=False) \r\n",
        "    Cls_AraElectra = ElectraForSequenceClassification.from_pretrained(model_name, num_labels=2)\r\n",
        "    QA_AraElectra = ElectraForQuestionAnswering.from_pretrained(model_name)\r\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "    learning_rate = 3e-5\r\n",
        "    optimizer = torch.optim.Adam(Cls_AraElectra.parameters(), lr=learning_rate)\r\n",
        "    cls_criterion = nn.CrossEntropyLoss()\r\n",
        "    Cls_AraElectra.to(device)\r\n",
        "    cls_model, optimizer, start_epoch, result_dict = load_ckp('Runs/AraElectraDecoupled/train/cls/first/best.pt', Cls_AraElectra, optimizer)\r\n",
        "    span_learning_rate = 3e-5\r\n",
        "    span_optimizer = torch.optim.AdamW(QA_AraElectra.parameters(), lr=span_learning_rate)\r\n",
        "    QA_AraElectra.to(device)\r\n",
        "    span_model, optimizer, start_epoch, result_dict = load_ckp('Runs/AraElectraDecoupled/train/span/first/best.pt', QA_AraElectra, optimizer)\r\n",
        "    return span_model, cls_model\r\n",
        "span_model, cls_model = load_models()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of the model checkpoint at aubmindlab/araelectra-base-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of ElectraForSequenceClassification were not initialized from the model checkpoint at aubmindlab/araelectra-base-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of the model checkpoint at aubmindlab/araelectra-base-discriminator were not used when initializing ElectraForQuestionAnswering: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n- This IS expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at aubmindlab/araelectra-base-discriminator and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1650316883645
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print Sample "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sample():\r\n",
        "    def add_end_index(answer, context):\r\n",
        "        ## 1 if span match the context 0 otherwise\r\n",
        "        text = answer['text']\r\n",
        "        start_idx = answer['answer_start']\r\n",
        "        end_idx = start_idx + len(text)\r\n",
        "        answer['answer_end'] = end_idx\r\n",
        "        if text == context[start_idx:end_idx]:\r\n",
        "            answer['answer_end'] = end_idx\r\n",
        "            return False\r\n",
        "        for i in range(1, 3):\r\n",
        "            if text == context[start_idx - i:end_idx - i]:\r\n",
        "                answer['answer_end'] = end_idx - 1\r\n",
        "                answer['answer_start'] = start_idx - 1\r\n",
        "                return False\r\n",
        "        return True\r\n",
        "\r\n",
        "    def arabert_preprocess(context, question, answer, arabert_prep):\r\n",
        "        answer['text'] = arabert_prep.preprocess(answer['text'])\r\n",
        "        context = arabert_prep.preprocess(context)\r\n",
        "        question = arabert_prep.preprocess(question)\r\n",
        "        res = context.find(answer['text'])\r\n",
        "        if res != -1:\r\n",
        "            answer['answer_start'] = res\r\n",
        "        return context, question, answer, res\r\n",
        "\r\n",
        "    def Read_AAQAD(path, arabert_prep):\r\n",
        "        contexts = []\r\n",
        "        answers = []\r\n",
        "        questions = []\r\n",
        "        IDs = []\r\n",
        "        plausible = []\r\n",
        "        cnt = 0\r\n",
        "        with open(path) as f:\r\n",
        "            aaqad_dict = json.load(f)\r\n",
        "            for article in aaqad_dict['data']:\r\n",
        "                for passage in article['paragraphs']:\r\n",
        "                    context = passage['context']\r\n",
        "                    for qa in passage['qas']:\r\n",
        "                        question = qa['question']\r\n",
        "                        if 'plausible_answers' in qa.keys():  # there is two cases if the question have no answer then use plausible answer\r\n",
        "                            access = 'plausible_answers'\r\n",
        "                            plausible.append(True)\r\n",
        "                        else:\r\n",
        "                            access = 'answers'\r\n",
        "                            plausible.append(False)\r\n",
        "                        for answer in qa[access]:\r\n",
        "                            context, question, answer, res = arabert_preprocess(context, question, answer, arabert_prep)\r\n",
        "                            # if res==-1:\r\n",
        "                            #  cnt+=1\r\n",
        "                            #  continue\r\n",
        "                            flag = add_end_index(answer, context)  # if false dont add the\r\n",
        "                            cnt = cnt + flag\r\n",
        "                            flag = False\r\n",
        "                            if not flag:\r\n",
        "                                contexts.append(context)\r\n",
        "                                answers.append(answer)\r\n",
        "                                questions.append(question)\r\n",
        "                                IDs.append(int(qa['id']))\r\n",
        "        return contexts, questions, answers, plausible, IDs\r\n",
        "\r\n",
        "    model_name = \"araelectra-base-discriminator\"\r\n",
        "    arabert_prep = ArabertPreprocessor(model_name=model_name)\r\n",
        "    aqad_test_contexts, aqad_test_questions, aqad_test_answers, aqad_test_plausible, aqad_test_ids = Read_AAQAD(\r\n",
        "        'Data/AAQAD-test.json', arabert_prep)\r\n",
        "    random.seed(3)\r\n",
        "    rand_idx = [random.randint(0, len(aqad_test_contexts)) for _ in range(2)]\r\n",
        "    rand_idx\r\n",
        "\r\n",
        "    # [974, 2427]\r\n",
        "    # plausible answer true means isimpossible True\r\n",
        "    def get_info(rand_idx):\r\n",
        "        contexts, questions, answers, plausible, IDs = [], [], [], [], []\r\n",
        "        for i, idx in enumerate(rand_idx):\r\n",
        "            print(\r\n",
        "                f'Sample {i + 1} \\nContext: {aqad_test_contexts[idx]} \\nQuestion: {aqad_test_questions[idx]} \\nIs Impossible to Answer? {aqad_test_plausible[idx]}')\r\n",
        "            print(\"---------------------------\")\r\n",
        "            contexts.append(aqad_test_contexts[idx])\r\n",
        "            questions.append(aqad_test_questions[idx])\r\n",
        "            answers.append(aqad_test_answers[idx])\r\n",
        "            plausible.append(aqad_test_plausible[idx])\r\n",
        "\r\n",
        "        return contexts, questions, answers, plausible, IDs\r\n",
        "\r\n",
        "    demo_contexts, demo_questions, demo_answers, demo_plausible, demo_IDs = get_info(rand_idx)\r\n",
        "    return demo_contexts, demo_questions \r\n",
        "#demo_contexts, demo_questions = get_sample()\r\n"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1650317275018
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Predictions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(demo_contexts, demo_questions, cls_model, span_model):\r\n",
        "    #Creating the tokenizer\r\n",
        "    model_name = model_name = \"aubmindlab/araelectra-base-discriminator\"\r\n",
        "    araelectra_tokenizer = AutoTokenizer.from_pretrained(model_name,do_lower_case=False)\r\n",
        "    demo_encodings = araelectra_tokenizer(demo_contexts, demo_questions, truncation=True, padding = True, return_tensors= 'pt')\r\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "    cls_model.eval()\r\n",
        "    span_model.eval()\r\n",
        "    soft = torch.nn.Softmax(dim=1)\r\n",
        "    tokens = demo_encodings['input_ids'].to(device)\r\n",
        "    masks = demo_encodings['attention_mask'].to(device)\r\n",
        "    tokens_type = demo_encodings['token_type_ids'].to(device)\r\n",
        "    outputs = span_model(tokens, masks, tokens_type)\r\n",
        "    no_probs = cls_model(tokens, masks, tokens_type)\r\n",
        "    no_probs = soft(no_probs.logits)\r\n",
        "    curr_batch_size = tokens.shape[0]\r\n",
        "      #print(curr_batch_size)\r\n",
        "      #print(outputs.start_logits.shape)\r\n",
        "      #print(no_probs.logits.shape)\r\n",
        "    for i in range(curr_batch_size):\r\n",
        "        #print(f\"this is tensor index {i}\")\r\n",
        "        start_pred, end_pred= torch.argmax(no_probs[i], dim=0), torch.argmax(no_probs[i], dim = 0)\r\n",
        "        #print(start_pred.shape, end_pred.shape)\r\n",
        "        #print(start_pred)\r\n",
        "        #print(start_pred, end_pred)\r\n",
        "        text_prediction = araelectra_tokenizer.decode(tokens[i][start_pred.item():end_pred.item()], skip_special_tokens=True, clean_up_tokenization_spaces=True)\r\n",
        "        probs_prediction = no_probs[i][1].item()\r\n",
        "        if probs_prediction>=0.5:\r\n",
        "            print(f'Sample {i+1} Prediction: \\nAnswer: Can not be answered with Confidence: {probs_prediction}')\r\n",
        "            print(\"---------------------------\")\r\n",
        "\r\n",
        "        else:\r\n",
        "            print(f'Sample {i+1} Prediction \\nAnswer: {text_prediction} with Confidence: {probs_prediction} with Start: {start_pred.item()} and End: {end_pred.item()}')\r\n",
        "            print(\"---------------------------\")\r\n"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1650317275404
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demo_contexts, demo_questions = get_sample()\r\n",
        "get_predictions(demo_contexts, demo_questions, cls_model, span_model)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Sample 1 \nContext: نقص الزنك له عواقب وخيمة على نمو الأطفال ، بحيث يؤدي إلى نقص في الطول و الإصابة بالتأخر النمو البنيوي ، فقد أظهرت دراسات للتدخلات التي أجريت في عدة بلدان وجود علاقة إيجابية بين توفير جرع الزنك المكملة والنمو الخطي لدى الأطفال . ويسبب نقصه أيضا مرض الإسهال و التهابات الجهاز التنفسي . \nQuestion: لماذا لا ينبغي أن يعطى الزنك بمفرده لأولئك الذين ليس لديهم أوجه قصور ؟ \nIs Impossible to Answer? True\n---------------------------\nSample 2 \nContext: في عام 1045 ، غزت الإمبراطورية البيزنطية أرمينيا . وبعدها بفترة قصيرة تلتها الدويلات الأخرى تحت السيطرة البيزنطية . لم يدم الحكم البيزنطي طويلا ، حيث انتصر السلاجقة في 1071 على البيزنطيين وسيطروا على أرمينيا في معركة ملاذكرد وأقاموا الإمبراطورية السلجوقية . هربا من الموت أو العبودية على يد أولئك الذين اغتالوا غاجيك الثاني ملك آني ، فر أحد أقاربه وهو أرمني يدعى روبن مع بعض أهل القرى إلى المضائق الجبلية في جبال طوروس ومن ثم إلى طرسوس في قيليقية . وفر لهم الحاكم البيزنطي مأوى في قصره حيث تأسست في نهاية المطاف مملكة قيليقية الأرمنية . كانت قيليقية حليفا قويا للصليبيين الأوروبيين واعتبرت نفسها حصنا للمسيحية في الشرق . يشهد أيضا لأهمية قيليقية في التاريخ والدولة الأرمنية نقل مقر الكاثوليكوس للكنيسة الأرمنية الرسولية وهو الزعيم الروحي للشعب الأرمني إلى المنطقة . سرعان ما بدأت الإمبراطورية السلجوقية في الانهيار . وفي أوائل القرن الثاني عشر أنشأ الأمراء الأرمن من الأسرة الزكرية إمارة أرمنية شبه مستقلة في أرمينيا الشمالية والشرقية عرفت باسم أرمينيا الزكرية واستمرت تحت رعاية من السلاجقة والمملكة الجورجية والأتابكة من أذربيجان والإمبراطورية الخوارزمية . تقاسمت عائلة الأوربليين النبيلة الحكم مع الزكريين في أجزاء مختلفة من البلاد ولا سيما في سيونيك وفايوتس دزور . \nQuestion: متى تغلب الأتراك السلاجقة على البيزنطيين ؟ \nIs Impossible to Answer? False\n---------------------------\nSample 1 Prediction: \nAnswer: Can not be answered with Confidence: 0.5032625794410706\n---------------------------\nSample 2 Prediction: \nAnswer: Can not be answered with Confidence: 0.5070127844810486\n---------------------------\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1650317284578
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}