{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "import shutil\r\n",
        "from collections import Counter\r\n",
        "import numpy as np\r\n",
        "import json\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from transformers import AutoTokenizer, ElectraForQuestionAnswering, DataCollatorWithPadding,BertModel, ElectraForSequenceClassification, ElectraModel\r\n",
        "from Preprocess.arabertpreprocess import ArabertPreprocessor\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import csv\r\n",
        "torch.manual_seed(3407)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "<torch._C.Generator at 0x7f3de9290130>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1652658848889
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_end_index(answer, context):\r\n",
        "  ## 1 if span match the context 0 otherwise\r\n",
        "  text = answer['text']\r\n",
        "  start_idx = answer['answer_start']\r\n",
        "  end_idx = start_idx + len(text)\r\n",
        "  answer['answer_end'] = end_idx\r\n",
        "  if text == context[start_idx:end_idx]:\r\n",
        "    answer['answer_end'] = end_idx\r\n",
        "    return False\r\n",
        "  for i in range(1,3):\r\n",
        "    if text == context[start_idx-i:end_idx-i]:\r\n",
        "      answer['answer_end']= end_idx-1\r\n",
        "      answer['answer_start'] = start_idx-1\r\n",
        "      return False\r\n",
        "  return True"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652658849093
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def arabert_preprocess(context,question, answer, arabert_prep):\r\n",
        "    answer['text'] = arabert_prep.preprocess(answer['text'])\r\n",
        "    context = arabert_prep.preprocess(context)\r\n",
        "    question = arabert_prep.preprocess(question)\r\n",
        "    res = context.find(answer['text'])\r\n",
        "    if res !=-1:\r\n",
        "        answer['answer_start'] = res\r\n",
        "    return context, question, answer, res"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652658849276
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Read_AAQAD(path,arabert_prep):\r\n",
        "  contexts =[]\r\n",
        "  answers =[]\r\n",
        "  questions =[]\r\n",
        "  IDs= []\r\n",
        "  plausible = []\r\n",
        "  cnt = 0\r\n",
        "  with open(path) as f:\r\n",
        "    aaqad_dict = json.load(f)\r\n",
        "    for article in aaqad_dict['data']:\r\n",
        "      for passage in article['paragraphs']:\r\n",
        "        context = passage['context']\r\n",
        "        for qa in passage['qas']:\r\n",
        "          question = qa['question']\r\n",
        "          if 'plausible_answers' in qa.keys():# there is two cases if the question have no answer then use plausible answer\r\n",
        "            access = 'plausible_answers'\r\n",
        "            plausible.append(True)\r\n",
        "          else:\r\n",
        "            access = 'answers'\r\n",
        "            plausible.append(False)\r\n",
        "          for answer in qa[access]:\r\n",
        "            context,question, answer, res =  arabert_preprocess(context,question, answer, arabert_prep)\r\n",
        "            #if res==-1:\r\n",
        "            #  cnt+=1\r\n",
        "            #  continue\r\n",
        "            flag = add_end_index(answer, context) #if false dont add the \r\n",
        "            cnt =cnt + flag\r\n",
        "            flag = False\r\n",
        "            if not flag:\r\n",
        "              contexts.append(context)\r\n",
        "              answers.append(answer)\r\n",
        "              questions.append(question)\r\n",
        "              IDs.append(int(qa['id']))\r\n",
        "  return contexts,questions,answers,plausible,IDs"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652658849457
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_ids(path):\r\n",
        "  #IDs need to be fixed for evaluating purposes\r\n",
        "    a_file = open(path, \"r\")\r\n",
        "    json_object = json.load(a_file)\r\n",
        "    a_file.close()\r\n",
        "    idx_cnt = 1\r\n",
        "    for article in json_object['data']:\r\n",
        "      for passage in article['paragraphs']:\r\n",
        "        context = passage['context']\r\n",
        "        for qa in passage['qas']:\r\n",
        "            qa['id'] = str(idx_cnt)\r\n",
        "            idx_cnt = idx_cnt + 1\r\n",
        "    a_file = open(path, \"w\")\r\n",
        "    json.dump(json_object, a_file)\r\n",
        "    a_file.close()"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652658849643
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"araelectra-base-discriminator\"\r\n",
        "arabert_prep = ArabertPreprocessor(model_name=model_name)\r\n",
        "fix_ids('Data/asquadv2-train.json')\r\n",
        "fix_ids('Data/asquadv2-val.json')\r\n",
        "fix_ids('Data/asquadv2-test.json')\r\n",
        "aqad_train_contexts, aqad_train_questions, aqad_train_answers,aqad_train_plausible, aqad_train_ids = Read_AAQAD('Data/asquadv2-train.json', arabert_prep)\r\n",
        "aqad_val_contexts, aqad_val_questions, aqad_val_answers,aqad_val_plausible, aqad_val_ids = Read_AAQAD('Data/asquadv2-val.json', arabert_prep)\r\n",
        "aqad_test_contexts, aqad_test_questions, aqad_test_answers,aqad_test_plausible, aqad_test_ids = Read_AAQAD('Data/asquadv2-test.json', arabert_prep)\r\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652658952868
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(aqad_train_ids)==len(aqad_train_ids)*(len(aqad_train_ids)+1)/2)\r\n",
        "print(sum(aqad_val_ids)==len(aqad_val_ids)*(len(aqad_val_ids)+1)/2)\r\n",
        "print(sum(aqad_test_ids)==len(aqad_test_ids)*(len(aqad_test_ids)+1)/2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "True\nTrue\nTrue\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652658953128
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answered_feat(contexts, questions, answers, plausible):\r\n",
        "    new_contexts, new_questions, new_answers = [], [], []\r\n",
        "    for i in range(len(answers)):\r\n",
        "        if plausible[i] == False:\r\n",
        "            new_contexts.append(contexts[i])\r\n",
        "            new_questions.append(questions[i])\r\n",
        "            new_answers.append(answers[i])\r\n",
        "    return new_contexts, new_questions, new_answers\r\n",
        "span_train_contexts, span_train_questions, span_train_answers = get_answered_feat(aqad_train_contexts, aqad_train_questions, aqad_train_answers, aqad_train_plausible)   "
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652658953327
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(span_train_contexts), len(aqad_train_contexts))\r\n",
        "print(sum(aqad_test_plausible))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "42042 76840\n4350\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659221894
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the tokenizer\r\n",
        "model_name = model_name = \"wissamantoun/araelectra-base-artydiqa\"\r\n",
        "araelectra_tokenizer = AutoTokenizer.from_pretrained(model_name,do_lower_case=False)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659235949
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = araelectra_tokenizer(aqad_train_questions, aqad_train_contexts, truncation = True )\r\n",
        "span_train_encodings = araelectra_tokenizer(span_train_questions, span_train_contexts, truncation=True)\r\n",
        "val_encodings = araelectra_tokenizer(aqad_val_questions, aqad_val_contexts, truncation=True, return_offsets_mapping=True)\r\n",
        "test_encodings = araelectra_tokenizer(aqad_test_questions, aqad_test_contexts, truncation=True,  return_offsets_mapping=True)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659258817
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_offset = val_encodings['offset_mapping']\r\n",
        "del val_encodings['offset_mapping']\r\n",
        "test_offset = test_encodings['offset_mapping']\r\n",
        "del test_encodings['offset_mapping']"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659258950
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_ids_to_idx = {k:i for i,k in enumerate(aqad_val_ids)}\r\n",
        "test_ids_to_idx = {k:i for i,k in enumerate(aqad_test_ids)}\r\n"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659259054
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def index_to_token_position(encodings , answers):\r\n",
        "  start_positions = list()\r\n",
        "  end_positions = list()\r\n",
        "  for i in range(len(answers)):\r\n",
        "    start_positions.append(encodings.char_to_token(i, answers[i]['answer_start'], 1))\r\n",
        "    end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'], 1))\r\n",
        "    #if context truncated\r\n",
        "    if start_positions[-1] is None: \r\n",
        "      start_positions[-1] = araelectra_tokenizer.model_max_length\r\n",
        "    #if end index is space\r\n",
        "    itt = 1\r\n",
        "    while end_positions[-1] is None: \r\n",
        "      end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end']-itt, 1)\r\n",
        "      itt = itt + 1 \r\n",
        "  encodings.update({'start_positions': torch.tensor(start_positions), 'end_positions': torch.tensor(end_positions)})\r\n",
        "  encodings['start_positions'] = encodings['start_positions'].view(len(answers), 1)\r\n",
        "  encodings['end_positions'] = encodings['end_positions'].view(len(answers), 1)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659259297
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_token_position(span_train_encodings, span_train_answers)\r\n",
        "index_to_token_position(val_encodings, aqad_val_answers)\r\n",
        "index_to_token_position(test_encodings, aqad_test_answers)"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659259415
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_weights_labels_tensors(encodings, plausible):\r\n",
        "  plausible = torch.tensor(plausible)\r\n",
        "  weights = torch.ones(plausible.shape)\r\n",
        "  no_ans = torch.ones(plausible.shape)\r\n",
        "  weights[plausible==False]=2.0\r\n",
        "  no_ans[plausible==False]=0.0\r\n",
        "  weights = weights.view(-1,1)\r\n",
        "  no_ans = no_ans.view(-1,1)\r\n",
        "  encodings.update({'weights':weights, 'no_ans':no_ans})"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659259524
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "add_weights_labels_tensors(train_encodings, aqad_train_plausible)\r\n",
        "add_weights_labels_tensors(val_encodings, aqad_val_plausible)\r\n",
        "add_weights_labels_tensors(test_encodings, aqad_test_plausible)"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659259636
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_encodings['IDs'] = aqad_val_ids\r\n",
        "test_encodings['IDs'] = aqad_test_ids"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659259746
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_encodings.keys())\r\n",
        "print(val_encodings.keys())\r\n",
        "print(test_encodings.keys())\r\n",
        "print(span_train_encodings.keys())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'weights', 'no_ans'])\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions', 'weights', 'no_ans', 'IDs'])\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions', 'weights', 'no_ans', 'IDs'])\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659259856
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset and DataLoader"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from tqdm import tqdm"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659259967
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AqadDataset(torch.utils.data.Dataset):\r\n",
        "    def __init__(self, encodings):\r\n",
        "        self.encodings = encodings\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        return {key: val[idx] for key, val in self.encodings.items()}\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.encodings.input_ids)\r\n",
        "\r\n",
        "cls_train_dataset = AqadDataset(train_encodings)\r\n",
        "span_train_dataset = AqadDataset(span_train_encodings)\r\n",
        "val_dataset = AqadDataset(val_encodings)\r\n",
        "test_dataset = AqadDataset(test_encodings)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659260083
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(araelectra_tokenizer)"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659260193
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls_train_loader = DataLoader(cls_train_dataset, batch_size=8, shuffle= True, collate_fn= data_collator)\r\n",
        "span_train_loader = DataLoader(span_train_dataset, batch_size=8, shuffle= True, collate_fn = data_collator)\r\n",
        "val_loader = DataLoader(val_dataset, batch_size = 8, shuffle = True, collate_fn = data_collator)\r\n",
        "test_loader = DataLoader(test_dataset, batch_size = 8, shuffle = True, collate_fn = data_collator)\r\n"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659260305
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checkpoints"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\r\n",
        "    \"\"\"\r\n",
        "    state: checkpoint to save\r\n",
        "    is_best: is this the best checkpoint; min validation loss\r\n",
        "    checkpoint_path: path to save checkpoint\r\n",
        "    best_model_path: path to save best checkpoint\r\n",
        "    \"\"\"\r\n",
        "    f_path = checkpoint_path\r\n",
        "    # save checkpoint data to the path given, checkpoint_path\r\n",
        "    torch.save(state, f_path)\r\n",
        "    # if it is a best model, min validation loss\r\n",
        "    if is_best:\r\n",
        "        best_fpath = best_model_path\r\n",
        "        # copy that checkpoint file to best path given, best_model_path\r\n",
        "        shutil.copyfile(f_path, best_fpath)"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659379297
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer):\r\n",
        "    \"\"\"\r\n",
        "    checkpoint_path: path to saved checkpoint\r\n",
        "    model: model to load checkpoint parameters into       \r\n",
        "    optimizer: optimizer defined in previous training\r\n",
        "    \"\"\"\r\n",
        "    # load check point\r\n",
        "    checkpoint = torch.load(checkpoint_fpath)\r\n",
        "    # initialize state_dict from checkpoint to model\r\n",
        "    model.load_state_dict(checkpoint['state_dict'])\r\n",
        "    # initialize optimizer from checkpoint to optimizer\r\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\r\n",
        "    # initialize valid_loss_min from checkpoint to valid_loss_min\r\n",
        "    results = checkpoint['result_dict']\r\n",
        "    # return model, optimizer, epoch value, min validation loss \r\n",
        "    return model, optimizer, checkpoint['epoch'], results"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659380222
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def order_exp(base_path, exp_name):\r\n",
        "  exp_path = os.path.join(base_path, exp_name)\r\n",
        "  if not os.path.exists(exp_path):\r\n",
        "    os.mkdir(exp_path)\r\n",
        "  curr_ckp_path = os.path.join(exp_path,'curr.pt')\r\n",
        "  best_ckp_path = os.path.join(exp_path, 'best.pt')\r\n",
        "  return curr_ckp_path, best_ckp_path, exp_path"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659381129
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification train and evaluation "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cls_eval(model, data_loader, exp_path, train_loss):\r\n",
        "    model.eval()\r\n",
        "    total_acc = 0\r\n",
        "    total_pred = None\r\n",
        "    total_IDs = None\r\n",
        "    soft = torch.nn.Softmax(dim=1)\r\n",
        "    for batch in data_loader:\r\n",
        "      tokens = batch['input_ids'].to(device)\r\n",
        "      masks = batch['attention_mask'].to(device)\r\n",
        "      tokens_type = batch['token_type_ids'].to(device)\r\n",
        "      IDs = batch['IDs'].to(device)\r\n",
        "      gt_no_ans = batch['no_ans'].to(device)\r\n",
        "      output = model(tokens, masks, tokens_type)\r\n",
        "      pred = output.logits.view(masks.shape[0],2,)\r\n",
        "      if total_pred is None:\r\n",
        "          total_pred = soft(pred)[:,1]\r\n",
        "          total_IDs = IDs\r\n",
        "      else:\r\n",
        "          total_pred = torch.cat((total_pred, soft(pred)[:,1]), 0)\r\n",
        "          total_IDs = torch.cat((total_IDs, IDs), 0)\r\n",
        "      pred = torch.argmax(pred, dim=1)\r\n",
        "      target = batch['no_ans'].to(device).view(masks.shape[0],)\r\n",
        "      total_acc += torch.sum(target==pred)\r\n",
        "\r\n",
        "    total_acc = total_acc/ val_dataset.__len__()\r\n",
        "    res_dict = {'acc':total_acc.item()*100, 'train_loss':train_loss}\r\n",
        "    if exp_path:\r\n",
        "        log_path = os.path.join(exp_path,'res.csv')\r\n",
        "        if not os.path.exists(log_path):\r\n",
        "            with open(log_path,'w') as f:\r\n",
        "                writer = csv.DictWriter(f, fieldnames=res_dict.keys())\r\n",
        "                writer.writeheader()\r\n",
        "        with open(log_path, 'a') as f:\r\n",
        "            writer = csv.DictWriter(f, fieldnames=res_dict.keys())\r\n",
        "            #writer.writeheader()\r\n",
        "            writer.writerow(res_dict)\r\n",
        "    return res_dict, {\"IDs\":total_IDs, \"preds\":total_pred}\r\n"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659386906
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cls_train(model,start_epoch, num_epochs, optimizer,max_acc, train_loader, val_loader, log, exp_name):\r\n",
        "  curr_ckp_path, best_ckp_path, exp_path = order_exp('Runs/AraElectraDecoupledAsquadv2/train/cls', exp_name)\r\n",
        "  model.train()\r\n",
        "  cls_pred = None\r\n",
        "  for epoch in range(start_epoch,num_epochs):\r\n",
        "    total_loss = 0.0\r\n",
        "    loop = tqdm(train_loader, leave=True)\r\n",
        "    for batch_idx, batch in enumerate(loop):\r\n",
        "      tokens = batch['input_ids'].to(device)\r\n",
        "      masks = batch['attention_mask'].to(device)\r\n",
        "      tokens_type = batch['token_type_ids'].to(device)\r\n",
        "      weights = batch['weights'].to(device)\r\n",
        "      output = model(tokens, masks, tokens_type)\r\n",
        "      pred = output.logits.view(masks.shape[0],2,)\r\n",
        "      target = batch['no_ans'].type(torch.LongTensor)\r\n",
        "      target = target.to(device)\r\n",
        "      loss = cls_criterion(pred, target.view(masks.shape[0],))\r\n",
        "      loss = loss*(weights.view(masks.shape[0],))\r\n",
        "      loss = torch.mean(loss)\r\n",
        "      loss.backward()\r\n",
        "      optimizer.step()\r\n",
        "      optimizer.zero_grad()\r\n",
        "      total_loss = total_loss + ((1 / (batch_idx + 1)) * (loss.item() - total_loss)) \r\n",
        "      loop.set_description(f'Epoch {epoch}')\r\n",
        "      loop.set_postfix(loss=loss.item())\r\n",
        "\r\n",
        "    result_dict, cls_pred = cls_eval(model, val_loader,exp_path,total_loss )\r\n",
        "    checkpoint = {\r\n",
        "            'epoch': epoch + 1,\r\n",
        "            'result_dict':result_dict,\r\n",
        "            'state_dict': model.state_dict(),\r\n",
        "            'optimizer': optimizer.state_dict(),\r\n",
        "        }\r\n",
        "    curr_acc = result_dict['acc']\r\n",
        "    if curr_acc>=max_acc:\r\n",
        "      max_acc = curr_acc\r\n",
        "      save_ckp(checkpoint, True, curr_ckp_path, best_ckp_path)\r\n",
        "    else:\r\n",
        "      save_ckp(checkpoint, False, curr_ckp_path, best_ckp_path)\r\n",
        "    print(result_dict)\r\n",
        "  return model, cls_pred\r\n"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659387886
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Cls_AraElectra = ElectraForSequenceClassification.from_pretrained(model_name, num_labels=2)\r\n",
        "QA_AraElectra = ElectraForQuestionAnswering.from_pretrained(model_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of the model checkpoint at wissamantoun/araelectra-base-artydiqa were not used when initializing ElectraForSequenceClassification: ['qa_outputs.weight', 'qa_outputs.bias']\n- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of ElectraForSequenceClassification were not initialized from the model checkpoint at wissamantoun/araelectra-base-artydiqa and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659401583
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze(Electra, count=None):\r\n",
        "    if count is not None:\r\n",
        "\t      # We freeze here the embeddings of the model\r\n",
        "        for param in Electra.embeddings.parameters():\r\n",
        "            param.requires_grad = False\r\n",
        "\r\n",
        "        if count != -1:\r\n",
        "\t          # if freeze_layer_count == -1, we only freeze the embedding layer\r\n",
        "\t          # otherwise we freeze the first `freeze_layer_count` encoder layers\r\n",
        "            for layer in Electra.encoder.layer[:count]:\r\n",
        "                for param in layer.parameters():\r\n",
        "                    param.requires_grad = False\r\n",
        "    print(sum(p.numel() for p in Electra.parameters()), sum(p.numel() for p in Electra.parameters() if p.requires_grad))"
      ],
      "outputs": [],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659628515
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freeze(Cls_AraElectra.electra,6)\r\n",
        "freeze(QA_AraElectra.electra, 6)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "134602752 42527232\n134602752 42527232\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652655298238
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Training"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\r\n",
        "learning_rate = 3e-5\r\n",
        "optimizer = torch.optim.Adam(Cls_AraElectra.parameters(), lr=learning_rate)\r\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "#criterion_span = nn.CrossEntropyLoss(reduction='none')\r\n",
        "cls_criterion = nn.CrossEntropyLoss(reduction='none')\r\n",
        "Cls_AraElectra.to(device)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": "ElectraForSequenceClassification(\n  (electra): ElectraModel(\n    (embeddings): ElectraEmbeddings(\n      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): ElectraEncoder(\n      (layer): ModuleList(\n        (0): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): ElectraClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652655310224
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls_trained_model, cls_pred = cls_train(Cls_AraElectra, 1, 2, optimizer, 0, cls_train_loader, val_loader , True, 'second')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Epoch 1: 100%|██████████| 9605/9605 [1:23:13<00:00,  1.92it/s, loss=0.831] \n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'acc': 82.08224773406982, 'train_loss': 0.48609214223793196}\n"
        }
      ],
      "execution_count": 46,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652554268172
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls_trained_model, cls_pred = cls_train(cls_trained_model, 2, 4, optimizer, 82, cls_train_loader, val_loader , True, 'second')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Epoch 2: 100%|██████████| 9605/9605 [1:23:06<00:00,  1.93it/s, loss=0.44]   \nEpoch 3:  95%|█████████▍| 9078/9605 [1:16:59<05:47,  1.52it/s, loss=0.546]  \rEpoch 3:  98%|█████████▊| 9365/9605 [1:19:26<02:16,  1.76it/s, loss=0.236] \rEpoch 3:  98%|█████████▊| 9371/9605 [1:19:29<02:02,  1.91it/s, loss=0.362]"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'acc': 83.96668434143066, 'train_loss': 0.3634232084243571}\n"
        }
      ],
      "execution_count": 48,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls_trained_model, cls_pred = cls_train(cls_trained_model, 5, 8, optimizer, 84.3, cls_train_loader, val_loader , True, 'second')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Epoch 5: 100%|██████████| 9605/9605 [1:23:19<00:00,  1.92it/s, loss=0.0704] \nEpoch 6: 100%|██████████| 9605/9605 [1:21:32<00:00,  1.96it/s, loss=0.433]   \nEpoch 7: 100%|██████████| 9605/9605 [1:21:26<00:00,  1.97it/s, loss=0.00571] \n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'acc': 84.14367437362671, 'train_loss': 0.19663139513469785}\n{'acc': 83.68558287620544, 'train_loss': 0.09591675791153734}\n{'acc': 83.75846147537231, 'train_loss': 0.08394046925884102}\n"
        }
      ],
      "execution_count": 49,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652583867288
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Cls Model if needed"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls_model = ElectraForSequenceClassification.from_pretrained(model_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of the model checkpoint at wissamantoun/araelectra-base-artydiqa were not used when initializing ElectraForSequenceClassification: ['qa_outputs.weight', 'qa_outputs.bias']\n- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of ElectraForSequenceClassification were not initialized from the model checkpoint at wissamantoun/araelectra-base-artydiqa and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659508937
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 3e-5\r\n",
        "optimizer = torch.optim.AdamW(cls_model.parameters(), lr=learning_rate)\r\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "#criterion_span = nn.CrossEntropyLoss(reduction='none')\r\n",
        "#cls_criterion = nn.CrossEntropyLoss()\r\n",
        "cls_model.to(device)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "ElectraForSequenceClassification(\n  (electra): ElectraModel(\n    (embeddings): ElectraEmbeddings(\n      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): ElectraEncoder(\n      (layer): ModuleList(\n        (0): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): ElectraClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659514157
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls_model, optimizer, start_epoch, result_dict = load_ckp('Runs/AraElectraDecoupledAsquadv2/train/cls/second/best.pt', cls_model, optimizer)\r\n"
      ],
      "outputs": [],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659536222
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Span Training"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_raw_preds(data_loader, model,ids_to_index,offset,contexts, max_answer_length, n_best_size): \r\n",
        "  model.eval()\r\n",
        "  imd_predictions,script_predictions = dict(), dict()\r\n",
        "  with torch.no_grad():\r\n",
        "    #F1 = EM = Total = 0\r\n",
        "    total_loss = 0.0\r\n",
        "    total_predictions = dict()\r\n",
        "    no_probs_pred = dict()\r\n",
        "    #loop = tqdm(data_loader)\r\n",
        "    loop = tqdm(data_loader, leave=True)\r\n",
        "    for batch_idx, batch in enumerate(loop):\r\n",
        "      tokens = batch['input_ids'].to(device)\r\n",
        "      masks = batch['attention_mask'].to(device)\r\n",
        "      tokens_type = batch['token_type_ids'].to(device)\r\n",
        "      gt_start = batch['start_positions'].to(device)\r\n",
        "      gt_end = batch['end_positions'].to(device)\r\n",
        "      IDs = batch['IDs'].to(device)\r\n",
        "      outputs = model(tokens, masks, tokens_type, start_positions=gt_start, end_positions=gt_end)\r\n",
        "      #calculating loss\r\n",
        "      loss = outputs.loss\r\n",
        "      #update average total loss \r\n",
        "      total_loss = total_loss + ((1 / (batch_idx + 1)) * (loss.item() - total_loss)) \r\n",
        "      #calculating f1 score and EM\r\n",
        "      curr_batch_size = tokens.shape[0]\r\n",
        "      post_raw_preds(IDs, outputs.start_logits, outputs.end_logits, ids_to_index, offset, contexts,max_answer_length, n_best_size, imd_predictions, script_predictions )\r\n",
        "    #saving evaluation results\r\n",
        "    #evaluation\r\n",
        "\r\n",
        "    model.train()\r\n",
        "    return imd_predictions,script_predictions"
      ],
      "outputs": [],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659543634
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def post_raw_preds(IDs, total_start_logits, total_end_logits,ids_to_index,offset,contexts, max_answer_length, n_best_size,\r\n",
        " imd_predictions,script_predictions ):\r\n",
        "    total_start_logits = total_start_logits.cpu().numpy()\r\n",
        "    total_end_logits = total_end_logits.cpu().numpy()\r\n",
        "    IDs = IDs.cpu().numpy()\r\n",
        "    for i in range(IDs.shape[0]):\r\n",
        "        offset_mapping = offset[ids_to_index[IDs[i].squeeze()]]\r\n",
        "        # The first feature comes from the first example. For the more general case, we will need to be match the example_id to\r\n",
        "        # an example index\r\n",
        "        context = contexts[ids_to_index[IDs[i].squeeze()]]\r\n",
        "        start_logits = total_start_logits[i]\r\n",
        "        end_logits = total_end_logits[i]\r\n",
        "        # Gather the indices the best start/end logits:\r\n",
        "        start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\r\n",
        "        end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\r\n",
        "        valid_answers = []\r\n",
        "        for start_index in start_indexes:\r\n",
        "            for end_index in end_indexes:\r\n",
        "                # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\r\n",
        "                # to part of the input_ids that are not in the context.\r\n",
        "                if (\r\n",
        "                    start_index >= len(offset_mapping)\r\n",
        "                    or end_index >= len(offset_mapping)\r\n",
        "                    or offset_mapping[start_index] is None\r\n",
        "                    or offset_mapping[end_index] is None\r\n",
        "                ):\r\n",
        "                    continue\r\n",
        "                # Don't consider answers with a length that is either < 0 or > max_answer_length.\r\n",
        "                if end_index < start_index or end_index - start_index + 1 > max_answer_length:\r\n",
        "                    continue\r\n",
        "                if start_index <= end_index: # We need to refine that test to check the answer is inside the context\r\n",
        "                    start_char = offset_mapping[start_index][0]\r\n",
        "                    end_char = offset_mapping[end_index][1]\r\n",
        "                    valid_answers.append(\r\n",
        "                        {\r\n",
        "                            \"score\": start_logits[start_index] + end_logits[end_index],\r\n",
        "                            \"text\": context[start_char: end_char]\r\n",
        "                        }\r\n",
        "                    )\r\n",
        "        if len(valid_answers) ==0:\r\n",
        "            valid_answers.append({\"text\":\"\", \"score\":\"\"})\r\n",
        "\r\n",
        "        valid_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\r\n",
        "        imd_predictions[str(IDs[i].squeeze())] = valid_answer\r\n",
        "        script_predictions[str(IDs[i].squeeze())] = valid_answer['text']"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659551946
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_preds(total_preds, no_probs_preds,data_path, log_path):\r\n",
        "    preds_path = os.path.join(log_path, 'preds')\r\n",
        "    if not os.path.exists(preds_path):\r\n",
        "        os.mkdir(preds_path)\r\n",
        "    no_probs_path = os.path.join(preds_path, 'na_probs.json')\r\n",
        "    text_preds_path = os.path.join(preds_path, 'preds.json')\r\n",
        "    jsonString = json.dumps(total_preds)\r\n",
        "    jsonFile = open(text_preds_path, \"w\")\r\n",
        "    jsonFile.write(jsonString)\r\n",
        "    jsonFile.close()\r\n",
        "    if no_probs_preds is not None:\r\n",
        "        jsonString = json.dumps(no_probs_preds)\r\n",
        "        jsonFile = open(no_probs_path, \"w\")\r\n",
        "        jsonFile.write(jsonString)\r\n",
        "        jsonFile.close()\r\n",
        "        #!python evaluatev2.py data_path text_preds_path electra --na-prob-file no_probs_path --na-prob-thresh 0.4 --out-file log_path\r\n",
        "        #os.system(f\"python evaluatev2.py {data_path} {text_preds_path} electra --na-prob-file {no_probs_path} --na-prob-thresh 0.5 --out-file {log_path}\")\r\n",
        "        !/anaconda/envs/azureml_py38/bin/python3 evaluatev2.py Data/asquadv2-val.json Runs/AraElectraDecoupledAsquadv2/train/span/third/preds/preds.json electra --na-prob-file Runs/AraElectraDecoupledAsquadv2/train/span/second/preds/na_probs.json  --na-prob-thresh 0.5  \r\n",
        "    else:\r\n",
        "        !/anaconda/envs/azureml_py38/bin/python3 evaluatev2.py Data/asquadv2-val.json Runs/AraElectraDecoupledAsquadv2/train/span/third/preds/preds.json electra  --out-file Runs/AraElectraDecoupledAsquadv2/train/span/third\r\n",
        "    if log_path:\r\n",
        "        with open(os.path.join(log_path, 'res.csv')) as f:\r\n",
        "            DictReader_obj = csv.DictReader(f)\r\n",
        "            lastrow = None\r\n",
        "            for item in DictReader_obj:\r\n",
        "                lastrow = dict(item)\r\n",
        "        #print(lastrow)\r\n",
        "        return lastrow\r\n",
        "    return 1\r\n"
      ],
      "outputs": [],
      "execution_count": 47,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652672604493
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def span_train(model,start_epoch, num_epochs, optimizer,max_compined_metric, train_loader, val_loader, log, exp_name):\r\n",
        "  curr_ckp_path, best_ckp_path, exp_path = order_exp('Runs/AraElectraDecoupledAsquadv2/train/span', exp_name)\r\n",
        "  model.train()\r\n",
        "  for epoch in range(start_epoch,num_epochs):\r\n",
        "    total_loss = 0.0\r\n",
        "    loop = tqdm(train_loader, leave=True)\r\n",
        "    for batch_idx, batch in enumerate(loop):\r\n",
        "      tokens = batch['input_ids'].to(device)\r\n",
        "      masks = batch['attention_mask'].to(device)\r\n",
        "      tokens_type = batch['token_type_ids'].to(device)\r\n",
        "      gt_start = batch['start_positions'].to(device)\r\n",
        "      gt_end = batch['end_positions'].to(device)\r\n",
        "      outputs = model(tokens, masks, tokens_type, start_positions=gt_start, end_positions=gt_end)\r\n",
        "      loss = outputs.loss\r\n",
        "      loss = 2*loss\r\n",
        "      loss.backward()\r\n",
        "      optimizer.step()\r\n",
        "      optimizer.zero_grad()\r\n",
        "      total_loss = total_loss + ((1 / (batch_idx + 1)) * (loss.item() - total_loss)) \r\n",
        "      loop.set_description(f'Epoch {epoch}')\r\n",
        "      loop.set_postfix(loss=loss.item())\r\n",
        "    \r\n",
        "    imd_preds, script_preds = get_raw_preds(val_loader, model,val_ids_to_idx,val_offset,aqad_val_contexts, 30, 10)\r\n",
        "    result_dict = get_preds(script_preds, None,'Data/asquadv2-val.json',exp_path )\r\n",
        "    checkpoint = {\r\n",
        "            'epoch': epoch + 1,\r\n",
        "            'result_dict':result_dict,\r\n",
        "            'state_dict': model.state_dict(),\r\n",
        "            'optimizer': optimizer.state_dict(),\r\n",
        "        }\r\n",
        "    curr_compined_metric = float(result_dict['HasAns_exact'])+1.5*float(result_dict['HasAns_f1'])\r\n",
        "    if curr_compined_metric>=max_compined_metric:\r\n",
        "      max_compined_metric = curr_compined_metric\r\n",
        "      save_ckp(checkpoint, True, curr_ckp_path, best_ckp_path)\r\n",
        "    else:\r\n",
        "      save_ckp(checkpoint, False, curr_ckp_path, best_ckp_path)\r\n",
        "    print(\"ckp saved\")\r\n",
        "  return model\r\n"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659739524
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QA_AraElectra = ElectraForQuestionAnswering.from_pretrained(model_name)\r\n",
        "freeze(QA_AraElectra.electra, 6)\r\n",
        "span_num_epochs = 4\r\n",
        "span_learning_rate = 3e-5\r\n",
        "span_optimizer = torch.optim.AdamW(QA_AraElectra.parameters(), lr=span_learning_rate)\r\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "#criterion_span = nn.CrossEntropyLoss(reduction='none')\r\n",
        "#cls_criterion = nn.CrossEntropyLoss()\r\n",
        "QA_AraElectra.to(device)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "134602752 42527232\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": "ElectraForQuestionAnswering(\n  (electra): ElectraModel(\n    (embeddings): ElectraEmbeddings(\n      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): ElectraEncoder(\n      (layer): ModuleList(\n        (0): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 43,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652659640531
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "span_trained_model = span_train(QA_AraElectra,0, 4, span_optimizer,0.0, span_train_loader, val_loader, True, 'third')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Epoch 0: 100%|██████████| 5256/5256 [46:06<00:00,  1.90it/s, loss=3.37] \n100%|██████████| 1201/1201 [05:29<00:00,  3.65it/s]\nEpoch 1: 100%|██████████| 5256/5256 [46:20<00:00,  1.89it/s, loss=4.93] \n100%|██████████| 1201/1201 [05:28<00:00,  3.66it/s]\nEpoch 2: 100%|██████████| 5256/5256 [46:15<00:00,  1.89it/s, loss=1.36]  \n100%|██████████| 1201/1201 [05:29<00:00,  3.65it/s]\nEpoch 3: 100%|██████████| 5256/5256 [46:20<00:00,  1.89it/s, loss=0.248] \n100%|██████████| 1201/1201 [05:27<00:00,  3.67it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"exact\": 31.80635085892764,\n  \"f1\": 39.18377598596737,\n  \"total\": 9605,\n  \"HasAns_exact\": 58.11607992388202,\n  \"HasAns_f1\": 71.60041262516015,\n  \"HasAns_total\": 5255,\n  \"NoAns_exact\": 0.022988505747126436,\n  \"NoAns_f1\": 0.022988505747126436,\n  \"NoAns_total\": 4350\n}\nckp saved\n{\n  \"exact\": 32.4518479958355,\n  \"f1\": 39.419988150956904,\n  \"total\": 9605,\n  \"HasAns_exact\": 59.27687916270219,\n  \"HasAns_f1\": 72.01312772406109,\n  \"HasAns_total\": 5255,\n  \"NoAns_exact\": 0.04597701149425287,\n  \"NoAns_f1\": 0.04597701149425287,\n  \"NoAns_total\": 4350\n}\nckp saved\n{\n  \"exact\": 32.160333159812595,\n  \"f1\": 39.31507513222507,\n  \"total\": 9605,\n  \"HasAns_exact\": 58.76308277830638,\n  \"HasAns_f1\": 71.84039898097464,\n  \"HasAns_total\": 5255,\n  \"NoAns_exact\": 0.022988505747126436,\n  \"NoAns_f1\": 0.022988505747126436,\n  \"NoAns_total\": 4350\n}\nckp saved\n{\n  \"exact\": 31.70223841749089,\n  \"f1\": 38.887389352235836,\n  \"total\": 9605,\n  \"HasAns_exact\": 57.906755470980016,\n  \"HasAns_f1\": 71.03965265998576,\n  \"HasAns_total\": 5255,\n  \"NoAns_exact\": 0.04597701149425287,\n  \"NoAns_f1\": 0.04597701149425287,\n  \"NoAns_total\": 4350\n}\nckp saved\n"
        }
      ],
      "execution_count": 45,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1652672239995
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!/anaconda/envs/azureml_py38/bin/python3 evaluatev2.py Data/asquadv2-val.json Runs/AraElectraDecoupledAsquadv2/train/span/third/preds/preds.json electra --na-prob-file Runs/AraElectraDecoupledAsquadv2/train/span/second/preds/na_probs.json  --na-prob-thresh 0.5 "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\r\n  \"exact\": 63.87298282144716,\r\n  \"f1\": 70.44332708661499,\r\n  \"total\": 9605,\r\n  \"HasAns_exact\": 53.6441484300666,\r\n  \"HasAns_f1\": 65.65331240093887,\r\n  \"HasAns_total\": 5255,\r\n  \"NoAns_exact\": 76.22988505747126,\r\n  \"NoAns_f1\": 76.22988505747126,\r\n  \"NoAns_total\": 4350,\r\n  \"best_exact\": 66.66319625195212,\r\n  \"best_exact_thresh\": 0.08445756882429123,\r\n  \"best_f1\": 72.30824856366091,\r\n  \"best_f1_thresh\": 0.15894971787929535\r\n}\r\n"
        }
      ],
      "execution_count": 50,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}