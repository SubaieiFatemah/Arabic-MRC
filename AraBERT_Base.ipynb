{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AraBERT_Base.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1_ku_8kAx0bw8tFEVT12px9bG1ymLMJ8q",
      "authorship_tag": "ABX9TyP5T9Uei6HfCXeTG3wtsGrY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeyadahmed10/Arabic-MRC/blob/Training/AraBERT_Base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0M2GTvtHwpz"
      },
      "source": [
        "## Install & import required packages\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InlWwhe7Hqn4",
        "outputId": "92f224c3-6fd6-4ffd-c90e-7431f9b26c8d"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4se86D7wISz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b78547a-415e-4de9-a9c6-2bfe1af52d24"
      },
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModel , AutoTokenizer\n",
        "torch.manual_seed(1)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f32a79e8d90>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMmkEr2-IkzZ"
      },
      "source": [
        "## Mount google drive & creating new directories for AAQAD\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTWjEUZvI9KJ"
      },
      "source": [
        "if not os.path.exists('/content/drive/MyDrive/MRC'):\n",
        "  os.mkdir('/content/drive/MyDrive/MRC')\n",
        "  os.mkdir('/content/drive/MyDrive/MRC/aaqad')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "QdJq2a98JzzU",
        "outputId": "9b508adf-a89f-4a9b-c7bb-1de93cbbab99"
      },
      "source": [
        "#uncomment if you did not download the data\n",
        "\"\"\" !pip install gdown\n",
        "!gdown https://drive.google.com/uc?id=1jhUmWb9eHVATqhrWKAXxSE2gqJ53-wk6 -O AAQAD.json\n",
        "!gdown https://drive.google.com/uc?id=1V5ziIZe__pGg14nH42WyMEFz444XPWf7 -O AAQAD\\-train.json\n",
        "!gdown https://drive.google.com/uc?id=19nj9jiCdJlHwAfgUTJ_Z8jg1cB34yfjv -O AAQAD\\-dev.json\n",
        "!gdown https://drive.google.com/uc?id=1z0XksuTwnqhiX1guxkmjYmoNA_JZ6SUN -O AAQAD\\-test.json \n",
        "\n",
        "src_path ='/content/'\n",
        "dest_path = '/content/drive/MyDrive/MRC/aaqad/'\n",
        "files_name =['AAQAD.json', 'AAQAD-train.json', 'AAQAD-dev.json', 'AAQAD-test.json']\n",
        "for name in files_name:\n",
        "  os.rename(src_path+name, dest_path+name)\n",
        "\"\"\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" !pip install gdown\\n!gdown https://drive.google.com/uc?id=1jhUmWb9eHVATqhrWKAXxSE2gqJ53-wk6 -O AAQAD.json\\n!gdown https://drive.google.com/uc?id=1V5ziIZe__pGg14nH42WyMEFz444XPWf7 -O AAQAD\\\\-train.json\\n!gdown https://drive.google.com/uc?id=19nj9jiCdJlHwAfgUTJ_Z8jg1cB34yfjv -O AAQAD\\\\-dev.json\\n!gdown https://drive.google.com/uc?id=1z0XksuTwnqhiX1guxkmjYmoNA_JZ6SUN -O AAQAD\\\\-test.json \\n\\nsrc_path ='/content/'\\ndest_path = '/content/drive/MyDrive/MRC/aaqad/'\\nfiles_name =['AAQAD.json', 'AAQAD-train.json', 'AAQAD-dev.json', 'AAQAD-test.json']\\nfor name in files_name:\\n  os.rename(src_path+name, dest_path+name)\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGjiH0ikMSJQ"
      },
      "source": [
        "## Load data and preprocessing\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "OcbL62xRM2dU",
        "outputId": "09366470-8416-46d8-cbc3-33c233833f9b"
      },
      "source": [
        "##DATA TREE AND TYPE##\n",
        "'''\n",
        "aaqad_dev_dict['data']##list of articles\n",
        "aaqad_dev_dict['data'][0]## dictionary of paragraph -- keys(title, paragraph)\n",
        "aaqad_dev_dict['data'][0]['paragraphs'] ##list of contexts\n",
        "aaqad_dev_dict['data'][0]['paragraphs'][0] ## dictionary of context and crossponding QAs pairs --keys(context, qas)\n",
        "aaqad_dev_dict['data'][0]['paragraphs'][0]['qas'] ##list of QAs pair\n",
        "aaqad_dev_dict['data'][0]['paragraphs'][0] ['qas'][0] ##dictionary of the elements of each question --keys(id, is_impossible,question, answers)\n",
        "aaqad_dev_dict['data'][0]['paragraphs'][0] ['qas'][0]['answers'] ##dictionary of start index and answer text --keys(answer_start, text)'''"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\naaqad_dev_dict['data']##list of articles\\naaqad_dev_dict['data'][0]## dictionary of paragraph -- keys(title, paragraph)\\naaqad_dev_dict['data'][0]['paragraphs'] ##list of contexts\\naaqad_dev_dict['data'][0]['paragraphs'][0] ## dictionary of context and crossponding QAs pairs --keys(context, qas)\\naaqad_dev_dict['data'][0]['paragraphs'][0]['qas'] ##list of QAs pair\\naaqad_dev_dict['data'][0]['paragraphs'][0] ['qas'][0] ##dictionary of the elements of each question --keys(id, is_impossible,question, answers)\\naaqad_dev_dict['data'][0]['paragraphs'][0] ['qas'][0]['answers'] ##dictionary of start index and answer text --keys(answer_start, text)\""
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO4PKnxETihu"
      },
      "source": [
        "def add_end_index(answer, context):\n",
        "  ## 1 if span mathc the context 0 otherwise\n",
        "  text = answer['text']\n",
        "  start_idx = answer['answer_start']\n",
        "  end_idx = start_idx + len(text)\n",
        "  if text == context[start_idx:end_idx]:\n",
        "    answer['answer_end'] = end_idx\n",
        "    return False\n",
        "  for i in range(1,3):\n",
        "    if text == context[start_idx-i:end_idx-i]:\n",
        "      answer['answer_end']= end_idx-1\n",
        "      answer['answer_start'] = start_idx-1\n",
        "      return False\n",
        "  return True"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L_EeDReM-57"
      },
      "source": [
        "def Read_AAQAD(path):\n",
        "  contexts =[]\n",
        "  answers =[]\n",
        "  questions =[]\n",
        "  plausible = []\n",
        "  cnt = 0\n",
        "  with open(path) as f:\n",
        "    aaqad_dict = json.load(f)\n",
        "    for article in aaqad_dict['data']:\n",
        "      for passage in article['paragraphs']:\n",
        "        context = passage['context']\n",
        "        for qa in passage['qas']:\n",
        "          question = qa['question']\n",
        "          if 'plausible_answers' in qa.keys():# there is two cases if the question have no answer then use plausible answer\n",
        "            access = 'plausible_answers'\n",
        "            plausible.append(1)\n",
        "          else:\n",
        "            access = 'answers'\n",
        "            plausible.append(0)\n",
        "          for answer in qa[access]:\n",
        "            flag = add_end_index(answer, context) #if false dont add the \n",
        "            cnt =cnt + flag\n",
        "            if not flag:\n",
        "              contexts.append(context)\n",
        "              answers.append(answer)\n",
        "              questions.append(question)\n",
        "  return contexts,questions,answers,plausible,cnt"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jabv_uE2TdHj"
      },
      "source": [
        "train_contexts, train_questions, train_answers,train_plausible, train_span_error = Read_AAQAD('/content/drive/MyDrive/MRC/aaqad/AAQAD-train.json')\n",
        "val_contexts, val_questions, val_answers,val_plausible, val_span_error = Read_AAQAD('/content/drive/MyDrive/MRC/aaqad/AAQAD-dev.json')\n",
        "test_contexts, test_questions, test_answers,test_plausible, test_span_error = Read_AAQAD('/content/drive/MyDrive/MRC/aaqad/AAQAD-test.json')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS7kUgcJZ34r",
        "outputId": "4cfecf5b-c1f9-4d00-938f-ca36ecb8edf7"
      },
      "source": [
        "total_error = train_span_error + val_span_error + test_span_error\n",
        "ratio = total_error/17817 #initial size of the data\n",
        "print(f\"Size of the data set before dropping the misslabeled spans: 17817 & after: {len(train_answers)+len(val_answers)+len(test_answers)}\")\n",
        "print(f\"Size of each split: \\n 1-Train: {len(train_answers)} \\n 2-Validation: {len(val_answers)} \\n 3-Test: {len(test_answers)}\")\n",
        "print(f\"percentage of span's error {ratio}\")\n",
        "print(f\"Number of errors for each split:\\n 1-Train: {train_span_error} \\n 2-Validation: {val_span_error}\\n 3-Test: {test_span_error}\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the data set before dropping the misslabeled spans: 17817 & after: 17753\n",
            "Size of each split: \n",
            " 1-Train: 12595 \n",
            " 2-Validation: 1915 \n",
            " 3-Test: 3243\n",
            "percentage of span's error 0.0035920749845653028\n",
            "Number of errors for each split:\n",
            " 1-Train: 34 \n",
            " 2-Validation: 11\n",
            " 3-Test: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsnTPfiZedfy"
      },
      "source": [
        "## Tokenization\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOqWFALlen2W"
      },
      "source": [
        "#Creating the tokenizer\n",
        "model_name = \"aubmindlab/bert-base-arabertv02\"\n",
        "arabert_tokenizer = AutoTokenizer.from_pretrained(model_name,do_lower_case=False)\n",
        "\n",
        "train_encodings = arabert_tokenizer(train_questions, train_contexts, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "val_encodings = arabert_tokenizer(val_questions, val_contexts, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "test_encodings = arabert_tokenizer(test_questions, test_contexts,truncation= True, padding= True, return_tensors=\"pt\")\n",
        "model_encodings = arabert_tokenizer(train_questions[:2], train_contexts[:2], truncation=True, padding=True, return_tensors=\"pt\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "142z-kzLgQIq"
      },
      "source": [
        "The encoding is dictionary of ['input_ids', 'token_type_ids', 'attention_mask'] <br>\n",
        "Input_ids: are the token of each sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_answers[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvUOq53AlZSL",
        "outputId": "35c2654d-3842-4caa-c01d-888c9ed9c93b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer_end': 227, 'answer_start': 211, 'text': 'تصل المسافة التي'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_contexts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "G-pky3qoouNj",
        "outputId": "7b942f55-e13a-43ee-b781-c35d5b6ddeb0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'هجرة الطيور هي رحلة موسمية تقوم بها أسراب من الطيور قاطعين مسافات هائلة عبر الصحاري وقمم الجبال العالية والمحيطات. تصل هذه الطيور إلى هدفها في وقت واحد يتطابق مع الوقت التي وصلت فيه في العام السابق. بعض الأنواع تصل المسافة التي تقطعها في هجرتها إلى 50 الف كيلومتر في السنة، البعض الآخر تستمر بالطيران بدون انقطاع لمدة تصل إلى 100 ساعة مع منظومة تحديد دقيقة للاتجاهات عند تلك الطيور. بعض الأنواع لها القدرة على الطيران لمسافات طويلة، ليلا ونهارا، دون توقف. هذه القدرة هامة للغاية للتمكن من عبور الصحاري الكبرى الممتدة لالاف الكيلومترات بدون طعام أو ماء. قبل بدء رحلتهم لعبور الصحراء تقوم الطيور بأكل طعام غني بالدهون مثل حبوب الذرة.\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings.char_to_token(0,train_answers[0]['answer_start'], 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90_A5aFHIU7G",
        "outputId": "62fd8f93-cacf-49ba-cb71-100a09213465"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ze0nuQLgZqb"
      },
      "source": [
        "def index_to_token_position(encodings , answers):\n",
        "  start_positions = list()\n",
        "  end_positions = list()\n",
        "  for i in range(len(answers)):\n",
        "    start_positions.append(encodings.char_to_token(i, answers[i]['answer_start'], 1))\n",
        "    end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'], 1))\n",
        "    #if context truncated\n",
        "    if start_positions[-1] is None: \n",
        "      start_positions[-1] = arabert_tokenizer.model_max_length\n",
        "    #if end index is space\n",
        "    itt = 1\n",
        "    while end_positions[-1] is None: \n",
        "      end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end']-itt, 1)\n",
        "      itt = itt + 1 \n",
        "  encodings.update({'start_positions': torch.tensor(start_positions), 'end_positions': torch.tensor(end_positions)})\n",
        "  encodings['start_positions'] = encodings['start_positions'].view(len(answers), 1)\n",
        "  encodings['end_positions'] = encodings['end_positions'].view(len(answers), 1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li1QBYPxkbpR"
      },
      "source": [
        "index_to_token_position(train_encodings, train_answers)\n",
        "index_to_token_position(val_encodings, val_answers)\n",
        "index_to_token_position(test_encodings, test_answers)\n",
        "index_to_token_position(model_encodings, train_answers[:2])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_encodings['start_positions'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkWMJ_KF0adt",
        "outputId": "772bcc46-4bc3-4ba4-c37a-22fe7d700b1d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_truncated(start_pos):\n",
        "  cnt = 0\n",
        "  for pos in start_pos:\n",
        "    if pos==512:\n",
        "      cnt+=1\n",
        "  return cnt\n",
        "\n",
        "print(is_truncated(train_encodings['start_positions']))\n",
        "print(is_truncated(val_encodings['start_positions']))\n",
        "print(is_truncated(test_encodings['start_positions']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl_UxGd5H47X",
        "outputId": "e6df1559-e202-40d9-ab56-b0fb187ebeae"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "0\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(test_encodings['start_positions'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihnAVF5JzlTW",
        "outputId": "66bc970f-199e-4562-99d6-0bb95611d946"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for metrics\n",
        "#decoded_string = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 3014])\n",
        "#print(decoded_string)"
      ],
      "metadata": {
        "id": "M66SpPjS_JuH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset and Dataloader\n",
        "---"
      ],
      "metadata": {
        "id": "YbHOOmppmfZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "cS9ATVPBUU_x"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AqadDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: val[idx] for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "train_dataset = AqadDataset(train_encodings)\n",
        "val_dataset = AqadDataset(val_encodings)\n",
        "model_dataset = AqadDataset(model_encodings)"
      ],
      "metadata": {
        "id": "-u2KCWejXhOa"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 8, shuffle= True)\n",
        "model_loader = DataLoader(model_dataset, batch_size = 2, shuffle= True)"
      ],
      "metadata": {
        "id": "IMH9XNyKa20T"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Jhnw5zANEja"
      },
      "source": [
        "## Modeling\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AraBert = AutoModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJQz9rCZM1Eh",
        "outputId": "a33f50b6-3fca-4c87-a6e2-d8d17062e0a1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02 were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first = train_dataset.__getitem__(0)"
      ],
      "metadata": {
        "id": "xghmwXtScBkj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''encodings = arabert_tokenizer(train_questions[0:3], train_contexts[0:3], truncation=True, padding=True, return_tensors=\"pt\")\n",
        "from transformers import BertForQuestionAnswering\n",
        "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
        "outputs = model(**encodings, start_positions=train_encodings['start_positions'][:3], end_positions=train_encodings['end_positions'][:3])\n",
        "loss = outputs.loss\n",
        "start_scores = outputs.start_logits\n",
        "end_scores = outputs.end_logits'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "shSWpWgFrbVR",
        "outputId": "de053519-dda9-4d3d-9dd1-497e3228e2c1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'encodings = arabert_tokenizer(train_questions[0:3], train_contexts[0:3], truncation=True, padding=True, return_tensors=\"pt\")\\nfrom transformers import BertForQuestionAnswering\\nmodel = BertForQuestionAnswering.from_pretrained(model_name)\\noutputs = model(**encodings, start_positions=train_encodings[\\'start_positions\\'][:3], end_positions=train_encodings[\\'end_positions\\'][:3])\\nloss = outputs.loss\\nstart_scores = outputs.start_logits\\nend_scores = outputs.end_logits'"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AraBertBase(nn.Module):\n",
        "  def __init__(self, BERT):\n",
        "    super().__init__()\n",
        "    self.base = BERT\n",
        "    #self.Weights = Weights\n",
        "    self.start = nn.Linear(768, 1)\n",
        "    self.end = nn.Linear(768, 1)\n",
        "  def forward(self, tokens, token_type, mask):\n",
        "    output = self.base(input_ids = tokens, attention_mask = mask, token_type_ids = token_type)\n",
        "    bert_encoding = output.last_hidden_state\n",
        "    start_span = self.start(bert_encoding)\n",
        "    end_span = self.end(bert_encoding)\n",
        "    return start_span, end_span\n"
      ],
      "metadata": {
        "id": "3ifcPJSKOKuo"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def EM_score(pred, GT):\n",
        "  if torch.equal(pred, GT):return 1\n",
        "  return 0"
      ],
      "metadata": {
        "id": "2IPIUZPQCEak"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def F1_score(prediction, ground_truth):\n",
        "    prediction_tokens = prediction.tolist()\n",
        "    ground_truth_tokens = ground_truth.tolist()\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1"
      ],
      "metadata": {
        "id": "J-i9-oqlGNIT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(data_loader, model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    F1 = EM = Total = 0\n",
        "    #loop = tqdm(data_loader)\n",
        "    for batch in data_loader:\n",
        "      tokens = batch['input_ids'].to(device)\n",
        "      masks = batch['attention_mask'].to(device)\n",
        "      tokens_type = batch['token_type_ids'].to(device)\n",
        "      start_span, end_span = model(tokens, masks, tokens_type)\n",
        "      for i in range(data_loader.batch_size):\n",
        "        start_gt, end_gt = batch['start_positions'][i], batch['end_positions'][i]\n",
        "        gt_tokens = batch['input_ids'][i][start_gt.item():end_gt.item()+1]\n",
        "        start_pred, end_pred = torch.argmax(start_span[i],dim=0), torch.argmax(end_span[i],dim =0)\n",
        "        pred_tokens = batch['input_ids'][i][start_pred.item():end_pred.item()+1]\n",
        "        F1 += F1_score(pred_tokens, gt_tokens)\n",
        "        EM += EM_score(torch.tensor([start_pred, end_pred]), torch.tensor([start_gt,end_gt]))\n",
        "        #print(torch.tensor([start_gt,end_gt]), torch.tensor([start_pred, end_pred]), pred_tokens, gt_tokens)\n",
        "        Total +=1\n",
        "    EM = 100.0 *EM/Total\n",
        "    F1 = 100.0 * F1 /Total \n",
        "    print(f\"EM: {EM}, f1: {F1}\")\n",
        "    model.train()\n",
        "    return EM,F1"
      ],
      "metadata": {
        "id": "oimas_BC_Tai"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AraBertBase(AraBert)\n",
        "num_epochs = 10\n",
        "learning_rate = 0.0003\n",
        "criterion1 = nn.CrossEntropyLoss() \n",
        "criterion2 = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "R1ilceKLPUzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e473e41-68b0-467d-857b-06ee59434612"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AraBertBase(\n",
              "  (base): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (start): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (end): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_Cpt = \"/content/drive/MyDrive/MRC/training/arabert_base/curr.pt\"\n",
        "PATH_Cpt_best = \"/content/drive/MyDrive/MRC/training/arabert_base/best.pt\""
      ],
      "metadata": {
        "id": "VbSw3So0D1aU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "loop = tqdm(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, batch in enumerate(loop):\n",
        "    print(epoch)\n",
        "    tokens = batch['input_ids'].to(device)\n",
        "    masks = batch['attention_mask'].to(device)\n",
        "    tokens_type = batch['token_type_ids'].to(device)\n",
        "    start_span, end_span = model(tokens, masks, tokens_type)\n",
        "    gt_start = batch['start_positions'].to(device)\n",
        "    gt_end = batch['end_positions'].to(device)\n",
        "    #print(type(batch))\n",
        "    #print(gt_start.shape)\n",
        "    #print(start_span.shape)\n",
        "    loss1 = criterion1(start_span, gt_start)\n",
        "    #print(loss1)\n",
        "    loss2 = criterion2(end_span, gt_end)\n",
        "    loss = loss1 + loss2\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    loop.set_description(f'Epoch {epoch}')\n",
        "    loop.set_postfix(loss=loss.item())\n",
        "  torch.save(model.state_dict(), PATH_Cpt) #saving checkpoint  \n",
        "  curr_em, curr_f1 = evaluate(eval_loader, model)\n",
        "  if curr_em>= best_em:\n",
        "    best_em = curr_em\n",
        "    torch.save(model.state_dict(), PATH_Cpt_best)"
      ],
      "metadata": {
        "id": "npcGLDUOAETl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "62603ef0-054e-43b0-f2db-0e1aa97b926b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1575 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:   0%|          | 1/1575 [00:49<21:39:11, 49.52s/it, loss=14]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:   0%|          | 2/1575 [01:39<21:40:39, 49.61s/it, loss=9.76]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 0:   0%|          | 2/1575 [02:23<31:17:51, 71.63s/it, loss=9.76]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-71440d7992c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mloss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_span\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(Loss* weights), reduction = None"
      ],
      "metadata": {
        "id": "mEoQeNjoP6x0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}