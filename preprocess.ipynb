{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocess.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/zeyadahmed10/Arabic-MRC/blob/Training/preprocess.ipynb",
      "authorship_tag": "ABX9TyP6jPIw2ms5uBAGV4IdVvtD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeyadahmed10/Arabic-MRC/blob/Training/preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0M2GTvtHwpz"
      },
      "source": [
        "## Install & import required packages\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InlWwhe7Hqn4",
        "outputId": "a7b977cf-dd73-4a92-934c-96c1f8c83647"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4se86D7wISz-"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModel , AutoTokenizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMmkEr2-IkzZ"
      },
      "source": [
        "## Mount google drive & creating new directories for AAQAD\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTWjEUZvI9KJ"
      },
      "source": [
        "if not os.path.exists('/content/drive/MyDrive/MRC'):\n",
        "  os.mkdir('/content/drive/MyDrive/MRC')\n",
        "  os.mkdir('/content/drive/MyDrive/MRC/aaqad')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "QdJq2a98JzzU",
        "outputId": "da8dae4c-63dd-4b02-c2a0-5bf50f85f030"
      },
      "source": [
        "#uncomment if you did not download the data\n",
        "\"\"\" !pip install gdown\n",
        "!gdown https://drive.google.com/uc?id=1jhUmWb9eHVATqhrWKAXxSE2gqJ53-wk6 -O AAQAD.json\n",
        "!gdown https://drive.google.com/uc?id=1V5ziIZe__pGg14nH42WyMEFz444XPWf7 -O AAQAD\\-train.json\n",
        "!gdown https://drive.google.com/uc?id=19nj9jiCdJlHwAfgUTJ_Z8jg1cB34yfjv -O AAQAD\\-dev.json\n",
        "!gdown https://drive.google.com/uc?id=1z0XksuTwnqhiX1guxkmjYmoNA_JZ6SUN -O AAQAD\\-test.json \n",
        "\n",
        "src_path ='/content/'\n",
        "dest_path = '/content/drive/MyDrive/MRC/aaqad/'\n",
        "files_name =['AAQAD.json', 'AAQAD-train.json', 'AAQAD-dev.json', 'AAQAD-test.json']\n",
        "for name in files_name:\n",
        "  os.rename(src_path+name, dest_path+name)\n",
        "\"\"\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" !pip install gdown\\n!gdown https://drive.google.com/uc?id=1jhUmWb9eHVATqhrWKAXxSE2gqJ53-wk6 -O AAQAD.json\\n!gdown https://drive.google.com/uc?id=1V5ziIZe__pGg14nH42WyMEFz444XPWf7 -O AAQAD\\\\-train.json\\n!gdown https://drive.google.com/uc?id=19nj9jiCdJlHwAfgUTJ_Z8jg1cB34yfjv -O AAQAD\\\\-dev.json\\n!gdown https://drive.google.com/uc?id=1z0XksuTwnqhiX1guxkmjYmoNA_JZ6SUN -O AAQAD\\\\-test.json \\n\\nsrc_path ='/content/'\\ndest_path = '/content/drive/MyDrive/MRC/aaqad/'\\nfiles_name =['AAQAD.json', 'AAQAD-train.json', 'AAQAD-dev.json', 'AAQAD-test.json']\\nfor name in files_name:\\n  os.rename(src_path+name, dest_path+name)\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGjiH0ikMSJQ"
      },
      "source": [
        "## Load data and preprocessing\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "OcbL62xRM2dU",
        "outputId": "272202ed-165a-41be-b362-38bbfeda0cb7"
      },
      "source": [
        "##DATA TREE AND TYPE##\n",
        "'''\n",
        "aaqad_dev_dict['data']##list of articles\n",
        "aaqad_dev_dict['data'][0]## dictionary of paragraph -- keys(title, paragraph)\n",
        "aaqad_dev_dict['data'][0]['paragraphs'] ##list of contexts\n",
        "aaqad_dev_dict['data'][0]['paragraphs'][0] ## dictionary of context and crossponding QAs pairs --keys(context, qas)\n",
        "aaqad_dev_dict['data'][0]['paragraphs'][0]['qas'] ##list of QAs pair\n",
        "aaqad_dev_dict['data'][0]['paragraphs'][0] ['qas'][0] ##dictionary of the elements of each question --keys(id, is_impossible,question, answers)\n",
        "aaqad_dev_dict['data'][0]['paragraphs'][0] ['qas'][0]['answers'] ##dictionary of start index and answer text --keys(answer_start, text)'''"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\naaqad_dev_dict['data']##list of articles\\naaqad_dev_dict['data'][0]## dictionary of paragraph -- keys(title, paragraph)\\naaqad_dev_dict['data'][0]['paragraphs'] ##list of contexts\\naaqad_dev_dict['data'][0]['paragraphs'][0] ## dictionary of context and crossponding QAs pairs --keys(context, qas)\\naaqad_dev_dict['data'][0]['paragraphs'][0]['qas'] ##list of QAs pair\\naaqad_dev_dict['data'][0]['paragraphs'][0] ['qas'][0] ##dictionary of the elements of each question --keys(id, is_impossible,question, answers)\\naaqad_dev_dict['data'][0]['paragraphs'][0] ['qas'][0]['answers'] ##dictionary of start index and answer text --keys(answer_start, text)\""
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO4PKnxETihu"
      },
      "source": [
        "def add_end_index(answer, context):\n",
        "  ## 1 if span mathc the context 0 otherwise\n",
        "  text = answer['text']\n",
        "  start_idx = answer['answer_start']\n",
        "  end_idx = start_idx + len(text)\n",
        "  if text == context[start_idx:end_idx]:\n",
        "    answer['answer_end'] = end_idx\n",
        "    return False\n",
        "  for i in range(1,3):\n",
        "    if text == context[start_idx-i:end_idx-i]:\n",
        "      answer['answer_end']= end_idx-1\n",
        "      answer['answer_start'] = start_idx-1\n",
        "      return False\n",
        "  return True"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L_EeDReM-57"
      },
      "source": [
        "def Read_AAQAD(path):\n",
        "  contexts =[]\n",
        "  answers =[]\n",
        "  questions =[]\n",
        "  plausible = []\n",
        "  cnt = 0\n",
        "  with open(path) as f:\n",
        "    aaqad_dict = json.load(f)\n",
        "    for article in aaqad_dict['data']:\n",
        "      for passage in article['paragraphs']:\n",
        "        context = passage['context']\n",
        "        for qa in passage['qas']:\n",
        "          question = qa['question']\n",
        "          if 'plausible_answers' in qa.keys():# there is two cases if the question have no answer then use plausible answer\n",
        "            access = 'plausible_answers'\n",
        "            plausible.append(1)\n",
        "          else:\n",
        "            access = 'answers'\n",
        "            plausible.append(0)\n",
        "          for answer in qa[access]:\n",
        "            flag = add_end_index(answer, context) #if false dont add the \n",
        "            cnt =cnt + flag\n",
        "            if not flag:\n",
        "              contexts.append(context)\n",
        "              answers.append(answer)\n",
        "              questions.append(question)\n",
        "  return contexts,questions,answers,plausible,cnt"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jabv_uE2TdHj"
      },
      "source": [
        "train_contexts, train_questions, train_answers,train_plausible, train_span_error = Read_AAQAD('/content/drive/MyDrive/MRC/aaqad/AAQAD-train.json')\n",
        "val_contexts, val_questions, val_answers,val_plausible, val_span_error = Read_AAQAD('/content/drive/MyDrive/MRC/aaqad/AAQAD-dev.json')\n",
        "test_contexts, test_questions, test_answers,test_plausible, test_span_error = Read_AAQAD('/content/drive/MyDrive/MRC/aaqad/AAQAD-test.json')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS7kUgcJZ34r",
        "outputId": "cd1ed423-e5d3-4bfd-8047-85892493b5ba"
      },
      "source": [
        "total_error = train_span_error + val_span_error + test_span_error\n",
        "ratio = total_error/17817 #initial size of the data\n",
        "print(f\"Size of the data set before dropping the misslabeled spans: 17817 & after: {len(train_answers)+len(val_answers)+len(test_answers)}\")\n",
        "print(f\"Size of each split: \\n 1-Train: {len(train_answers)} \\n 2-Validation: {len(val_answers)} \\n 3-Test: {len(test_answers)}\")\n",
        "print(f\"percentage of span's error {ratio}\")\n",
        "print(f\"Number of errors for each split:\\n 1-Train: {train_span_error} \\n 2-Validation: {val_span_error}\\n 3-Test: {test_span_error}\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the data set before dropping the misslabeled spans: 17817 & after: 17753\n",
            "Size of each split: \n",
            " 1-Train: 12595 \n",
            " 2-Validation: 1915 \n",
            " 3-Test: 3243\n",
            "percentage of span's error 0.0035920749845653028\n",
            "Number of errors for each split:\n",
            " 1-Train: 34 \n",
            " 2-Validation: 11\n",
            " 3-Test: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsnTPfiZedfy"
      },
      "source": [
        "## Tokenization\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOqWFALlen2W"
      },
      "source": [
        "#Creating the tokenizer\n",
        "model_name = \"aubmindlab/bert-base-arabertv02\"\n",
        "arabert_tokenizer = AutoTokenizer.from_pretrained(model_name,do_lower_case=False)\n",
        "\n",
        "train_encodings = arabert_tokenizer(train_questions, train_contexts, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "val_encodings = arabert_tokenizer(val_questions, val_contexts, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "test_encodings = arabert_tokenizer(test_questions, test_contexts,truncation= True, padding= True, return_tensors=\"pt\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "142z-kzLgQIq"
      },
      "source": [
        "The encoding is dictionary of ['input_ids', 'token_type_ids', 'attention_mask'] <br>\n",
        "Input_ids: are the token of each sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_answers[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvUOq53AlZSL",
        "outputId": "a92714ea-e372-45c6-d13a-0723a677b92e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer_end': 227, 'answer_start': 211, 'text': 'تصل المسافة التي'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_contexts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "G-pky3qoouNj",
        "outputId": "f83e4975-6662-4c59-8a67-99df8e35c7ef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'هجرة الطيور هي رحلة موسمية تقوم بها أسراب من الطيور قاطعين مسافات هائلة عبر الصحاري وقمم الجبال العالية والمحيطات. تصل هذه الطيور إلى هدفها في وقت واحد يتطابق مع الوقت التي وصلت فيه في العام السابق. بعض الأنواع تصل المسافة التي تقطعها في هجرتها إلى 50 الف كيلومتر في السنة، البعض الآخر تستمر بالطيران بدون انقطاع لمدة تصل إلى 100 ساعة مع منظومة تحديد دقيقة للاتجاهات عند تلك الطيور. بعض الأنواع لها القدرة على الطيران لمسافات طويلة، ليلا ونهارا، دون توقف. هذه القدرة هامة للغاية للتمكن من عبور الصحاري الكبرى الممتدة لالاف الكيلومترات بدون طعام أو ماء. قبل بدء رحلتهم لعبور الصحراء تقوم الطيور بأكل طعام غني بالدهون مثل حبوب الذرة.\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings.char_to_token(0,train_answers[0]['answer_start'], 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90_A5aFHIU7G",
        "outputId": "316e9936-9acb-4ca5-ee2a-a47c6ceb1a76"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ze0nuQLgZqb"
      },
      "source": [
        "def index_to_token_position(encodings , answers):\n",
        "  start_positions = list()\n",
        "  end_positions = list()\n",
        "  for i in range(len(answers)):\n",
        "    start_positions.append(encodings.char_to_token(i, answers[i]['answer_start'], 1))\n",
        "    end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'], 1))\n",
        "    #if context truncated\n",
        "    if start_positions[-1] is None: \n",
        "      start_positions[-1] = arabert_tokenizer.model_max_length\n",
        "    #if end index is space\n",
        "    itt = 1\n",
        "    while end_positions[-1] is None: \n",
        "      end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end']-itt, 1)\n",
        "      itt = itt + 1 \n",
        "  encodings.update({'start_positions': torch.tensor(start_positions), 'end_positions': torch.tensor(end_positions)})"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li1QBYPxkbpR"
      },
      "source": [
        "index_to_token_position(train_encodings, train_answers)\n",
        "index_to_token_position(val_encodings, val_answers)\n",
        "index_to_token_position(test_encodings, test_answers)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_truncated(start_pos):\n",
        "  cnt = 0\n",
        "  for pos in start_pos:\n",
        "    if pos==512:\n",
        "      cnt+=1\n",
        "  return cnt\n",
        "\n",
        "print(is_truncated(train_encodings['start_positions']))\n",
        "print(is_truncated(val_encodings['start_positions']))\n",
        "print(is_truncated(test_encodings['start_positions']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl_UxGd5H47X",
        "outputId": "ee9361c6-8379-4918-ca1c-ce6ba693d477"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "0\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for metrics\n",
        "#decoded_string = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 3014])\n",
        "#print(decoded_string)"
      ],
      "metadata": {
        "id": "M66SpPjS_JuH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgQzHLGEMDaR",
        "outputId": "5eb4efff-ec6a-42d5-bba4-f1665f703011"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Jhnw5zANEja"
      },
      "source": [
        "## Modeling\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "cS9ATVPBUU_x"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AqadDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: val[idx] for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "train_dataset = AqadDataset(train_encodings)\n",
        "val_dataset = AqadDataset(val_encodings)"
      ],
      "metadata": {
        "id": "-u2KCWejXhOa"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AraBert = AutoModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJQz9rCZM1Eh",
        "outputId": "690a79a8-f5d8-4c08-86e0-454f4a525913"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02 were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AraBert.parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfqq9fAaQBDJ",
        "outputId": "20867d14-8a71-4f26-f860-f4ebf48c5d72"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f760a2a9f50>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 16, shuffle= True)"
      ],
      "metadata": {
        "id": "IMH9XNyKa20T"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first = train_dataset.__getitem__(0)\n",
        "first.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xghmwXtScBkj",
        "outputId": "a44b6b8e-9cc8-4ad0-aa9b-cceab6384537"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second = {\n",
        "    'input_ids':first['input_ids'],\n",
        "    'token_type_ids':first['token_type_ids'],\n",
        "    'attention_mask':first['attention_mask']\n",
        "}\n"
      ],
      "metadata": {
        "id": "tw4374f8c-VK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encodings = arabert_tokenizer(train_questions[0:3], train_contexts[0:3], truncation=True, padding=True, return_tensors=\"pt\")\n",
        "from transformers import BertForQuestionAnswering\n",
        "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
        "outputs = model(**encodings, start_positions=train_encodings['start_positions'][:3], end_positions=train_encodings['end_positions'][:3])\n",
        "loss = outputs.loss\n",
        "start_scores = outputs.start_logits\n",
        "end_scores = outputs.end_logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shSWpWgFrbVR",
        "outputId": "5d95d35e-3293-489c-8aba-5a70ef36f30d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02 were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02 and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dMC9lPrs0S7",
        "outputId": "f5973853-0cc6-4f83-9094-701312d81f3e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.1345, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "starts = torch.argmax(start_scores, dim=-1)\n",
        "ends = torch.argmax(end_scores, dim=-1)\n",
        "print(starts)\n",
        "print(ends)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWKL5cMEsn8Q",
        "outputId": "2b0a58eb-09d5-46fe-f0b3-9bcc3b3f195e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([15, 85, 14])\n",
            "tensor([ 9, 37, 23])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for i, x in enumerate(train_loader):\n",
        "#  output= AraBert(**x)"
      ],
      "metadata": {
        "id": "ERX1exfkorSQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = AraBert(**second)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "Qxd1W8-Uf4mA",
        "outputId": "5bc634c5-0788-4c02-d51d-61a1642cf4b7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-f2c3d7eee53f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAraBert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msecond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to specify either input_ids or inputs_embeds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AraBert(input_ids = first['input_ids'], token_type_ids = first['token_type_ids'],attention_mask = first['attention_mask'])"
      ],
      "metadata": {
        "id": "-SaXKf9eceIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AraBertBase(nn.Module):\n",
        "  def __init__(self, BERT):\n",
        "    super().__init__()\n",
        "    self.base = BERT\n",
        "  def forward(self, X):\n",
        "    output_dict = self.base(**X)\n",
        "    \n"
      ],
      "metadata": {
        "id": "3ifcPJSKOKuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R1ilceKLPUzF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}