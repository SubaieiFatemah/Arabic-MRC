{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocess.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPFclhseXLc/B6N/4LU1VWz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeyadahmed10/Arabic-MRC/blob/DataCleaning/preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0M2GTvtHwpz"
      },
      "source": [
        "## Install & import required packages\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InlWwhe7Hqn4",
        "outputId": "adac033e-edf5-4682-e203-385cb8ec8f66"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4se86D7wISz-"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMmkEr2-IkzZ"
      },
      "source": [
        "## Mount google drive & creating new directories for AAQAD\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVXsuVnfIgfX",
        "outputId": "7ceb2cd2-a328-4c26-a700-b382e45f6a0e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTWjEUZvI9KJ"
      },
      "source": [
        "if not os.path.exists('/content/drive/MyDrive/MRC'):\n",
        "  os.mkdir('/content/drive/MyDrive/MRC')\n",
        "  os.mkdir('/content/drive/MyDrive/MRC/aaqad')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "QdJq2a98JzzU",
        "outputId": "0e8c513e-2587-4f7c-960b-69ebd6bd2ced"
      },
      "source": [
        "#uncomment if you did not download the data\n",
        "\"\"\" !pip install gdown\n",
        "!gdown https://drive.google.com/uc?id=1jhUmWb9eHVATqhrWKAXxSE2gqJ53-wk6 -O AAQAD.json\n",
        "!gdown https://drive.google.com/uc?id=1V5ziIZe__pGg14nH42WyMEFz444XPWf7 -O AAQAD\\-train.json\n",
        "!gdown https://drive.google.com/uc?id=19nj9jiCdJlHwAfgUTJ_Z8jg1cB34yfjv -O AAQAD\\-dev.json\n",
        "!gdown https://drive.google.com/uc?id=1z0XksuTwnqhiX1guxkmjYmoNA_JZ6SUN -O AAQAD\\-test.json \n",
        "\n",
        "src_path ='/content/'\n",
        "dest_path = '/content/drive/MyDrive/MRC/aaqad/'\n",
        "files_name =['AAQAD.json', 'AAQAD-train.json', 'AAQAD-dev.json', 'AAQAD-test.json']\n",
        "for name in files_name:\n",
        "  os.rename(src_path+name, dest_path+name)\n",
        "\"\"\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" !pip install gdown\\n!gdown https://drive.google.com/uc?id=1jhUmWb9eHVATqhrWKAXxSE2gqJ53-wk6 -O AAQAD.json\\n!gdown https://drive.google.com/uc?id=1V5ziIZe__pGg14nH42WyMEFz444XPWf7 -O AAQAD\\\\-train.json\\n!gdown https://drive.google.com/uc?id=19nj9jiCdJlHwAfgUTJ_Z8jg1cB34yfjv -O AAQAD\\\\-dev.json\\n!gdown https://drive.google.com/uc?id=1z0XksuTwnqhiX1guxkmjYmoNA_JZ6SUN -O AAQAD\\\\-test.json \\n\\nsrc_path ='/content/'\\ndest_path = '/content/drive/MyDrive/MRC/aaqad/'\\nfiles_name =['AAQAD.json', 'AAQAD-train.json', 'AAQAD-dev.json', 'AAQAD-test.json']\\nfor name in files_name:\\n  os.rename(src_path+name, dest_path+name)\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGjiH0ikMSJQ"
      },
      "source": [
        "## Load data and preprocessing\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghe8dtIIMj2v"
      },
      "source": [
        "with open('/content/drive/MyDrive/MRC/aaqad/AAQAD-dev.json') as f:\n",
        "  aaqad_dev_dict= json.load(f)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcbL62xRM2dU",
        "outputId": "ef34aa12-eee5-4127-938d-ee3d3fa6fd8f"
      },
      "source": [
        "##DATA TREE AND TYPE##\n",
        "aaqad_dev_dict['data']##list of articles\n",
        "aaqad_dev_dict['data'][0]## dictionary of paragraph -- keys(title, paragraph)\n",
        "aaqad_dev_dict['data'][0]['paragraphs'] ##list of contexts\n",
        "aaqad_dev_dict['data'][0]['paragraphs'][0] ## dictionary of context and crossponding QAs pairs --keys(context, qas)\n",
        "aaqad_dev_dict['data'][0]['paragraphs'][0]['qas'] ##list of QAs pair\n",
        "aaqad_dev_dict['data'][0]['paragraphs'][0] ['qas'][0] ##dictionary of the elements of each question --keys(id, is_impossible,question, answers)\n",
        "aaqad_dev_dict['data'][0]['paragraphs'][0] ['qas'][0]['answers'] ##dictionary of start index and answer text --keys(answer_start, text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'answer_start': 6,\n",
              "  'text': 'لديفيس تطوير مصطلح تبديل الرزم الذي ألهم مُطوري الشبكات'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO4PKnxETihu"
      },
      "source": [
        "def add_end_index(answer, context):\n",
        "  ## 1 if span mathc the context 0 otherwise\n",
        "  text = answer['text']\n",
        "  start_idx = answer['answer_start']\n",
        "  end_idx = start_idx + len(text)\n",
        "  if text == context[start_idx:end_idx]:\n",
        "    answer['answer_end'] = end_idx\n",
        "    return False\n",
        "  for i in range(1,3):\n",
        "    if text == context[start_idx-i:end_idx-i]:\n",
        "      answer['answer_end']= end_idx-1\n",
        "      answer['answer_start'] = start_idx-1\n",
        "      return False\n",
        "  return True"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L_EeDReM-57"
      },
      "source": [
        "def Read_AAQAD(path):\n",
        "  contexts =[]\n",
        "  answers =[]\n",
        "  questions =[]\n",
        "  cnt = 0\n",
        "  with open(path) as f:\n",
        "    aaqad_dict = json.load(f)\n",
        "    for article in aaqad_dict['data']:\n",
        "      for passage in article['paragraphs']:\n",
        "        context = passage['context']\n",
        "        for qa in passage['qas']:\n",
        "          question = qa['question']\n",
        "          if 'plausible_answers' in qa.keys():# there is two cases if the question have no answer then use plausible answer\n",
        "            access = 'plausible_answers'\n",
        "          else:\n",
        "            access = 'answers'\n",
        "          for answer in qa[access]:\n",
        "            flag = add_end_index(answer, context) #if false dont add the \n",
        "            cnt =cnt + flag\n",
        "            if not flag:\n",
        "              contexts.append(context)\n",
        "              answers.append(answer)\n",
        "              questions.append(question)\n",
        "  return contexts,questions,answers,cnt"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jabv_uE2TdHj"
      },
      "source": [
        "train_contexts, train_questions, train_answers, train_span_error = Read_AAQAD('/content/drive/MyDrive/MRC/aaqad/AAQAD-train.json')\n",
        "val_contexts, val_questions, val_answers, val_span_error = Read_AAQAD('/content/drive/MyDrive/MRC/aaqad/AAQAD-dev.json')\n",
        "test_contexts, test_questions, test_answers, test_span_error = Read_AAQAD('/content/drive/MyDrive/MRC/aaqad/AAQAD-test.json')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS7kUgcJZ34r",
        "outputId": "6e292601-c32a-4553-b0b6-58d14b700d50"
      },
      "source": [
        "total_error = train_span_error + val_span_error + test_span_error\n",
        "ratio = total_error/17817 #initial size of the data\n",
        "print(f\"Size of the data set before dropping the misslabeled spans: 17817 & after: {len(train_answers)+len(val_answers)+len(test_answers)}\")\n",
        "print(f\"Size of each split: \\n 1-Train: {len(train_answers)} \\n 2-Validation: {len(val_answers)} \\n 3-Test: {len(test_answers)}\")\n",
        "print(f\"percentage of span's error {ratio}\")\n",
        "print(f\"Number of errors for each split:\\n 1-Train: {train_span_error} \\n 2-Validation: {val_span_error}\\n 3-Test: {test_span_error}\")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the data set before dropping the misslabeled spans: 17817 & after: 17753\n",
            "Size of each split: \n",
            " 1-Train: 12595 \n",
            " 2-Validation: 1915 \n",
            " 3-Test: 3243\n",
            "percentage of span's error 0.0035920749845653028\n",
            "Number of errors for each split:\n",
            " 1-Train: 34 \n",
            " 2-Validation: 11\n",
            " 3-Test: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsnTPfiZedfy"
      },
      "source": [
        "## Tokenization\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOqWFALlen2W"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "#Creating the tokenizer\n",
        "model_name = \"aubmindlab/bert-base-arabertv02\"\n",
        "arabert_tokenizer = AutoTokenizer.from_pretrained(model_name,do_lower_case=False)\n",
        "\n",
        "train_encodings = arabert_tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "val_encodings = arabert_tokenizer(val_contexts, val_questions, truncation=True, padding=True)\n",
        "test_encodings = arabert_tokenizer(test_contexts,test_questions, truncation= True, padding= True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "142z-kzLgQIq"
      },
      "source": [
        "The encoding is dictionary of ['input_ids', 'token_type_ids', 'attention_mask'] <br>\n",
        "Input_ids: are the token of each sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ze0nuQLgZqb"
      },
      "source": [
        "def index_to_token_position(encodings , answers):\n",
        "  start_positions = list()\n",
        "  end_positions = list()\n",
        "  for i in range(len(answers)):\n",
        "    start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
        "    end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n",
        "    #if context truncated\n",
        "    if start_positions[-1] is None: \n",
        "      start_positions[-1] = arabert_tokenizer.model_max_length\n",
        "    #if end index is space\n",
        "    itt = 1\n",
        "    while end_positions[-1] is None: \n",
        "      end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end']-itt)\n",
        "      itt = itt + 1 \n",
        "      \n",
        "  return start_positions, end_positions"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li1QBYPxkbpR"
      },
      "source": [
        "train_start_pos, train_end_pos =index_to_token_position(train_encodings, train_answers)\n",
        "val_start_pos, val_end_pos = index_to_token_position(val_encodings, val_answers)\n",
        "test_start_pos ,test_end_pos = index_to_token_position(test_encodings, test_answers)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIzP7mZxlt0w",
        "outputId": "d52537f4-0989-49ea-d518-b92776ed1003"
      },
      "source": [
        "train_encodings.keys()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8bYM9g6o-zL",
        "outputId": "0987297d-0a72-4c05-b52d-2d48b357f152"
      },
      "source": [
        "def if_any_truncated(positions, max_token = arabert_tokenizer.model_max_length):\n",
        "  cnt = 0\n",
        "  for pos in positions:\n",
        "    if pos == max_token:\n",
        "      cnt = cnt + 1\n",
        "  return cnt\n",
        "print(if_any_truncated(train_start_pos))\n",
        "print(if_any_truncated(val_start_pos))\n",
        "print(if_any_truncated(test_start_pos))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "0\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDGhDkJwv35r"
      },
      "source": [
        "## Converting data to tensor for modeling\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9kF1O9-woJc"
      },
      "source": [
        "train_span = tf.convert_to_tensor([train_start_pos, train_end_pos])\n",
        "val_span = tf.convert_to_tensor([val_start_pos, val_end_pos])\n",
        "test_span = tf.convert_to_tensor([test_start_pos, test_end_pos])\n",
        "train_span = tf.transpose(train_span)\n",
        "val_span = tf.transpose(val_span)\n",
        "test_span = tf.transpose(test_span)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vrMP6kgyqVi",
        "outputId": "0b433f90-457e-4c0b-c1cf-074b22e61bb6"
      },
      "source": [
        "print(train_span.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12595, 2)\n"
          ]
        }
      ]
    }
  ]
}