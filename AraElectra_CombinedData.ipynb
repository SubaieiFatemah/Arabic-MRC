{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "import shutil\r\n",
        "from collections import Counter\r\n",
        "import numpy as np\r\n",
        "import json\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from transformers import AutoTokenizer, ElectraForQuestionAnswering, DataCollatorWithPadding\r\n",
        "from Preprocess.arabertpreprocess import ArabertPreprocessor\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import csv\r\n",
        "torch.manual_seed(3407)\r\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "<torch._C.Generator at 0x7f465423cd80>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1646075096137
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Data and Preprocessing"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_end_index(answer, context):\r\n",
        "  ## 1 if span mathc the context 0 otherwise\r\n",
        "  text = answer['text']\r\n",
        "  start_idx = answer['answer_start']\r\n",
        "  end_idx = start_idx + len(text)\r\n",
        "  if text == context[start_idx:end_idx]:\r\n",
        "    answer['answer_end'] = end_idx\r\n",
        "    return False\r\n",
        "  for i in range(1,3):\r\n",
        "    if text == context[start_idx-i:end_idx-i]:\r\n",
        "      answer['answer_end']= end_idx-1\r\n",
        "      answer['answer_start'] = start_idx-1\r\n",
        "      return False\r\n",
        "  return True"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075096306
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def arabert_preprocess(context,question, answer, arabert_prep):\r\n",
        "    answer['text'] = arabert_prep.preprocess(answer['text'])\r\n",
        "    context = arabert_prep.preprocess(context)\r\n",
        "    question = arabert_prep.preprocess(question)\r\n",
        "    res = context.find(answer['text'])\r\n",
        "    answer['answer_start'] = res\r\n",
        "    return context, question, answer, res"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075096470
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Read_AAQAD(path,arabert_prep):\r\n",
        "  contexts =[]\r\n",
        "  answers =[]\r\n",
        "  questions =[]\r\n",
        "  IDs= []\r\n",
        "  cnt = 0\r\n",
        "  with open(path) as f:\r\n",
        "    aaqad_dict = json.load(f)\r\n",
        "    for article in aaqad_dict['data']:\r\n",
        "      for passage in article['paragraphs']:\r\n",
        "        context = passage['context']\r\n",
        "        for qa in passage['qas']:\r\n",
        "          question = qa['question']\r\n",
        "          if 'plausible_answers' in qa.keys():# there is two cases if the question have no answer then use plausible answer\r\n",
        "            access = 'plausible_answers'\r\n",
        "            #plausible.append(False)\r\n",
        "          else:\r\n",
        "            access = 'answers'\r\n",
        "            #plausible.append(True)\r\n",
        "          for answer in qa[access]:\r\n",
        "            context,question, answer, res =  arabert_preprocess(context,question, answer, arabert_prep)\r\n",
        "            if res==-1:\r\n",
        "              cnt+=1\r\n",
        "              continue\r\n",
        "            flag = add_end_index(answer, context) #if false dont add the \r\n",
        "            cnt =cnt + flag\r\n",
        "            if not flag:\r\n",
        "              contexts.append(context)\r\n",
        "              answers.append(answer)\r\n",
        "              questions.append(question)\r\n",
        "              IDs.append(qa['id'])\r\n",
        "  return contexts,questions,answers,IDs\r\n",
        "            "
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075096622
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"araelectra-base-discriminator\"\r\n",
        "arabert_prep = ArabertPreprocessor(model_name=model_name)\r\n",
        "train_contexts, train_questions, train_answers, train_ids = Read_AAQAD('Data/ASQUAD1.json', arabert_prep)\r\n",
        "aqad_train_contexts, aqad_train_questions, aqad_train_answers, aqad_train_ids = Read_AAQAD('Data/AAQAD-train.json', arabert_prep)\r\n",
        "arcd_train_contexts, arcd_train_questions, arcd_train_answers, arcd_train_ids = Read_AAQAD('Data/arcd-train.json', arabert_prep)\r\n",
        "aqad_val_contexts, aqad_val_questions, aqad_val_answers, aqad_val_ids = Read_AAQAD('Data/AAQAD-dev.json', arabert_prep)\r\n",
        "arcd_test_contexts, arcd_test_questions, arcd_test_answers, arcd_test_ids = Read_AAQAD('Data/arcd-test.json', arabert_prep)\r\n",
        "aqad_test_contexts, aqad_test_questions, aqad_test_answers, aqad_test_ids = Read_AAQAD('Data/AAQAD-test.json', arabert_prep)\r\n"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075158791
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_contexts = train_contexts +aqad_train_contexts +arcd_train_contexts\r\n",
        "train_questions = train_questions+ aqad_train_questions +arcd_train_questions\r\n",
        "train_answers = train_answers+ aqad_train_answers+ arcd_train_answers\r\n",
        "train_ids = train_ids + aqad_train_ids + arcd_train_ids\r\n",
        "print(len(train_contexts), len(train_questions), len(train_answers))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "61666 61666 61666\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075158958
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del aqad_train_contexts, aqad_train_questions, aqad_train_answers, aqad_train_ids\r\n",
        "del arcd_train_contexts, arcd_train_questions, arcd_train_answers, arcd_train_ids\r\n",
        "print(len(train_contexts), len(train_questions), len(train_answers))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "61666 61666 61666\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075159133
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_contexts[0])\r\n",
        "print(train_questions[0])\r\n",
        "print(train_answers[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "يعتمد ASCII أساس ا على الأبجدية الإنجليزية ، ويقوم بترميز 128 حرف ا محدد ا في أعداد صحيحة من سبعة أجزاء كما هو موضح في مخطط ASCII على اليمين . الأحرف المشفرة هي الأرقام من 0 إلى 9 ، والأحرف الصغيرة ا إلى ز ، والأحرف الكبيرة A إلى Z ، ورموز الترقيم الأساسية ، ورموز التحكم التي نشأت مع أجهزة تيليتيبي ، ومساحة . على سبيل المثال ، سيصبح الحرف الصغير ج 1101010 والعشري 106 . تتضمن ASCII تعريفات ل 128 حرف ا 33 حرف ا تحكم ا غير الطباعة العديد منها الآن قديمة تؤثر على كيفية معالجة النص والمساحة و 95 حرف ا قابلا للطباعة ، بما في ذلك المساحة التي ي عتبر رسم ا غير مرئي 223 .\nما هو ASCII على أساس ؟\n{'text': 'الأبجدية الإنجليزية', 'answer_start': 23, 'answer_end': 42}\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075159284
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the tokenizer\r\n",
        "model_name = model_name = \"aubmindlab/araelectra-base-discriminator\"\r\n",
        "\r\n",
        "araelectra_tokenizer = AutoTokenizer.from_pretrained(model_name,do_lower_case=False)\r\n",
        "train_encodings = araelectra_tokenizer(train_questions, train_contexts, truncation=True)\r\n",
        "aqad_val_encodings = araelectra_tokenizer(aqad_val_questions, aqad_val_contexts, truncation=True)\r\n",
        "#test_encodings = arabert_tokenizer(test_questions, test_contexts,truncation= True, padding= True, return_tensors=\"pt\")"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075167263
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def index_to_token_position(encodings , answers):\r\n",
        "  start_positions = list()\r\n",
        "  end_positions = list()\r\n",
        "  for i in range(len(answers)):\r\n",
        "    start_positions.append(encodings.char_to_token(i, answers[i]['answer_start'], 1))\r\n",
        "    end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'], 1))\r\n",
        "    #if context truncated\r\n",
        "    if start_positions[-1] is None: \r\n",
        "      start_positions[-1] = araelectra_tokenizer.model_max_length\r\n",
        "    #if end index is space\r\n",
        "    itt = 1\r\n",
        "    while end_positions[-1] is None: \r\n",
        "      end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end']-itt, 1)\r\n",
        "      itt = itt + 1 \r\n",
        "  encodings.update({'start_positions': torch.tensor(start_positions), 'end_positions': torch.tensor(end_positions)})\r\n",
        "  encodings['start_positions'] = encodings['start_positions'].view(len(answers), 1)\r\n",
        "  encodings['end_positions'] = encodings['end_positions'].view(len(answers), 1)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075167421
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_token_position(train_encodings, train_answers)\r\n",
        "index_to_token_position(aqad_val_encodings, aqad_val_answers)\r\n"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075167619
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings.keys()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075167798
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train_encodings.update({'IDs':torch.tensor(train_ids)})\r\n",
        "aqad_val_encodings.update({'IDs':torch.tensor(aqad_val_ids)})\r\n",
        "#train_encodings['IDs'] = train_encodings['IDs'].view(len(train_contexts), 1)\r\n",
        "aqad_val_encodings['IDs'] = aqad_val_encodings['IDs'].view(len(aqad_val_contexts), 1)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075167974
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset and Dataloader"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from tqdm import tqdm"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075168121
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AqadDataset(torch.utils.data.Dataset):\r\n",
        "    def __init__(self, encodings):\r\n",
        "        self.encodings = encodings\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        return {key: val[idx] for key, val in self.encodings.items()}\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.encodings.input_ids)\r\n",
        "\r\n",
        "train_dataset = AqadDataset(train_encodings)\r\n",
        "aqad_val_dataset = AqadDataset(aqad_val_encodings)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075168287
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(araelectra_tokenizer)"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075168455
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle= True, collate_fn= data_collator)\r\n",
        "aqad_val_loader = DataLoader(aqad_val_dataset, batch_size = 8, shuffle = True, collate_fn = data_collator)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075168614
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for step, batch in enumerate(train_loader):\r\n",
        "    print(batch['input_ids'].shape)\r\n",
        "    print(batch.keys())\r\n",
        "    if step>1:\r\n",
        "        break"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "torch.Size([8, 402])\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])\ntorch.Size([8, 184])\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])\ntorch.Size([8, 411])\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075168772
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checkpoint Saving and Loading"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\r\n",
        "    \"\"\"\r\n",
        "    state: checkpoint to save\r\n",
        "    is_best: is this the best checkpoint; min validation loss\r\n",
        "    checkpoint_path: path to save checkpoint\r\n",
        "    best_model_path: path to save best checkpoint\r\n",
        "    \"\"\"\r\n",
        "    f_path = checkpoint_path\r\n",
        "    # save checkpoint data to the path given, checkpoint_path\r\n",
        "    torch.save(state, f_path)\r\n",
        "    # if it is a best model, min validation loss\r\n",
        "    if is_best:\r\n",
        "        best_fpath = best_model_path\r\n",
        "        # copy that checkpoint file to best path given, best_model_path\r\n",
        "        shutil.copyfile(f_path, best_fpath)"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075168944
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer):\r\n",
        "    \"\"\"\r\n",
        "    checkpoint_path: path to saved checkpoint\r\n",
        "    model: model to load checkpoint parameters into       \r\n",
        "    optimizer: optimizer defined in previous training\r\n",
        "    \"\"\"\r\n",
        "    # load check point\r\n",
        "    checkpoint = torch.load(checkpoint_fpath)\r\n",
        "    # initialize state_dict from checkpoint to model\r\n",
        "    model.load_state_dict(checkpoint['state_dict'])\r\n",
        "    # initialize optimizer from checkpoint to optimizer\r\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\r\n",
        "    # initialize valid_loss_min from checkpoint to valid_loss_min\r\n",
        "    valid_loss_min = checkpoint['val_loss']\r\n",
        "    # return model, optimizer, epoch value, min validation loss \r\n",
        "    return model, optimizer, checkpoint['epoch'], valid_loss_min"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075169101
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def order_exp(base_path, exp_name):\r\n",
        "  exp_path = os.path.join(base_path, exp_name)\r\n",
        "  if not os.path.exists(exp_path):\r\n",
        "    os.mkdir(exp_path)\r\n",
        "  curr_ckp_path = os.path.join(exp_path,'curr.pt')\r\n",
        "  best_ckp_path = os.path.join(exp_path, 'best.pt')\r\n",
        "  return curr_ckp_path, best_ckp_path, exp_path"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075169274
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate SQuAD"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\r\n",
        "from collections import Counter\r\n",
        "import string\r\n",
        "import re\r\n",
        "import argparse\r\n",
        "import json\r\n",
        "import sys\r\n",
        "import nltk\r\n",
        "import random\r\n",
        "nltk.download('punkt')\r\n",
        "def normalize_answer(s):\r\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\r\n",
        "    def remove_articles(text):\r\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\r\n",
        "\r\n",
        "    def white_space_fix(text):\r\n",
        "        return ' '.join(text.split())\r\n",
        "\r\n",
        "    def remove_punc(text):\r\n",
        "        exclude = set(string.punctuation)\r\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\r\n",
        "\r\n",
        "    def lower(text):\r\n",
        "        return text.lower()\r\n",
        "\r\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\r\n",
        "\r\n",
        "\r\n",
        "def f1_score(prediction, ground_truth):\r\n",
        "    prediction_tokens = normalize_answer(prediction).split()\r\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\r\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\r\n",
        "    num_same = sum(common.values())\r\n",
        "    if num_same == 0:\r\n",
        "        return 0\r\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\r\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\r\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\r\n",
        "    return f1\r\n",
        "\r\n",
        "\r\n",
        "def exact_match_score(prediction, ground_truth):\r\n",
        "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\r\n",
        "\r\n",
        "\r\n",
        "def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\r\n",
        "    scores_for_ground_truths = []\r\n",
        "    for ground_truth in ground_truths:\r\n",
        "        score = metric_fn(prediction, ground_truth)\r\n",
        "        scores_for_ground_truths.append(score)\r\n",
        "    return max(scores_for_ground_truths)\r\n",
        "\r\n",
        "def evaluate_squad(dataset, predictions):\r\n",
        "    f1 = exact_match = total = exact_sentence = inclusion = random = 0\r\n",
        "    f1_ans = exact_match_ans = total_ans = exact_sentence_ans  = 0\r\n",
        "    f1_noans = exact_match_noans = total_noans = exact_sentence_noans = 0\r\n",
        "    for article in dataset:\r\n",
        "        for paragraph in article['paragraphs']:\r\n",
        "            for qa in paragraph['qas']:\r\n",
        "                flag = False\r\n",
        "                total += 1\r\n",
        "                if qa['id'] not in predictions:\r\n",
        "                    message = 'Unanswered question ' + str(qa['id']) + \\\r\n",
        "                              ' will receive score 0.'\r\n",
        "                    print(message, file=sys.stderr)\r\n",
        "                    continue\r\n",
        "                ground_truths = list(map(lambda x: arabert_prep.preprocess(x['text']), qa['answers']))\r\n",
        "                #print(type(ground_truths))\r\n",
        "                if len(ground_truths)==0:\r\n",
        "                    flag = True\r\n",
        "                    total_noans +=1\r\n",
        "                else:\r\n",
        "                    total_ans+=1\r\n",
        "                if flag:\r\n",
        "                    ground_truths = list(map(lambda x: arabert_prep.preprocess(x['text']), qa['plausible_answers']))\r\n",
        "                prediction = predictions[qa['id']]\r\n",
        "                sents = nltk.sent_tokenize(arabert_prep.preprocess(paragraph['context']))\r\n",
        "                indx_g = -1\r\n",
        "                indx_p = -1\r\n",
        "                i = 0\r\n",
        "                for sent in sents:\r\n",
        "                    if sent.find(ground_truths[0]) != -1:\r\n",
        "                        indx_g = i\r\n",
        "                    if sent.find(prediction) != -1:\r\n",
        "                        indx_p = i\r\n",
        "                    i += 1\r\n",
        "                if prediction.find(ground_truths[0]) != -1 or ground_truths[0].find(prediction):\r\n",
        "                    inclusion += 1\r\n",
        "                if indx_g == indx_p and indx_p != -1:\r\n",
        "                    exact_sentence += 1\r\n",
        "                    if flag:\r\n",
        "                        exact_sentence_noans+=1\r\n",
        "                    else:\r\n",
        "                        exact_sentence_ans+=1\r\n",
        "\r\n",
        "                curr_exact_match= metric_max_over_ground_truths(\r\n",
        "                    exact_match_score, prediction, ground_truths)\r\n",
        "                curr_f1 = metric_max_over_ground_truths(\r\n",
        "                    f1_score, prediction, ground_truths)\r\n",
        "                if flag:\r\n",
        "                    f1_noans+=curr_f1\r\n",
        "                    exact_match_noans+=curr_exact_match\r\n",
        "                else:\r\n",
        "                    f1_ans+=curr_f1\r\n",
        "                    exact_match_ans+=curr_exact_match\r\n",
        "                f1+=curr_f1\r\n",
        "                exact_match+=curr_exact_match\r\n",
        "    print(f\"total examples {total}, total have answers {total_ans} total have no answers {total_noans}\")\r\n",
        "    exact_sentence = 100 * exact_sentence / total\r\n",
        "    exact_match = 100.0 * exact_match / total\r\n",
        "    f1 = 100.0 * f1 / total\r\n",
        "\r\n",
        "    exact_sentence_ans = 100 * exact_sentence_ans / total_ans\r\n",
        "    exact_match_ans = 100.0 * exact_match_ans / total_ans\r\n",
        "    f1_ans = 100.0 * f1_ans / total_ans\r\n",
        "    print(exact_sentence_noans)\r\n",
        "    exact_sentence_noans = 100 * exact_sentence_noans / total_noans\r\n",
        "    exact_match_noans = 100.0 * exact_match_noans / total_noans\r\n",
        "    f1_noans = 100.0 * f1_noans / total_noans\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    return {'exact_match': exact_match, 'f1': f1, 'exact_sentence': exact_sentence,\r\n",
        "    'exact_match_ans': exact_match_ans, 'f1_ans': f1_ans, 'exact_sentence_ans': exact_match_ans,\r\n",
        "    'exact_match_noans': exact_match_noans, 'f1_noans':f1_noans, 'exact_sentence_noans':exact_sentence_noans}\r\n",
        "\r\n",
        "\r\n",
        "#evaluation\r\n",
        "'''\r\n",
        "predict_file_path = 'Data/AAQAD-test.json'\r\n",
        "predictions_file_path = 'Predictions.json'\r\n",
        "with open(predict_file_path) as dataset_file:\r\n",
        "  dataset_json = json.load(dataset_file)\r\n",
        "  dataset = dataset_json['data']\r\n",
        "with open(predictions_file_path) as prediction_file:\r\n",
        "  predictions = json.load(prediction_file)\r\n",
        "print(json.dumps(evaluate(dataset, predictions)))'''"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading package punkt to /home/azureuser/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "\"\\npredict_file_path = 'Data/AAQAD-test.json'\\npredictions_file_path = 'Predictions.json'\\nwith open(predict_file_path) as dataset_file:\\n  dataset_json = json.load(dataset_file)\\n  dataset = dataset_json['data']\\nwith open(predictions_file_path) as prediction_file:\\n  predictions = json.load(prediction_file)\\nprint(json.dumps(evaluate(dataset, predictions)))\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075169457
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate and Train functions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(data_loader, model, log, log_path=None, train_loss=None): \r\n",
        "  model.eval()\r\n",
        "  with torch.no_grad():\r\n",
        "    #F1 = EM = Total = 0\r\n",
        "    total_loss = 0.0\r\n",
        "    total_predictions = dict()\r\n",
        "    #loop = tqdm(data_loader)\r\n",
        "    #loop = tqdm(data_loader, leave=True)\r\n",
        "    for batch_idx, batch in enumerate(data_loader):\r\n",
        "      #moving tensors to gpu    \r\n",
        "      tokens = batch['input_ids'].to(device)\r\n",
        "      masks = batch['attention_mask'].to(device)\r\n",
        "      tokens_type = batch['token_type_ids'].to(device)\r\n",
        "      gt_start = batch['start_positions'].to(device)\r\n",
        "      gt_end = batch['end_positions'].to(device)\r\n",
        "      IDs = batch['IDs'].to(device)\r\n",
        "      outputs = model(tokens, masks, tokens_type, start_positions=gt_start, end_positions=gt_end)\r\n",
        "      #calculating loss\r\n",
        "      loss = outputs.loss\r\n",
        "      #update average total loss \r\n",
        "      total_loss = total_loss + ((1 / (batch_idx + 1)) * (loss - total_loss)) \r\n",
        "      #calculating f1 score and EM\r\n",
        "      curr_batch_size = gt_start.shape[0]\r\n",
        "      #print(curr_batch_size)\r\n",
        "      for i in range(curr_batch_size):\r\n",
        "        #print(f\"this is tensor index {i}\")\r\n",
        "        start_gt, end_gt = batch['start_positions'][i], batch['end_positions'][i]\r\n",
        "        start_pred, end_pred = torch.argmax(outputs.start_logits[i],dim=0), torch.argmax(outputs.end_logits[i],dim =0)\r\n",
        "        total_predictions[IDs[i].item()] = araelectra_tokenizer.decode(tokens[i][start_pred.item():end_pred.item()], skip_special_tokens=True, clean_up_tokenization_spaces=True)\r\n",
        "    #saving evaluation results\r\n",
        "    #evaluation\r\n",
        "    print(total_predictions[5539])\r\n",
        "    with open('Data/AAQAD-dev.json') as dataset_file:\r\n",
        "        dataset_json = json.load(dataset_file)\r\n",
        "        dataset = dataset_json['data']\r\n",
        "    result_dict = evaluate_squad(dataset, total_predictions)\r\n",
        "    try:\r\n",
        "        result_dict['train_loss'] = train_loss.item()\r\n",
        "        result_dict['val_loss'] = total_loss.item()\r\n",
        "    except:\r\n",
        "        pass\r\n",
        "    print(type(result_dict))\r\n",
        "    print(result_dict)\r\n",
        "    #print(json.dumps(result_dict))\r\n",
        "    if(log):\r\n",
        "      log_path = os.path.join(log_path,'res.csv')\r\n",
        "      if not os.path.exists(log_path):\r\n",
        "          with open(log_path,'w') as f:\r\n",
        "            writer = csv.DictWriter(f, fieldnames=result_dict.keys())\r\n",
        "            writer.writeheader()\r\n",
        "      with open(log_path, 'a') as f:\r\n",
        "        writer = csv.DictWriter(f, fieldnames=result_dict.keys())\r\n",
        "        #writer.writeheader()\r\n",
        "        writer.writerow(result_dict)\r\n",
        "    model.train()\r\n",
        "    return result_dict"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075169649
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,start_epoch, num_epochs, optimizer,max_compined_metric, train_loader, val_loader, log, exp_name):\r\n",
        "  curr_ckp_path, best_ckp_path, exp_path = order_exp('Runs/AraElectra_CombinedData/train', exp_name)\r\n",
        "  model.train()\r\n",
        "  for epoch in range(start_epoch,num_epochs):\r\n",
        "    total_loss = 0.0\r\n",
        "    loop = tqdm(train_loader, leave=True)\r\n",
        "    for batch_idx, batch in enumerate(loop):\r\n",
        "      tokens = batch['input_ids'].to(device)\r\n",
        "      masks = batch['attention_mask'].to(device)\r\n",
        "      tokens_type = batch['token_type_ids'].to(device)\r\n",
        "      gt_start = batch['start_positions'].to(device)\r\n",
        "      gt_end = batch['end_positions'].to(device)\r\n",
        "      outputs = model(tokens, masks, tokens_type, start_positions=gt_start, end_positions=gt_end)\r\n",
        "      loss = outputs.loss\r\n",
        "      loss.backward()\r\n",
        "      optimizer.step()\r\n",
        "      optimizer.zero_grad()\r\n",
        "      total_loss = total_loss + ((1 / (batch_idx + 1)) * (loss - total_loss)) \r\n",
        "      loop.set_description(f'Epoch {epoch}')\r\n",
        "      loop.set_postfix(loss=loss.item())\r\n",
        "\r\n",
        "    result_dict = evaluate(val_loader, model , log, exp_path, total_loss)\r\n",
        "    checkpoint = {\r\n",
        "            'epoch': epoch + 1,\r\n",
        "            'result_dict':result_dict,\r\n",
        "            'state_dict': model.state_dict(),\r\n",
        "            'optimizer': optimizer.state_dict(),\r\n",
        "        }\r\n",
        "    curr_compined_metric = result_dict['exact_match']+1.5*result_dict['f1']+0.7*result_dict['exact_sentence']\r\n",
        "    if curr_compined_metric>=max_compined_metric:\r\n",
        "      max_compined_metric = curr_compined_metric\r\n",
        "      save_ckp(checkpoint, True, curr_ckp_path, best_ckp_path)\r\n",
        "    else:\r\n",
        "      save_ckp(checkpoint, False, curr_ckp_path, best_ckp_path)\r\n",
        "  return model\r\n"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075169833
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze(Electra, count=None):\r\n",
        "    if count is not None:\r\n",
        "\t      # We freeze here the embeddings of the model\r\n",
        "        for param in Electra.electra.embeddings.parameters():\r\n",
        "            param.requires_grad = False\r\n",
        "\r\n",
        "        if count != -1:\r\n",
        "\t          # if freeze_layer_count == -1, we only freeze the embedding layer\r\n",
        "\t          # otherwise we freeze the first `freeze_layer_count` encoder layers\r\n",
        "            for layer in Electra.electra.encoder.layer[:count]:\r\n",
        "                for param in layer.parameters():\r\n",
        "                    param.requires_grad = False\r\n",
        "    print(sum(p.numel() for p in Electra.parameters()), sum(p.numel() for p in Electra.parameters() if p.requires_grad))"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075169999
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QA_AraElectra = ElectraForQuestionAnswering.from_pretrained(model_name)\r\n",
        "freeze(QA_AraElectra, 4)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of the model checkpoint at aubmindlab/araelectra-base-discriminator were not used when initializing ElectraForQuestionAnswering: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n- This IS expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at aubmindlab/araelectra-base-discriminator and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "134604290 56704514\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075172975
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "QA_AraElectra.to(device)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "ElectraForQuestionAnswering(\n  (electra): ElectraModel(\n    (embeddings): ElectraEmbeddings(\n      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): ElectraEncoder(\n      (layer): ModuleList(\n        (0): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075175301
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\r\n",
        "learning_rate = 3e-5\r\n",
        "optimizer = torch.optim.AdamW(QA_AraElectra.parameters(), lr=learning_rate)\r\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "QA_AraElectra.to(device)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "ElectraForQuestionAnswering(\n  (electra): ElectraModel(\n    (embeddings): ElectraEmbeddings(\n      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): ElectraEncoder(\n      (layer): ModuleList(\n        (0): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646075175512
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = train(QA_AraElectra, 0, num_epochs, optimizer, 0, train_loader, aqad_val_loader,True, 'firstFreeze4AdamW')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Epoch 0: 100%|██████████| 7709/7709 [1:23:25<00:00,  1.54it/s, loss=2.72] \nEpoch 1: 100%|██████████| 7709/7709 [1:23:35<00:00,  1.54it/s, loss=0.806]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "179\ntotal examples 1926, total have answers 1193 total have no answers 733\n416\n<class 'dict'>\n{'exact_match': 3.790238836967809, 'f1': 22.611938207877447, 'exact_sentence': 57.11318795430945, 'exact_match_ans': 4.694048616932104, 'f1_ans': 25.984081185595617, 'exact_sentence_ans': 4.694048616932104, 'exact_match_noans': 2.319236016371078, 'f1_noans': 17.123579991754934, 'exact_sentence_noans': 56.75306957708049, 'train_loss': 2.4689888954162598, 'val_loss': 2.9085168838500977}\n179\ntotal examples 1926, total have answers 1193 total have no answers 733\n443\n<class 'dict'>\n{'exact_match': 3.6863966770508827, 'f1': 24.435995525849044, 'exact_sentence': 59.345794392523366, 'exact_match_ans': 4.861693210393965, 'f1_ans': 27.79402539149263, 'exact_sentence_ans': 4.861693210393965, 'exact_match_noans': 1.7735334242837653, 'f1_noans': 18.970607217918772, 'exact_sentence_noans': 60.43656207366985, 'train_loss': 1.9735907316207886, 'val_loss': 2.9121501445770264}\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646085432676
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}